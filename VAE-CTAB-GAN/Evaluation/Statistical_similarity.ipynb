{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c3d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler,OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, log_loss\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch \n",
    "import os\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "662cad1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14c7e40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'label1_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/VAE-CTAB-GAN/Real_Datasets/train_category_1.csv\"\\nlabel1 = pd.read_csv(label1_path, low_memory=False)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load original data\n",
    "data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/VAE-CTAB-GAN/Real_Datasets/train_category.csv\"\n",
    "data = pd.read_csv(data_path, low_memory=False)\n",
    "\n",
    "##load test data\n",
    "test_data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/VAE-CTAB-GAN/Real_Datasets/test_category.csv\"\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "data_0 = data[data['loan_status']==0]\n",
    "data_0_sampled = data_0.sample(540000,random_state=42)\n",
    "\n",
    "\"\"\"label1_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/VAE-CTAB-GAN/Real_Datasets/train_category_1.csv\"\n",
    "label1 = pd.read_csv(label1_path, low_memory=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b985234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data.drop(columns='loan_status')\n",
    "data_y = data[['loan_status']]\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_under, y_under = rus.fit_resample(data_x, data_y)\n",
    "\n",
    "data_base = pd.concat([X_under,y_under], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39dd779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep_features = ['grade', 'term_months', 'total_pymnt', 'total_pymnt_inv','total_il_high_credit_limit', 'loan_amnt']\n",
    "keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "\n",
    "data_classification = data_base.copy()\n",
    "test_classification = test_data.copy()\n",
    "\n",
    "data_classification = data_classification.drop(columns = keep_features)\n",
    "test_classification = test_classification.drop(columns = keep_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f806c51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Encoding 완료! 결과 shape: (435578, 35)\n"
     ]
    }
   ],
   "source": [
    "## data Encoding\n",
    "Labelencoding_features = ['term_months', 'sub_grade']\n",
    "onehot_features = ['debt_settlement_flag', 'home_ownership', 'purpose']\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "label_encoders = {}\n",
    "for col in Labelencoding_features:\n",
    "    le = LabelEncoder()\n",
    "    data_classification[col] = le.fit_transform(data_classification[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# One-Hot Encoding\n",
    "onehot_encoded = onehot_encoder.fit_transform(data_classification[onehot_features])\n",
    "onehot_encoded_df = pd.DataFrame(\n",
    "    onehot_encoded, \n",
    "    columns=onehot_encoder.get_feature_names_out(onehot_features),\n",
    "    index=data_classification.index\n",
    ")\n",
    "\n",
    "# Merge\n",
    "data_classification.drop(columns=onehot_features, inplace=True)\n",
    "data_classification = pd.concat([data_classification, onehot_encoded_df], axis=1)\n",
    "\n",
    "print(\"✅ Encoding 완료! 결과 shape:\", data_classification.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a9a604c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 테스트 데이터 인코딩 완료! 결과 shape: (744306, 35)\n"
     ]
    }
   ],
   "source": [
    "##Test data encoding\n",
    "for col in Labelencoding_features:\n",
    "    le = label_encoders[col]\n",
    "    test_classification[col] = le.transform(test_classification[col])\n",
    "\n",
    "# One-Hot Encoding (train에서 fit된 onehot_encoder 재사용)\n",
    "onehot_encoded_test = onehot_encoder.transform(test_classification[onehot_features])\n",
    "onehot_encoded_test_df = pd.DataFrame(\n",
    "    onehot_encoded_test,\n",
    "    columns=onehot_encoder.get_feature_names_out(onehot_features),\n",
    "    index=test_classification.index\n",
    ")\n",
    "\n",
    "# Merge\n",
    "test_classification.drop(columns=onehot_features, inplace=True)\n",
    "test_classification = pd.concat([test_classification, onehot_encoded_test_df], axis=1)\n",
    "\n",
    "print(\"✅ 테스트 데이터 인코딩 완료! 결과 shape:\", test_classification.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03f43049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features(df, label_encoders, onehot_encoder, label_cols, onehot_cols):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Label Encoding\n",
    "    for col in label_cols:\n",
    "        le = label_encoders[col]\n",
    "        df[col] = le.transform(df[col])\n",
    "\n",
    "    # One-Hot Encoding\n",
    "    onehot_encoded = onehot_encoder.transform(df[onehot_cols])\n",
    "    onehot_df = pd.DataFrame(\n",
    "        onehot_encoded, \n",
    "        columns=onehot_encoder.get_feature_names_out(onehot_cols),\n",
    "        index=df.index\n",
    "    )\n",
    "\n",
    "    df.drop(columns=onehot_cols, inplace=True)\n",
    "    df = pd.concat([df, onehot_df], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0db3b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "def ml_utility(model, X_test, y_test, method):\n",
    "    results = []\n",
    "\n",
    "    if method == \"non-augmented\":\n",
    "        X_train = data_classification.drop(columns='loan_status')\n",
    "        y_train = data_classification[['loan_status']]\n",
    "\n",
    "\n",
    "    elif method == 'SMOTE-NC':\n",
    "        print(\"smote-nc\")\n",
    "        smote_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/base/smote-nc.csv\"\n",
    "        smote_data = pd.read_csv(smote_path)\n",
    "        ##합성 데이터와 합치기\n",
    "        combined = pd.concat([data_0_sampled, smote_data], axis=0).sample(frac=1, random_state=42)\n",
    "\n",
    "        drop_cols = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt', 'funded_amnt']\n",
    "        combined = combined.drop(columns=drop_cols)\n",
    "        combined['term_months'] = combined['term_months'].apply(lambda x: 36 if abs(x - 36) < abs(x - 60) else 60)\n",
    "        combined = encode_features(combined, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        X_train = combined.drop(columns='loan_status')\n",
    "        y_train = combined[['loan_status']]\n",
    "        \n",
    "    else:\n",
    "        fake_base = {\n",
    "            'table-gan': 'tablegan/tablegan.csv',\n",
    "            'vae-tablegan': 'tablegan/vae-tablegan.csv',\n",
    "            'ctgan': 'ctgan/ctgan.csv',\n",
    "            'vae-ctgan': 'ctgan/vae-ctgan.csv',\n",
    "            'ctabgan': 'ctabgan/ctabgan.csv',\n",
    "            'vae-ctabgan': 'ctabgan/vae-ctabgan.csv'\n",
    "        }\n",
    "\n",
    "        if method not in fake_base:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "        print(f\"{method}\")\n",
    "        fake_path = f\"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/{fake_base[method]}\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1  # 모든 fake는 default\n",
    "            \n",
    "        combined = pd.concat([data_0_sampled, fake], axis=0).sample(frac=1, random_state=42)\n",
    "        \n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt', 'funded_amnt']\n",
    "        fake = combined.drop(columns=keep_features)\n",
    "        fake['term_months'] = fake['term_months'].apply(lambda x: 36 if abs(x - 36) < abs(x - 60) else 60)\n",
    "        fake = encode_features(fake, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        X_train = fake.drop(columns='loan_status')\n",
    "        y_train = fake[['loan_status']]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    results.append({\n",
    "        \"Method\": method,\n",
    "        \"Accuracy\": round(accuracy_score(y_test, y_pred), 4),\n",
    "        \"F1\": round(f1_score(y_test, y_pred), 4),\n",
    "        \"AUC\": round(roc_auc_score(y_test, y_proba), 4),\n",
    "        \"Class1 Recall\": round(report[\"1\"][\"recall\"], 4),\n",
    "        \"Class1 Precision\": round(report[\"1\"][\"precision\"], 4)\n",
    "    })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b31ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  12%|█▎        | 1/8 [00:29<03:25, 29.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smote-nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  25%|██▌       | 2/8 [01:39<05:18, 53.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table-gan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  38%|███▊      | 3/8 [02:46<04:57, 59.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vae-tablegan\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "methods = [\n",
    "    \"non-augmented\", \"SMOTE-NC\",\n",
    "    \"table-gan\", \"vae-tablegan\",\n",
    "    \"ctgan\", \"vae-ctgan\",\n",
    "    \"ctabgan\", \"vae-ctabgan\",\n",
    "]\n",
    "\n",
    "X_test = test_classification.drop(columns='loan_status')\n",
    "y_test = test_classification['loan_status']\n",
    "\n",
    "# 전체 결과 저장용 DataFrame\n",
    "ml_utility_df = pd.DataFrame()\n",
    "\n",
    "for method in tqdm(methods, desc=\"Methods\"):\n",
    "    model = LogisticRegression(\n",
    "        penalty='l2',\n",
    "        solver='lbfgs',         \n",
    "        max_iter=1000,        \n",
    "        random_state=42,\n",
    "        n_jobs=-1             \n",
    "    )\n",
    "\n",
    "    result_table = ml_utility(model, X_test, y_test, method)\n",
    "    ml_utility_df = pd.concat([ml_utility_df, pd.DataFrame(result_table)], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0f9c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Method  Accuracy      F1     AUC  Class1 Recall  Class1 Precision\n",
      "0  non-augmented    0.8840  0.7540  0.9529         0.9114            0.6430\n",
      "1       SMOTE-NC    0.9024  0.7363  0.9435         0.6988            0.7781\n",
      "2      table-gan    0.8233  0.2204  0.7798         0.1281            0.7914\n",
      "3   vae-tablegan    0.8316  0.2403  0.5701         0.1365            0.9996\n",
      "4          ctgan    0.9008  0.7605  0.9420         0.8075            0.7187\n",
      "5      vae-ctgan    0.8316  0.2403  0.5701         0.1365            0.9996\n",
      "6        ctabgan    0.8806  0.6174  0.9339         0.4938            0.8236\n",
      "7    vae-ctabgan    0.8996  0.7631  0.9452         0.8287            0.7070\n"
     ]
    }
   ],
   "source": [
    "print(ml_utility_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08aff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ ML Utility 차이 계산 (baseline = non-augmented)\n",
    "baseline = ml_utility_df[ml_utility_df[\"Method\"] == \"non-augmented\"].iloc[0]\n",
    "\n",
    "for metric in [\"Accuracy\", \"F1\", \"AUC\", \"Class1 Recall\", \"Class1 Precision\"]:\n",
    "    diff_col = f\"{metric} Diff\"\n",
    "    ml_utility_df[diff_col] = ml_utility_df[metric].apply(lambda x: abs(x - baseline[metric]))\n",
    "\n",
    "# ✅ baseline은 차이 0으로 세팅 (가독성)\n",
    "for metric in [\"Accuracy Diff\", \"F1 Diff\", \"AUC Diff\", \"Class1 Recall Diff\", \"Class1 Precision Diff\"]:\n",
    "    ml_utility_df.loc[ml_utility_df[\"Method\"] == \"non-augmented\", metric] = 0.0\n",
    "\n",
    "# ✅ 결과 저장\n",
    "#ml_utility_df.to_csv(\"ml_utility_results_with_diff.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a65e4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Class1 Recall</th>\n",
       "      <th>Class1 Precision</th>\n",
       "      <th>Accuracy Diff</th>\n",
       "      <th>F1 Diff</th>\n",
       "      <th>AUC Diff</th>\n",
       "      <th>Class1 Recall Diff</th>\n",
       "      <th>Class1 Precision Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non-augmented</td>\n",
       "      <td>0.8840</td>\n",
       "      <td>0.7540</td>\n",
       "      <td>0.9529</td>\n",
       "      <td>0.9114</td>\n",
       "      <td>0.6430</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMOTE-NC</td>\n",
       "      <td>0.9024</td>\n",
       "      <td>0.7363</td>\n",
       "      <td>0.9435</td>\n",
       "      <td>0.6988</td>\n",
       "      <td>0.7781</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.2126</td>\n",
       "      <td>0.1351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>table-gan</td>\n",
       "      <td>0.8233</td>\n",
       "      <td>0.2204</td>\n",
       "      <td>0.7798</td>\n",
       "      <td>0.1281</td>\n",
       "      <td>0.7914</td>\n",
       "      <td>0.0607</td>\n",
       "      <td>0.5336</td>\n",
       "      <td>0.1731</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>0.1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vae-tablegan</td>\n",
       "      <td>0.8316</td>\n",
       "      <td>0.2403</td>\n",
       "      <td>0.5701</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.0524</td>\n",
       "      <td>0.5137</td>\n",
       "      <td>0.3828</td>\n",
       "      <td>0.7749</td>\n",
       "      <td>0.3566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ctgan</td>\n",
       "      <td>0.9008</td>\n",
       "      <td>0.7605</td>\n",
       "      <td>0.9420</td>\n",
       "      <td>0.8075</td>\n",
       "      <td>0.7187</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1039</td>\n",
       "      <td>0.0757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vae-ctgan</td>\n",
       "      <td>0.8316</td>\n",
       "      <td>0.2403</td>\n",
       "      <td>0.5701</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.0524</td>\n",
       "      <td>0.5137</td>\n",
       "      <td>0.3828</td>\n",
       "      <td>0.7749</td>\n",
       "      <td>0.3566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ctabgan</td>\n",
       "      <td>0.8806</td>\n",
       "      <td>0.6174</td>\n",
       "      <td>0.9339</td>\n",
       "      <td>0.4938</td>\n",
       "      <td>0.8236</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.4176</td>\n",
       "      <td>0.1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vae-ctabgan</td>\n",
       "      <td>0.8996</td>\n",
       "      <td>0.7631</td>\n",
       "      <td>0.9452</td>\n",
       "      <td>0.8287</td>\n",
       "      <td>0.7070</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0827</td>\n",
       "      <td>0.0640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Method  Accuracy      F1     AUC  Class1 Recall  Class1 Precision  \\\n",
       "0  non-augmented    0.8840  0.7540  0.9529         0.9114            0.6430   \n",
       "1       SMOTE-NC    0.9024  0.7363  0.9435         0.6988            0.7781   \n",
       "2      table-gan    0.8233  0.2204  0.7798         0.1281            0.7914   \n",
       "3   vae-tablegan    0.8316  0.2403  0.5701         0.1365            0.9996   \n",
       "4          ctgan    0.9008  0.7605  0.9420         0.8075            0.7187   \n",
       "5      vae-ctgan    0.8316  0.2403  0.5701         0.1365            0.9996   \n",
       "6        ctabgan    0.8806  0.6174  0.9339         0.4938            0.8236   \n",
       "7    vae-ctabgan    0.8996  0.7631  0.9452         0.8287            0.7070   \n",
       "\n",
       "   Accuracy Diff  F1 Diff  AUC Diff  Class1 Recall Diff  Class1 Precision Diff  \n",
       "0         0.0000   0.0000    0.0000              0.0000                 0.0000  \n",
       "1         0.0184   0.0177    0.0094              0.2126                 0.1351  \n",
       "2         0.0607   0.5336    0.1731              0.7833                 0.1484  \n",
       "3         0.0524   0.5137    0.3828              0.7749                 0.3566  \n",
       "4         0.0168   0.0065    0.0109              0.1039                 0.0757  \n",
       "5         0.0524   0.5137    0.3828              0.7749                 0.3566  \n",
       "6         0.0034   0.1366    0.0190              0.4176                 0.1806  \n",
       "7         0.0156   0.0091    0.0077              0.0827                 0.0640  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_utility_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f80aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\\nfrom scipy.spatial.distance import jensenshannon\\nfrom scipy.stats import wasserstein_distance, pearsonr\\nimport numpy as np\\nimport pandas as pd\\n\\ndef compute_classification_metrics(y_true, y_pred_proba):\\n    y_pred = (y_pred_proba >= 0.5).astype(int)\\n    return {\\n        \"accuracy\": accuracy_score(y_true, y_pred),\\n        \"f1_score\": f1_score(y_true, y_pred),\\n        \"auc\": roc_auc_score(y_true, y_pred_proba)\\n    }\\n\\ndef compute_jsd(p, q):\\n    p = np.clip(p, 1e-10, 1)\\n    q = np.clip(q, 1e-10, 1)\\n    return jensenshannon(p, q)**2  # Square to match traditional JSD\\n\\ndef compute_stat_similarity(real, synth):\\n    jsd = np.mean([\\n        compute_jsd(real[col].value_counts(normalize=True).reindex(index=synth[col].value_counts().index, fill_value=0).values,\\n                    synth[col].value_counts(normalize=True).reindex(index=synth[col].value_counts().index, fill_value=0).values)\\n        for col in real.columns\\n    ])\\n\\n    wd = np.mean([\\n        wasserstein_distance(real[col], synth[col]) for col in real.select_dtypes(include=[np.number]).columns\\n    ])\\n\\n    corr_diff = np.linalg.norm(real.corr().values - synth.corr().values)\\n    return jsd, wd, corr_diff\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.stats import wasserstein_distance, pearsonr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_classification_metrics(y_true, y_pred_proba):\n",
    "    y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1_score\": f1_score(y_true, y_pred),\n",
    "        \"auc\": roc_auc_score(y_true, y_pred_proba)\n",
    "    }\n",
    "\n",
    "def compute_jsd(p, q):\n",
    "    p = np.clip(p, 1e-10, 1)\n",
    "    q = np.clip(q, 1e-10, 1)\n",
    "    return jensenshannon(p, q)**2  # Square to match traditional JSD\n",
    "\n",
    "def compute_stat_similarity(real, synth):\n",
    "    jsd = np.mean([\n",
    "        compute_jsd(real[col].value_counts(normalize=True).reindex(index=synth[col].value_counts().index, fill_value=0).values,\n",
    "                    synth[col].value_counts(normalize=True).reindex(index=synth[col].value_counts().index, fill_value=0).values)\n",
    "        for col in real.columns\n",
    "    ])\n",
    "\n",
    "    wd = np.mean([\n",
    "        wasserstein_distance(real[col], synth[col]) for col in real.select_dtypes(include=[np.number]).columns\n",
    "    ])\n",
    "\n",
    "    corr_diff = np.linalg.norm(real.corr().values - synth.corr().values)\n",
    "    return jsd, wd, corr_diff\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CTGAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
