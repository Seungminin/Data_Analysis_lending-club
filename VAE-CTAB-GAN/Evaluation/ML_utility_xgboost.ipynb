{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c3d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler,OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, log_loss\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch \n",
    "import os\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "662cad1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c7e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load original data\n",
    "data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/VAE-CTAB-GAN/Real_Datasets/train_category.csv\"\n",
    "data = pd.read_csv(data_path, low_memory=False)\n",
    "\n",
    "##load test data\n",
    "test_data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/VAE-CTAB-GAN/Real_Datasets/test_category.csv\"\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "data_0 = data[data['loan_status']==0]\n",
    "data_0_sampled = data_0.sample(540000,random_state=42)\n",
    "\n",
    "\"\"\"label1_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/VAE-CTAB-GAN/Real_Datasets/train_category_1.csv\"\n",
    "label1 = pd.read_csv(label1_path, low_memory=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b985234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data.drop(columns='loan_status')\n",
    "data_y = data[['loan_status']]\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_under, y_under = rus.fit_resample(data_x, data_y)\n",
    "\n",
    "data_base = pd.concat([X_under,y_under], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39dd779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep_features = ['grade', 'term_months', 'total_pymnt', 'total_pymnt_inv','total_il_high_credit_limit', 'loan_amnt']\n",
    "keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "\n",
    "data_classification = data_base.copy()\n",
    "test_classification = test_data.copy()\n",
    "\n",
    "data_classification = data_classification.drop(columns = keep_features)\n",
    "test_classification = test_classification.drop(columns = keep_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f806c51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Encoding 완료! 결과 shape: (435578, 35)\n"
     ]
    }
   ],
   "source": [
    "## data Encoding\n",
    "Labelencoding_features = ['term_months', 'sub_grade']\n",
    "onehot_features = ['debt_settlement_flag', 'home_ownership', 'purpose']\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "label_encoders = {}\n",
    "for col in Labelencoding_features:\n",
    "    le = LabelEncoder()\n",
    "    data_classification[col] = le.fit_transform(data_classification[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# One-Hot Encoding\n",
    "onehot_encoded = onehot_encoder.fit_transform(data_classification[onehot_features])\n",
    "onehot_encoded_df = pd.DataFrame(\n",
    "    onehot_encoded, \n",
    "    columns=onehot_encoder.get_feature_names_out(onehot_features),\n",
    "    index=data_classification.index\n",
    ")\n",
    "\n",
    "# Merge\n",
    "data_classification.drop(columns=onehot_features, inplace=True)\n",
    "data_classification = pd.concat([data_classification, onehot_encoded_df], axis=1)\n",
    "\n",
    "print(\"✅ Encoding 완료! 결과 shape:\", data_classification.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a9a604c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 테스트 데이터 인코딩 완료! 결과 shape: (744306, 35)\n"
     ]
    }
   ],
   "source": [
    "##Test data encoding\n",
    "for col in Labelencoding_features:\n",
    "    le = label_encoders[col]\n",
    "    test_classification[col] = le.transform(test_classification[col])\n",
    "\n",
    "# One-Hot Encoding (train에서 fit된 onehot_encoder 재사용)\n",
    "onehot_encoded_test = onehot_encoder.transform(test_classification[onehot_features])\n",
    "onehot_encoded_test_df = pd.DataFrame(\n",
    "    onehot_encoded_test,\n",
    "    columns=onehot_encoder.get_feature_names_out(onehot_features),\n",
    "    index=test_classification.index\n",
    ")\n",
    "\n",
    "# Merge\n",
    "test_classification.drop(columns=onehot_features, inplace=True)\n",
    "test_classification = pd.concat([test_classification, onehot_encoded_test_df], axis=1)\n",
    "\n",
    "print(\"✅ 테스트 데이터 인코딩 완료! 결과 shape:\", test_classification.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03f43049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features(df, label_encoders, onehot_encoder, label_cols, onehot_cols):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Label Encoding\n",
    "    for col in label_cols:\n",
    "        le = label_encoders[col]\n",
    "        df[col] = le.transform(df[col])\n",
    "\n",
    "    # One-Hot Encoding\n",
    "    onehot_encoded = onehot_encoder.transform(df[onehot_cols])\n",
    "    onehot_df = pd.DataFrame(\n",
    "        onehot_encoded, \n",
    "        columns=onehot_encoder.get_feature_names_out(onehot_cols),\n",
    "        index=df.index\n",
    "    )\n",
    "\n",
    "    df.drop(columns=onehot_cols, inplace=True)\n",
    "    df = pd.concat([df, onehot_df], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0db3b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "def ml_utility(model, X_test, y_test, method):\n",
    "    results = []\n",
    "\n",
    "    if method == \"non-augmented\":\n",
    "        X_train = data_classification.drop(columns='loan_status')\n",
    "        y_train = data_classification[['loan_status']]\n",
    "\n",
    "\n",
    "    elif method == 'SMOTE-NC':\n",
    "        print(\"smote-nc\")\n",
    "        smote_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/base/smote-nc.csv\"\n",
    "        smote_data = pd.read_csv(smote_path)\n",
    "        ##합성 데이터와 합치기\n",
    "        combined = pd.concat([data_0_sampled, smote_data], axis=0).sample(frac=1, random_state=42)\n",
    "\n",
    "        drop_cols = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt', 'funded_amnt']\n",
    "        combined = combined.drop(columns=drop_cols)\n",
    "        combined['term_months'] = combined['term_months'].apply(lambda x: 36 if abs(x - 36) < abs(x - 60) else 60)\n",
    "        combined = encode_features(combined, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        X_train = combined.drop(columns='loan_status')\n",
    "        y_train = combined[['loan_status']]\n",
    "        \n",
    "    else:\n",
    "        fake_base = {\n",
    "            'table-gan': 'tablegan/tablegan.csv',\n",
    "            'vae-tablegan': 'tablegan/vae-tablegan.csv',\n",
    "            'ctgan': 'ctgan/ctgan.csv',\n",
    "            'vae-ctgan': 'ctgan/vae-ctgan.csv',\n",
    "            'ctabgan': 'ctabgan/ctabgan.csv',\n",
    "            'vae-ctabgan': 'ctabgan/vae-ctabgan.csv'\n",
    "        }\n",
    "\n",
    "        if method not in fake_base:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "        print(f\"{method}\")\n",
    "        fake_path = f\"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/{fake_base[method]}\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1  # 모든 fake는 default\n",
    "            \n",
    "        combined = pd.concat([data_0_sampled, fake], axis=0).sample(frac=1, random_state=42)\n",
    "        \n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt', 'funded_amnt']\n",
    "        fake = combined.drop(columns=keep_features)\n",
    "        fake['term_months'] = fake['term_months'].apply(lambda x: 36 if abs(x - 36) < abs(x - 60) else 60)\n",
    "        fake = encode_features(fake, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        X_train = fake.drop(columns='loan_status')\n",
    "        y_train = fake[['loan_status']]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    results.append({\n",
    "        \"Method\": method,\n",
    "        \"Accuracy\": round(accuracy_score(y_test, y_pred), 4),\n",
    "        \"F1\": round(f1_score(y_test, y_pred), 4),\n",
    "        \"AUC\": round(roc_auc_score(y_test, y_proba), 4),\n",
    "        \"Class1 Recall\": round(report[\"1\"][\"recall\"], 4),\n",
    "        \"Class1 Precision\": round(report[\"1\"][\"precision\"], 4)\n",
    "    })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b31ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  12%|█▎        | 1/8 [00:01<00:12,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smote-nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  25%|██▌       | 2/8 [00:06<00:20,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  38%|███▊      | 3/8 [00:10<00:18,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  50%|█████     | 4/8 [00:14<00:15,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  62%|██████▎   | 5/8 [00:19<00:12,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  75%|███████▌  | 6/8 [00:23<00:08,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  88%|████████▊ | 7/8 [00:28<00:04,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods: 100%|██████████| 8/8 [00:32<00:00,  4.03s/it]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "methods = [\n",
    "    \"non-augmented\", \"SMOTE-NC\",\n",
    "    \"table-gan\", \"vae-tablegan\",\n",
    "    \"ctgan\", \"vae-ctgan\",\n",
    "    \"ctabgan\", \"vae-ctabgan\",\n",
    "]\n",
    "\n",
    "X_test = test_classification.drop(columns='loan_status')\n",
    "y_test = test_classification['loan_status']\n",
    "\n",
    "# 전체 결과 저장용 DataFrame\n",
    "ml_utility_df = pd.DataFrame()\n",
    "\n",
    "for method in tqdm(methods, desc=\"Methods\"):\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.01,\n",
    "        objective='binary:logistic',\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42,\n",
    "        verbosity=0  # verbose=False를 의미함\n",
    "    )\n",
    "\n",
    "    result_table = ml_utility(model, X_test, y_test, method)  # result_table: list of dict\n",
    "    ml_utility_df = pd.concat([ml_utility_df, pd.DataFrame(result_table)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f0f9c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Method  Accuracy      F1     AUC  Class1 Recall  Class1 Precision\n",
      "0  non-augmented    0.8754  0.7415  0.9480         0.9162            0.6228\n",
      "1       SMOTE-NC    0.8815  0.7380  0.9304         0.8556            0.6488\n",
      "2      table-gan    0.8366  0.3679  0.5752         0.2438            0.7495\n",
      "3   vae-tablegan    0.8323  0.2460  0.5701         0.1403            0.9996\n",
      "4          ctgan    0.8726  0.7347  0.9376         0.9045            0.6185\n",
      "5      vae-ctgan    0.8323  0.2460  0.5701         0.1403            0.9996\n",
      "6        ctabgan    0.8933  0.7426  0.9337         0.7887            0.7015\n",
      "7    vae-ctabgan    0.8883  0.7566  0.9456         0.8901            0.6580\n"
     ]
    }
   ],
   "source": [
    "print(ml_utility_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d08aff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ ML Utility 차이 계산 (baseline = non-augmented)\n",
    "baseline = ml_utility_df[ml_utility_df[\"Method\"] == \"non-augmented\"].iloc[0]\n",
    "\n",
    "for metric in [\"Accuracy\", \"F1\", \"AUC\", \"Class1 Recall\", \"Class1 Precision\"]:\n",
    "    diff_col = f\"{metric} Diff\"\n",
    "    ml_utility_df[diff_col] = ml_utility_df[metric].apply(lambda x: abs(x - baseline[metric]))\n",
    "\n",
    "# ✅ baseline은 차이 0으로 세팅 (가독성)\n",
    "for metric in [\"Accuracy Diff\", \"F1 Diff\", \"AUC Diff\", \"Class1 Recall Diff\", \"Class1 Precision Diff\"]:\n",
    "    ml_utility_df.loc[ml_utility_df[\"Method\"] == \"non-augmented\", metric] = 0.0\n",
    "\n",
    "# ✅ 결과 저장\n",
    "#ml_utility_df.to_csv(\"ml_utility_results_with_diff.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a65e4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Class1 Recall</th>\n",
       "      <th>Class1 Precision</th>\n",
       "      <th>Accuracy Diff</th>\n",
       "      <th>F1 Diff</th>\n",
       "      <th>AUC Diff</th>\n",
       "      <th>Class1 Recall Diff</th>\n",
       "      <th>Class1 Precision Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non-augmented</td>\n",
       "      <td>0.8754</td>\n",
       "      <td>0.7415</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.6228</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMOTE-NC</td>\n",
       "      <td>0.8815</td>\n",
       "      <td>0.7380</td>\n",
       "      <td>0.9304</td>\n",
       "      <td>0.8556</td>\n",
       "      <td>0.6488</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.0606</td>\n",
       "      <td>0.0260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>table-gan</td>\n",
       "      <td>0.8366</td>\n",
       "      <td>0.3679</td>\n",
       "      <td>0.5752</td>\n",
       "      <td>0.2438</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.3728</td>\n",
       "      <td>0.6724</td>\n",
       "      <td>0.1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vae-tablegan</td>\n",
       "      <td>0.8323</td>\n",
       "      <td>0.2460</td>\n",
       "      <td>0.5701</td>\n",
       "      <td>0.1403</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.0431</td>\n",
       "      <td>0.4955</td>\n",
       "      <td>0.3779</td>\n",
       "      <td>0.7759</td>\n",
       "      <td>0.3768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ctgan</td>\n",
       "      <td>0.8726</td>\n",
       "      <td>0.7347</td>\n",
       "      <td>0.9376</td>\n",
       "      <td>0.9045</td>\n",
       "      <td>0.6185</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vae-ctgan</td>\n",
       "      <td>0.8323</td>\n",
       "      <td>0.2460</td>\n",
       "      <td>0.5701</td>\n",
       "      <td>0.1403</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.0431</td>\n",
       "      <td>0.4955</td>\n",
       "      <td>0.3779</td>\n",
       "      <td>0.7759</td>\n",
       "      <td>0.3768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ctabgan</td>\n",
       "      <td>0.8933</td>\n",
       "      <td>0.7426</td>\n",
       "      <td>0.9337</td>\n",
       "      <td>0.7887</td>\n",
       "      <td>0.7015</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>0.0787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vae-ctabgan</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>0.7566</td>\n",
       "      <td>0.9456</td>\n",
       "      <td>0.8901</td>\n",
       "      <td>0.6580</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.0352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Method  Accuracy      F1     AUC  Class1 Recall  Class1 Precision  \\\n",
       "0  non-augmented    0.8754  0.7415  0.9480         0.9162            0.6228   \n",
       "1       SMOTE-NC    0.8815  0.7380  0.9304         0.8556            0.6488   \n",
       "2      table-gan    0.8366  0.3679  0.5752         0.2438            0.7495   \n",
       "3   vae-tablegan    0.8323  0.2460  0.5701         0.1403            0.9996   \n",
       "4          ctgan    0.8726  0.7347  0.9376         0.9045            0.6185   \n",
       "5      vae-ctgan    0.8323  0.2460  0.5701         0.1403            0.9996   \n",
       "6        ctabgan    0.8933  0.7426  0.9337         0.7887            0.7015   \n",
       "7    vae-ctabgan    0.8883  0.7566  0.9456         0.8901            0.6580   \n",
       "\n",
       "   Accuracy Diff  F1 Diff  AUC Diff  Class1 Recall Diff  Class1 Precision Diff  \n",
       "0         0.0000   0.0000    0.0000              0.0000                 0.0000  \n",
       "1         0.0061   0.0035    0.0176              0.0606                 0.0260  \n",
       "2         0.0388   0.3736    0.3728              0.6724                 0.1267  \n",
       "3         0.0431   0.4955    0.3779              0.7759                 0.3768  \n",
       "4         0.0028   0.0068    0.0104              0.0117                 0.0043  \n",
       "5         0.0431   0.4955    0.3779              0.7759                 0.3768  \n",
       "6         0.0179   0.0011    0.0143              0.1275                 0.0787  \n",
       "7         0.0129   0.0151    0.0024              0.0261                 0.0352  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_utility_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f80aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.stats import wasserstein_distance, pearsonr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_classification_metrics(y_true, y_pred_proba):\n",
    "    y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1_score\": f1_score(y_true, y_pred),\n",
    "        \"auc\": roc_auc_score(y_true, y_pred_proba)\n",
    "    }\n",
    "\n",
    "def compute_jsd(p, q):\n",
    "    p = np.clip(p, 1e-10, 1)\n",
    "    q = np.clip(q, 1e-10, 1)\n",
    "    return jensenshannon(p, q)**2  # Square to match traditional JSD\n",
    "\n",
    "def compute_stat_similarity(real, synth):\n",
    "    jsd = np.mean([\n",
    "        compute_jsd(real[col].value_counts(normalize=True).reindex(index=synth[col].value_counts().index, fill_value=0).values,\n",
    "                    synth[col].value_counts(normalize=True).reindex(index=synth[col].value_counts().index, fill_value=0).values)\n",
    "        for col in real.columns\n",
    "    ])\n",
    "\n",
    "    wd = np.mean([\n",
    "        wasserstein_distance(real[col], synth[col]) for col in real.select_dtypes(include=[np.number]).columns\n",
    "    ])\n",
    "\n",
    "    corr_diff = np.linalg.norm(real.corr().values - synth.corr().values)\n",
    "    return jsd, wd, corr_diff\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CTGAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
