{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d5d28ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler,OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, log_loss\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch \n",
    "import os\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c669424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55fca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/base/train_category.csv\"\n",
    "data = pd.read_csv(data_path, low_memory=False)\n",
    "\n",
    "test_data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/base/test_category.csv\"\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ed38855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep_features = ['grade', 'term_months', 'total_pymnt', 'total_pymnt_inv','total_il_high_credit_limit', 'loan_amnt']\n",
    "keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "\n",
    "data_classification = data.copy()\n",
    "test_classification = test_data.copy()\n",
    "\n",
    "data_classification = data_classification.drop(columns = keep_features)\n",
    "test_classification = test_classification.drop(columns = keep_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d4173de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Encoding 완료! 결과 shape: (1116458, 35)\n"
     ]
    }
   ],
   "source": [
    "## data Encoding\n",
    "Labelencoding_features = ['term_months', 'sub_grade']\n",
    "onehot_features = ['debt_settlement_flag', 'home_ownership', 'purpose']\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "label_encoders = {}\n",
    "for col in Labelencoding_features:\n",
    "    le = LabelEncoder()\n",
    "    data_classification[col] = le.fit_transform(data_classification[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# One-Hot Encoding\n",
    "onehot_encoded = onehot_encoder.fit_transform(data_classification[onehot_features])\n",
    "onehot_encoded_df = pd.DataFrame(\n",
    "    onehot_encoded, \n",
    "    columns=onehot_encoder.get_feature_names_out(onehot_features),\n",
    "    index=data_classification.index\n",
    ")\n",
    "\n",
    "# Merge\n",
    "data_classification.drop(columns=onehot_features, inplace=True)\n",
    "data_classification = pd.concat([data_classification, onehot_encoded_df], axis=1)\n",
    "\n",
    "print(\"✅ Encoding 완료! 결과 shape:\", data_classification.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "947c52a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 테스트 데이터 인코딩 완료! 결과 shape: (744306, 35)\n"
     ]
    }
   ],
   "source": [
    "##Test data encoding\n",
    "for col in Labelencoding_features:\n",
    "    le = label_encoders[col]\n",
    "    test_classification[col] = le.transform(test_classification[col])\n",
    "\n",
    "# One-Hot Encoding (train에서 fit된 onehot_encoder 재사용)\n",
    "onehot_encoded_test = onehot_encoder.transform(test_classification[onehot_features])\n",
    "onehot_encoded_test_df = pd.DataFrame(\n",
    "    onehot_encoded_test,\n",
    "    columns=onehot_encoder.get_feature_names_out(onehot_features),\n",
    "    index=test_classification.index\n",
    ")\n",
    "\n",
    "# Merge\n",
    "test_classification.drop(columns=onehot_features, inplace=True)\n",
    "test_classification = pd.concat([test_classification, onehot_encoded_test_df], axis=1)\n",
    "\n",
    "print(\"✅ 테스트 데이터 인코딩 완료! 결과 shape:\", test_classification.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8641974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features(df, label_encoders, onehot_encoder, label_cols, onehot_cols):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Label Encoding\n",
    "    for col in label_cols:\n",
    "        le = label_encoders[col]\n",
    "        df[col] = le.transform(df[col])\n",
    "\n",
    "    # One-Hot Encoding\n",
    "    onehot_encoded = onehot_encoder.transform(df[onehot_cols])\n",
    "    onehot_df = pd.DataFrame(\n",
    "        onehot_encoded, \n",
    "        columns=onehot_encoder.get_feature_names_out(onehot_cols),\n",
    "        index=df.index\n",
    "    )\n",
    "\n",
    "    df.drop(columns=onehot_cols, inplace=True)\n",
    "    df = pd.concat([df, onehot_df], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12424918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def load_data_by_method(method):\n",
    "    test_data = test_classification\n",
    "    X_test = test_data.drop(columns='loan_status')\n",
    "    y_test = test_data[['loan_status']]\n",
    "\n",
    "    base_data = data_classification\n",
    "\n",
    "    if method == 'Base':\n",
    "        X_train = base_data.drop(columns='loan_status')\n",
    "        y_train = base_data[['loan_status']]\n",
    "\n",
    "    elif method == 'Undersampling':\n",
    "        data_x = base_data.drop(columns='loan_status')\n",
    "        data_y = base_data[['loan_status']]\n",
    "        X_temp, _, y_temp, _ = train_test_split(data_x, data_y, test_size=0.13, random_state=42, stratify=data_y)\n",
    "        rus = RandomUnderSampler(random_state=42)\n",
    "        X_under, y_under = rus.fit_resample(X_temp, y_temp)\n",
    "        X_train, y_train = X_under, y_under\n",
    "\n",
    "    elif method == 'SMOTE-NC':\n",
    "        smote_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/smotenc/smotenc_data.csv\"\n",
    "        smote_data = pd.read_csv(smote_path)\n",
    "        drop_cols = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt', 'funded_amnt']\n",
    "        smote_data = smote_data.drop(columns=drop_cols)\n",
    "        smote_data = encode_features(smote_data, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        X_train = smote_data.drop(columns='loan_status')\n",
    "        y_train = smote_data[['loan_status']]\n",
    "\n",
    "    else:\n",
    "        fake_base = {\n",
    "            'table-gan': 'tablegan/tablegan.csv',\n",
    "            'Smotified-tablegan': 'tablegan/smotified-tablegan.csv',\n",
    "            'vae-tablegan': 'tablegan/vae-tablegan.csv',\n",
    "            'ctgan': 'ctgan/ctgan.csv',\n",
    "            'smotified-ctgan': 'ctgan/smotified-ctgan.csv',\n",
    "            'vae-ctgan': 'ctgan/vae-ctgan.csv',\n",
    "            'smotified-vae-ctgan': 'ctgan/smotified-vae-ctgan.csv',\n",
    "            'ctabgan': 'ctabgan/ctabgan.csv',\n",
    "            'smotified-ctabgan': 'ctabgan/smotified_ctabgan.csv',\n",
    "            'vae-ctabgan': 'ctabgan/vae-ctabgan.csv',\n",
    "            'smotified-vae-ctabgan': 'ctabgan/smotified-vae-ctabgan.csv'\n",
    "        }\n",
    "\n",
    "        if method not in fake_base:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "        fake_path = f\"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/{fake_base[method]}\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1  # 모든 fake는 default\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt', 'funded_amnt']\n",
    "        fake = fake.drop(columns=keep_features)\n",
    "        fake['term_months'] = fake['term_months'].apply(lambda x: 36 if abs(x - 36) < abs(x - 60) else 60)\n",
    "        fake = encode_features(fake, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        base_x = base_data.drop(columns='loan_status')\n",
    "        base_y = base_data[['loan_status']]\n",
    "        X_base, _, y_base, _ = train_test_split(base_x, base_y, test_size=0.2, stratify=base_y, random_state=42)\n",
    "        train_real = pd.concat([X_base, y_base], axis=1)\n",
    "        train_total = pd.concat([train_real, fake])\n",
    "        train_total = shuffle(train_total, random_state=42)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b77285e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_with_sharpe_top = []\n",
    "\n",
    "summary_with_grade_top = []\n",
    "\n",
    "def linear_portfolio_top(Method, top_10_indices):\n",
    "    selected = test_data.loc[top_10_indices.index].copy()\n",
    "    returns = (selected['total_pymnt_inv'] - selected['funded_amnt']) / selected['funded_amnt']\n",
    "    \n",
    "    avg_return = returns.mean()\n",
    "    std_return = returns.std()\n",
    "    sharpe_ratio = avg_return / std_return if std_return != 0 else np.nan\n",
    "\n",
    "    summary_with_sharpe_top.append({\n",
    "        'Method': Method,\n",
    "        'Average Return': avg_return * 100,\n",
    "        'Std Dev': std_return,\n",
    "        'Sharpe Ratio': sharpe_ratio\n",
    "    }) \n",
    "\n",
    "    A_count = len(selected[selected['grade'] == 'A'])\n",
    "    B_count = len(selected[selected['grade'] == 'B'])\n",
    "    C_count = len(selected[selected['grade'] == 'C'])\n",
    "    D_count = len(selected[selected['grade'] == 'D'])\n",
    "    E_count = len(selected[selected['grade'] == 'E'])\n",
    "    F_G_count = len(selected[selected['grade'] == 'F']) + len(selected[selected['grade'] == 'G'])\n",
    "\n",
    "    summary_with_grade_top.append({\n",
    "        'Method': Method,\n",
    "        'A': A_count,\n",
    "        'B': B_count,\n",
    "        'C': C_count,\n",
    "        'D': D_count,\n",
    "        'E': E_count,\n",
    "        'F+G': F_G_count,\n",
    "        'Total': len(selected)\n",
    "    }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b609c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "##상위 10% 투자\n",
    "from imblearn.over_sampling import SMOTE\n",
    "drop2 = ['loan_status', 'return']\n",
    "\n",
    "def select_fully_paid(y_pred, method):\n",
    "    scaler = StandardScaler()\n",
    "    reg = LinearRegression()\n",
    "\n",
    "    fully_paid_indices = (y_pred == 0)\n",
    "    test_regression = test_data[fully_paid_indices]\n",
    "    test_regression['return'] = (test_regression['total_pymnt_inv'] - test_regression['funded_amnt'])/test_regression['funded_amnt']\n",
    "\n",
    "    train_regression = data.copy()\n",
    "\n",
    "    if method == 'Base':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        data_x = train_regression.drop(columns='return')\n",
    "        data_y = train_regression[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "        return method, top_10_percent\n",
    "    \n",
    "    elif method == 'Undersampling':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['loan_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        X_train = train_regression.drop(columns='loan_status')\n",
    "        y_train = train_regression[['loan_status']]\n",
    "\n",
    "        undersampler = RandomUnderSampler(random_state=42)\n",
    "        X_under, y_under = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        data_under = pd.concat([pd.DataFrame(X_under, columns=X_train.columns), pd.DataFrame(y_under, columns=['loan_status'])], axis=1)\n",
    "\n",
    "        data_x = data_under.drop(columns=drop2)  \n",
    "        data_y = data_under[['return']]  \n",
    "\n",
    "        test_x = test_regression.drop(columns = drop2)\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent\n",
    "    \n",
    "    elif method == 'SMOTE-NC':\n",
    "        smote_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/smotenc/smotenc_data.csv\"\n",
    "        data_smote = pd.read_csv(smote_path)\n",
    "        \n",
    "        data_smote['return'] = (data_smote['total_pymnt_inv'] - data_smote['funded_amnt'])/data_smote['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "\n",
    "        train_regression = data_smote.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        X_train = train_regression.drop(columns='return')\n",
    "        y_train = train_regression[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        #y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent\n",
    "    \n",
    "    elif method == 'table-gan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/tablegan/tablegan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent\n",
    "        \n",
    "    elif method == 'Smotified-tablegan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/tablegan/smotified-tablegan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    \n",
    "    elif method == 'vae-tablegan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/tablegan/vae-tablegan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    \n",
    "    elif method == 'ctgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    \n",
    "    elif method == 'smotified-ctgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/smotified-ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    \n",
    "    elif method == 'vae-ctgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/vae-ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    \n",
    "    elif method == 'smotified-vae-ctgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/smotified-vae-ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        \n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "\n",
    "    elif method == 'ctabgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        \n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    \n",
    "    elif method == 'smotified-ctabgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/smotified_ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        \n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "\n",
    "    elif method == 'vae-ctabgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/vae-ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        \n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    \n",
    "    elif method == 'smotified-vae-ctabgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/smotified-vae-ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        \n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ad8ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "classification_metrics_summary = []\n",
    "\n",
    "def return_evaluation(model, data_x, data_y, X_test, y_test, method):\n",
    "    print(f\"Preprocessing method : {method}\")\n",
    "\n",
    "    if method == 'Base':\n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2,\n",
    "                                                           random_state=42, stratify=data_y)\n",
    "        model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "\n",
    "    elif method == 'Undersampling':\n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.13, random_state=42, stratify=data_y)\n",
    "        undersampler = RandomUnderSampler(random_state=42)\n",
    "        X_under, y_under = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        data_under = pd.concat([pd.DataFrame(X_under, columns=data_x.columns), pd.DataFrame(y_under, columns=['loan_status'])], axis=1)\n",
    "        X_train = data_under.drop(columns=['loan_status'])  # Feature (입력 데이터)\n",
    "        y_train = data_under[['loan_status']]  # Target (타겟 변수)\n",
    "\n",
    "        model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    elif method == 'SMOTE-NC':\n",
    "        smote_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/smotenc/smotenc_data.csv\"\n",
    "        data_smote = pd.read_csv(smote_path)\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        data_smote_classification = data_smote.copy()\n",
    "        data_smote_classification = data_smote_classification.drop(columns = keep_features)\n",
    "\n",
    "        data_smote_classification = encode_features(data_smote_classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        data_x = data_smote_classification.drop(columns='loan_status') \n",
    "        data_y = data_smote_classification[['loan_status']]\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, random_state=42, stratify=data_y)\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'table-gan':\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/tablegan/tablegan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "        \n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, random_state=42, stratify=data_y)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total, random_state=42)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        \n",
    "    elif method == 'Smotified-tablegan':\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/tablegan/smotified-tablegan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'vae-tablegan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/tablegan/vae-tablegan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'ctgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'smotified-ctgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/smotified-ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'vae-ctgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/vae-ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        \n",
    "    elif method == 'smotified-vae-ctgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/smotified-vae-ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'ctabgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'smotified-ctabgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/smotified_ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'vae-ctabgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/vae-ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'smotified-vae-ctabgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/smotified-vae-ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    report = classification_report(\n",
    "        y_test, y_pred,\n",
    "        target_names=[\"Fully Paid\", \"Default\"],\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "    classification_metrics_summary.append({\n",
    "        \"Method\": method,\n",
    "        \"Class 0 Precision\": report[\"Fully Paid\"][\"precision\"],\n",
    "        \"Class 0 Recall\": report[\"Fully Paid\"][\"recall\"],\n",
    "        \"Class 0 F1\": report[\"Fully Paid\"][\"f1-score\"],\n",
    "        \"Class 1 Precision\": report[\"Default\"][\"precision\"],\n",
    "        \"Class 1 Recall\": report[\"Default\"][\"recall\"],\n",
    "        \"Class 1 F1\": report[\"Default\"][\"f1-score\"],\n",
    "        \"Macro Avg F1\": report[\"macro avg\"][\"f1-score\"],\n",
    "        \"Weighted Avg F1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "    })\n",
    "\n",
    "    #10% index뽑기기\n",
    "    Method, top_10_indices = select_fully_paid(y_pred, method)\n",
    "\n",
    "    #portfolio 만들기들기\n",
    "    linear_portfolio_top(Method, top_10_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e721ce1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : Base\n",
      "RMSE: 0.19724239831874127\n",
      "R²: 0.016356161994040885\n",
      "Preprocessing method : Undersampling\n",
      "RMSE: 0.2007067594710921\n",
      "R²: -0.6261143279074499\n",
      "Preprocessing method : SMOTE-NC\n",
      "RMSE: 0.21738932909898348\n",
      "R²: -0.4388215339785775\n",
      "Preprocessing method : table-gan\n",
      "RMSE: 0.22283512191911087\n",
      "R²: -0.2932030258814302\n",
      "Preprocessing method : Smotified-tablegan\n",
      "RMSE: 0.19713295551090343\n",
      "R²: 0.017154648608653456\n",
      "Preprocessing method : vae-tablegan\n",
      "RMSE: 0.1971387760534237\n",
      "R²: 0.016983799504805996\n",
      "Preprocessing method : ctgan\n",
      "RMSE: 0.20422177534639346\n",
      "R²: -0.43840202107602333\n",
      "Preprocessing method : smotified-ctgan\n",
      "RMSE: 0.21388429754420588\n",
      "R²: -0.3493896371125407\n",
      "Preprocessing method : vae-ctgan\n",
      "RMSE: 0.19713396692085047\n",
      "R²: 0.01723221030985289\n",
      "Preprocessing method : smotified-vae-ctgan\n",
      "RMSE: 0.19716577935101962\n",
      "R²: 0.017356745131909657\n",
      "Preprocessing method : ctabgan\n",
      "RMSE: 0.32619192111171824\n",
      "R²: -2.1122779380882974\n",
      "Preprocessing method : smotified-ctabgan\n",
      "RMSE: 0.34087443352269775\n",
      "R²: -2.366097698658735\n",
      "Preprocessing method : vae-ctabgan\n",
      "RMSE: 0.18822574088294117\n",
      "R²: -0.26054386025719833\n",
      "Preprocessing method : smotified-vae-ctabgan\n",
      "RMSE: 0.19326352039242245\n",
      "R²: -0.31167499029177925\n"
     ]
    }
   ],
   "source": [
    "methods = [\n",
    "    'Base', 'Undersampling', 'SMOTE-NC',\n",
    "    'table-gan', 'Smotified-tablegan', 'vae-tablegan',\n",
    "    'ctgan', 'smotified-ctgan', 'vae-ctgan',\n",
    "    'smotified-vae-ctgan', 'ctabgan', 'smotified-ctabgan', 'vae-ctabgan', 'smotified-vae-ctabgan'\n",
    "]\n",
    "\n",
    "X_test = test_classification.drop(columns='loan_status')\n",
    "y_test = test_classification['loan_status']\n",
    "\n",
    "returns_df = pd.DataFrame()\n",
    "\n",
    "for method in methods:\n",
    "    data_x = data_classification.drop(columns='loan_status')\n",
    "    data_y = data_classification['loan_status']\n",
    "\n",
    "    model = LGBMClassifier(\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=500,               \n",
    "        device='cpu',\n",
    "        verbosity=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    return_evaluation(model, data_x, data_y, X_test, y_test, method)\n",
    "\n",
    "#classification 결과\n",
    "classification_metrics_df = pd.DataFrame(classification_metrics_summary)\n",
    "\n",
    "#상위 10% 투자전략\n",
    "returns_with_sharpe_df_top = pd.DataFrame(summary_with_sharpe_top)\n",
    "portfolio_grade_distribution_df_top = pd.DataFrame(summary_with_grade_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f572ebfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Class 0 Precision</th>\n",
       "      <th>Class 0 Recall</th>\n",
       "      <th>Class 0 F1</th>\n",
       "      <th>Class 1 Precision</th>\n",
       "      <th>Class 1 Recall</th>\n",
       "      <th>Class 1 F1</th>\n",
       "      <th>Macro Avg F1</th>\n",
       "      <th>Weighted Avg F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.942686</td>\n",
       "      <td>0.947614</td>\n",
       "      <td>0.945144</td>\n",
       "      <td>0.779072</td>\n",
       "      <td>0.762267</td>\n",
       "      <td>0.770578</td>\n",
       "      <td>0.857861</td>\n",
       "      <td>0.911091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undersampling</td>\n",
       "      <td>0.975915</td>\n",
       "      <td>0.877935</td>\n",
       "      <td>0.924336</td>\n",
       "      <td>0.643858</td>\n",
       "      <td>0.910594</td>\n",
       "      <td>0.754341</td>\n",
       "      <td>0.839338</td>\n",
       "      <td>0.891175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE-NC</td>\n",
       "      <td>0.959110</td>\n",
       "      <td>0.920835</td>\n",
       "      <td>0.939583</td>\n",
       "      <td>0.719523</td>\n",
       "      <td>0.838008</td>\n",
       "      <td>0.774258</td>\n",
       "      <td>0.856921</td>\n",
       "      <td>0.907333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>table-gan</td>\n",
       "      <td>0.945213</td>\n",
       "      <td>0.939414</td>\n",
       "      <td>0.942305</td>\n",
       "      <td>0.756173</td>\n",
       "      <td>0.775318</td>\n",
       "      <td>0.765626</td>\n",
       "      <td>0.853965</td>\n",
       "      <td>0.907840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Smotified-tablegan</td>\n",
       "      <td>0.942771</td>\n",
       "      <td>0.947559</td>\n",
       "      <td>0.945159</td>\n",
       "      <td>0.778978</td>\n",
       "      <td>0.762652</td>\n",
       "      <td>0.770729</td>\n",
       "      <td>0.857944</td>\n",
       "      <td>0.911133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vae-tablegan</td>\n",
       "      <td>0.942809</td>\n",
       "      <td>0.947628</td>\n",
       "      <td>0.945212</td>\n",
       "      <td>0.779237</td>\n",
       "      <td>0.762804</td>\n",
       "      <td>0.770933</td>\n",
       "      <td>0.858073</td>\n",
       "      <td>0.911216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ctgan</td>\n",
       "      <td>0.965957</td>\n",
       "      <td>0.902972</td>\n",
       "      <td>0.933403</td>\n",
       "      <td>0.684511</td>\n",
       "      <td>0.868684</td>\n",
       "      <td>0.765678</td>\n",
       "      <td>0.849541</td>\n",
       "      <td>0.900685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>smotified-ctgan</td>\n",
       "      <td>0.956231</td>\n",
       "      <td>0.926678</td>\n",
       "      <td>0.941223</td>\n",
       "      <td>0.731669</td>\n",
       "      <td>0.824977</td>\n",
       "      <td>0.775526</td>\n",
       "      <td>0.858375</td>\n",
       "      <td>0.908900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vae-ctgan</td>\n",
       "      <td>0.942773</td>\n",
       "      <td>0.947578</td>\n",
       "      <td>0.945169</td>\n",
       "      <td>0.779040</td>\n",
       "      <td>0.762659</td>\n",
       "      <td>0.770763</td>\n",
       "      <td>0.857966</td>\n",
       "      <td>0.911148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>smotified-vae-ctgan</td>\n",
       "      <td>0.942725</td>\n",
       "      <td>0.947529</td>\n",
       "      <td>0.945121</td>\n",
       "      <td>0.778836</td>\n",
       "      <td>0.762459</td>\n",
       "      <td>0.770561</td>\n",
       "      <td>0.857841</td>\n",
       "      <td>0.911070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ctabgan</td>\n",
       "      <td>0.955589</td>\n",
       "      <td>0.927361</td>\n",
       "      <td>0.941264</td>\n",
       "      <td>0.732832</td>\n",
       "      <td>0.822160</td>\n",
       "      <td>0.774930</td>\n",
       "      <td>0.858097</td>\n",
       "      <td>0.908817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>smotified-ctabgan</td>\n",
       "      <td>0.955147</td>\n",
       "      <td>0.927428</td>\n",
       "      <td>0.941084</td>\n",
       "      <td>0.732567</td>\n",
       "      <td>0.820293</td>\n",
       "      <td>0.773952</td>\n",
       "      <td>0.857518</td>\n",
       "      <td>0.908481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vae-ctabgan</td>\n",
       "      <td>0.968902</td>\n",
       "      <td>0.897432</td>\n",
       "      <td>0.931798</td>\n",
       "      <td>0.675529</td>\n",
       "      <td>0.881144</td>\n",
       "      <td>0.764757</td>\n",
       "      <td>0.848278</td>\n",
       "      <td>0.899214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>smotified-vae-ctabgan</td>\n",
       "      <td>0.967609</td>\n",
       "      <td>0.898662</td>\n",
       "      <td>0.931862</td>\n",
       "      <td>0.676856</td>\n",
       "      <td>0.875868</td>\n",
       "      <td>0.763608</td>\n",
       "      <td>0.847735</td>\n",
       "      <td>0.899041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method  Class 0 Precision  Class 0 Recall  Class 0 F1  \\\n",
       "0                    Base           0.942686        0.947614    0.945144   \n",
       "1           Undersampling           0.975915        0.877935    0.924336   \n",
       "2                SMOTE-NC           0.959110        0.920835    0.939583   \n",
       "3               table-gan           0.945213        0.939414    0.942305   \n",
       "4      Smotified-tablegan           0.942771        0.947559    0.945159   \n",
       "5            vae-tablegan           0.942809        0.947628    0.945212   \n",
       "6                   ctgan           0.965957        0.902972    0.933403   \n",
       "7         smotified-ctgan           0.956231        0.926678    0.941223   \n",
       "8               vae-ctgan           0.942773        0.947578    0.945169   \n",
       "9     smotified-vae-ctgan           0.942725        0.947529    0.945121   \n",
       "10                ctabgan           0.955589        0.927361    0.941264   \n",
       "11      smotified-ctabgan           0.955147        0.927428    0.941084   \n",
       "12            vae-ctabgan           0.968902        0.897432    0.931798   \n",
       "13  smotified-vae-ctabgan           0.967609        0.898662    0.931862   \n",
       "\n",
       "    Class 1 Precision  Class 1 Recall  Class 1 F1  Macro Avg F1  \\\n",
       "0            0.779072        0.762267    0.770578      0.857861   \n",
       "1            0.643858        0.910594    0.754341      0.839338   \n",
       "2            0.719523        0.838008    0.774258      0.856921   \n",
       "3            0.756173        0.775318    0.765626      0.853965   \n",
       "4            0.778978        0.762652    0.770729      0.857944   \n",
       "5            0.779237        0.762804    0.770933      0.858073   \n",
       "6            0.684511        0.868684    0.765678      0.849541   \n",
       "7            0.731669        0.824977    0.775526      0.858375   \n",
       "8            0.779040        0.762659    0.770763      0.857966   \n",
       "9            0.778836        0.762459    0.770561      0.857841   \n",
       "10           0.732832        0.822160    0.774930      0.858097   \n",
       "11           0.732567        0.820293    0.773952      0.857518   \n",
       "12           0.675529        0.881144    0.764757      0.848278   \n",
       "13           0.676856        0.875868    0.763608      0.847735   \n",
       "\n",
       "    Weighted Avg F1  \n",
       "0          0.911091  \n",
       "1          0.891175  \n",
       "2          0.907333  \n",
       "3          0.907840  \n",
       "4          0.911133  \n",
       "5          0.911216  \n",
       "6          0.900685  \n",
       "7          0.908900  \n",
       "8          0.911148  \n",
       "9          0.911070  \n",
       "10         0.908817  \n",
       "11         0.908481  \n",
       "12         0.899214  \n",
       "13         0.899041  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_metrics_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a732afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Average Return</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>19.575445</td>\n",
       "      <td>0.158344</td>\n",
       "      <td>1.236261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undersampling</td>\n",
       "      <td>15.333046</td>\n",
       "      <td>0.128179</td>\n",
       "      <td>1.196222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE-NC</td>\n",
       "      <td>15.023782</td>\n",
       "      <td>0.121883</td>\n",
       "      <td>1.232638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>table-gan</td>\n",
       "      <td>14.347957</td>\n",
       "      <td>0.111919</td>\n",
       "      <td>1.281999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Smotified-tablegan</td>\n",
       "      <td>17.024736</td>\n",
       "      <td>0.129163</td>\n",
       "      <td>1.318083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vae-tablegan</td>\n",
       "      <td>17.024320</td>\n",
       "      <td>0.129162</td>\n",
       "      <td>1.318059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ctgan</td>\n",
       "      <td>15.276493</td>\n",
       "      <td>0.117079</td>\n",
       "      <td>1.304807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>smotified-ctgan</td>\n",
       "      <td>15.069701</td>\n",
       "      <td>0.113847</td>\n",
       "      <td>1.323685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vae-ctgan</td>\n",
       "      <td>17.024144</td>\n",
       "      <td>0.129162</td>\n",
       "      <td>1.318042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>smotified-vae-ctgan</td>\n",
       "      <td>17.024837</td>\n",
       "      <td>0.129160</td>\n",
       "      <td>1.318117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ctabgan</td>\n",
       "      <td>16.238926</td>\n",
       "      <td>0.196085</td>\n",
       "      <td>0.828156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>smotified-ctabgan</td>\n",
       "      <td>8.537567</td>\n",
       "      <td>0.091201</td>\n",
       "      <td>0.936131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vae-ctabgan</td>\n",
       "      <td>16.149877</td>\n",
       "      <td>0.124779</td>\n",
       "      <td>1.294274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>smotified-vae-ctabgan</td>\n",
       "      <td>15.154592</td>\n",
       "      <td>0.120961</td>\n",
       "      <td>1.252853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method  Average Return   Std Dev  Sharpe Ratio\n",
       "0                    Base       19.575445  0.158344      1.236261\n",
       "1           Undersampling       15.333046  0.128179      1.196222\n",
       "2                SMOTE-NC       15.023782  0.121883      1.232638\n",
       "3               table-gan       14.347957  0.111919      1.281999\n",
       "4      Smotified-tablegan       17.024736  0.129163      1.318083\n",
       "5            vae-tablegan       17.024320  0.129162      1.318059\n",
       "6                   ctgan       15.276493  0.117079      1.304807\n",
       "7         smotified-ctgan       15.069701  0.113847      1.323685\n",
       "8               vae-ctgan       17.024144  0.129162      1.318042\n",
       "9     smotified-vae-ctgan       17.024837  0.129160      1.318117\n",
       "10                ctabgan       16.238926  0.196085      0.828156\n",
       "11      smotified-ctabgan        8.537567  0.091201      0.936131\n",
       "12            vae-ctabgan       16.149877  0.124779      1.294274\n",
       "13  smotified-vae-ctabgan       15.154592  0.120961      1.252853"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_with_sharpe_df_top.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cc00db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F+G</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>7574</td>\n",
       "      <td>15503</td>\n",
       "      <td>17370</td>\n",
       "      <td>10098</td>\n",
       "      <td>6378</td>\n",
       "      <td>3301</td>\n",
       "      <td>60224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undersampling</td>\n",
       "      <td>16009</td>\n",
       "      <td>16708</td>\n",
       "      <td>12374</td>\n",
       "      <td>5232</td>\n",
       "      <td>2518</td>\n",
       "      <td>1055</td>\n",
       "      <td>53896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE-NC</td>\n",
       "      <td>18192</td>\n",
       "      <td>18000</td>\n",
       "      <td>12751</td>\n",
       "      <td>5565</td>\n",
       "      <td>2182</td>\n",
       "      <td>830</td>\n",
       "      <td>57520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>table-gan</td>\n",
       "      <td>16045</td>\n",
       "      <td>18981</td>\n",
       "      <td>14267</td>\n",
       "      <td>7125</td>\n",
       "      <td>2402</td>\n",
       "      <td>723</td>\n",
       "      <td>59543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Smotified-tablegan</td>\n",
       "      <td>12876</td>\n",
       "      <td>18749</td>\n",
       "      <td>15919</td>\n",
       "      <td>7967</td>\n",
       "      <td>3363</td>\n",
       "      <td>1341</td>\n",
       "      <td>60215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vae-tablegan</td>\n",
       "      <td>12876</td>\n",
       "      <td>18750</td>\n",
       "      <td>15920</td>\n",
       "      <td>7967</td>\n",
       "      <td>3363</td>\n",
       "      <td>1341</td>\n",
       "      <td>60217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ctgan</td>\n",
       "      <td>16589</td>\n",
       "      <td>18424</td>\n",
       "      <td>12983</td>\n",
       "      <td>5293</td>\n",
       "      <td>2019</td>\n",
       "      <td>696</td>\n",
       "      <td>56004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>smotified-ctgan</td>\n",
       "      <td>18005</td>\n",
       "      <td>19090</td>\n",
       "      <td>12939</td>\n",
       "      <td>5415</td>\n",
       "      <td>1958</td>\n",
       "      <td>652</td>\n",
       "      <td>58059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vae-ctgan</td>\n",
       "      <td>12876</td>\n",
       "      <td>18750</td>\n",
       "      <td>15919</td>\n",
       "      <td>7967</td>\n",
       "      <td>3363</td>\n",
       "      <td>1341</td>\n",
       "      <td>60216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>smotified-vae-ctgan</td>\n",
       "      <td>12874</td>\n",
       "      <td>18751</td>\n",
       "      <td>15920</td>\n",
       "      <td>7967</td>\n",
       "      <td>3363</td>\n",
       "      <td>1341</td>\n",
       "      <td>60216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ctabgan</td>\n",
       "      <td>2097</td>\n",
       "      <td>10811</td>\n",
       "      <td>19681</td>\n",
       "      <td>15959</td>\n",
       "      <td>6756</td>\n",
       "      <td>2837</td>\n",
       "      <td>58141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>smotified-ctabgan</td>\n",
       "      <td>39153</td>\n",
       "      <td>14190</td>\n",
       "      <td>3940</td>\n",
       "      <td>769</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>58172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vae-ctabgan</td>\n",
       "      <td>15080</td>\n",
       "      <td>16891</td>\n",
       "      <td>13332</td>\n",
       "      <td>6327</td>\n",
       "      <td>2777</td>\n",
       "      <td>1085</td>\n",
       "      <td>55492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>smotified-vae-ctabgan</td>\n",
       "      <td>16891</td>\n",
       "      <td>16646</td>\n",
       "      <td>12349</td>\n",
       "      <td>6095</td>\n",
       "      <td>2634</td>\n",
       "      <td>1027</td>\n",
       "      <td>55642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method      A      B      C      D     E   F+G  Total\n",
       "0                    Base   7574  15503  17370  10098  6378  3301  60224\n",
       "1           Undersampling  16009  16708  12374   5232  2518  1055  53896\n",
       "2                SMOTE-NC  18192  18000  12751   5565  2182   830  57520\n",
       "3               table-gan  16045  18981  14267   7125  2402   723  59543\n",
       "4      Smotified-tablegan  12876  18749  15919   7967  3363  1341  60215\n",
       "5            vae-tablegan  12876  18750  15920   7967  3363  1341  60217\n",
       "6                   ctgan  16589  18424  12983   5293  2019   696  56004\n",
       "7         smotified-ctgan  18005  19090  12939   5415  1958   652  58059\n",
       "8               vae-ctgan  12876  18750  15919   7967  3363  1341  60216\n",
       "9     smotified-vae-ctgan  12874  18751  15920   7967  3363  1341  60216\n",
       "10                ctabgan   2097  10811  19681  15959  6756  2837  58141\n",
       "11      smotified-ctabgan  39153  14190   3940    769   111     9  58172\n",
       "12            vae-ctabgan  15080  16891  13332   6327  2777  1085  55492\n",
       "13  smotified-vae-ctabgan  16891  16646  12349   6095  2634  1027  55642"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_grade_distribution_df_top.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91bad410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        A      B      C      D      E   F+G\n",
      "0   12.58  25.74  28.84  16.77  10.59  5.48\n",
      "1   29.70  31.00  22.96   9.71   4.67  1.96\n",
      "2   31.63  31.29  22.17   9.67   3.79  1.44\n",
      "3   26.95  31.88  23.96  11.97   4.03  1.21\n",
      "4   21.38  31.14  26.44  13.23   5.58  2.23\n",
      "5   21.38  31.14  26.44  13.23   5.58  2.23\n",
      "6   29.62  32.90  23.18   9.45   3.61  1.24\n",
      "7   31.01  32.88  22.29   9.33   3.37  1.12\n",
      "8   21.38  31.14  26.44  13.23   5.58  2.23\n",
      "9   21.38  31.14  26.44  13.23   5.58  2.23\n",
      "10   3.61  18.59  33.85  27.45  11.62  4.88\n",
      "11  67.31  24.39   6.77   1.32   0.19  0.02\n",
      "12  27.18  30.44  24.03  11.40   5.00  1.96\n",
      "13  30.36  29.92  22.19  10.95   4.73  1.85\n"
     ]
    }
   ],
   "source": [
    "portfolio_grade = portfolio_grade_distribution_df_top.copy()\n",
    "\n",
    "grade_columns = ['A', 'B', 'C', 'D', 'E', 'F+G']\n",
    "\n",
    "for col in grade_columns:\n",
    "    portfolio_grade[col] = (portfolio_grade[col] / portfolio_grade['Total']) * 100\n",
    "    portfolio_grade[col] = round(portfolio_grade[col],2)\n",
    "\n",
    "# 결과 출력\n",
    "print(portfolio_grade[[col for col in grade_columns]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5aafb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F+G</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>12.58</td>\n",
       "      <td>25.74</td>\n",
       "      <td>28.84</td>\n",
       "      <td>16.77</td>\n",
       "      <td>10.59</td>\n",
       "      <td>5.48</td>\n",
       "      <td>60224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undersampling</td>\n",
       "      <td>29.70</td>\n",
       "      <td>31.00</td>\n",
       "      <td>22.96</td>\n",
       "      <td>9.71</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1.96</td>\n",
       "      <td>53896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE-NC</td>\n",
       "      <td>31.63</td>\n",
       "      <td>31.29</td>\n",
       "      <td>22.17</td>\n",
       "      <td>9.67</td>\n",
       "      <td>3.79</td>\n",
       "      <td>1.44</td>\n",
       "      <td>57520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>table-gan</td>\n",
       "      <td>26.95</td>\n",
       "      <td>31.88</td>\n",
       "      <td>23.96</td>\n",
       "      <td>11.97</td>\n",
       "      <td>4.03</td>\n",
       "      <td>1.21</td>\n",
       "      <td>59543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Smotified-tablegan</td>\n",
       "      <td>21.38</td>\n",
       "      <td>31.14</td>\n",
       "      <td>26.44</td>\n",
       "      <td>13.23</td>\n",
       "      <td>5.58</td>\n",
       "      <td>2.23</td>\n",
       "      <td>60215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vae-tablegan</td>\n",
       "      <td>21.38</td>\n",
       "      <td>31.14</td>\n",
       "      <td>26.44</td>\n",
       "      <td>13.23</td>\n",
       "      <td>5.58</td>\n",
       "      <td>2.23</td>\n",
       "      <td>60217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ctgan</td>\n",
       "      <td>29.62</td>\n",
       "      <td>32.90</td>\n",
       "      <td>23.18</td>\n",
       "      <td>9.45</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.24</td>\n",
       "      <td>56004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>smotified-ctgan</td>\n",
       "      <td>31.01</td>\n",
       "      <td>32.88</td>\n",
       "      <td>22.29</td>\n",
       "      <td>9.33</td>\n",
       "      <td>3.37</td>\n",
       "      <td>1.12</td>\n",
       "      <td>58059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vae-ctgan</td>\n",
       "      <td>21.38</td>\n",
       "      <td>31.14</td>\n",
       "      <td>26.44</td>\n",
       "      <td>13.23</td>\n",
       "      <td>5.58</td>\n",
       "      <td>2.23</td>\n",
       "      <td>60216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>smotified-vae-ctgan</td>\n",
       "      <td>21.38</td>\n",
       "      <td>31.14</td>\n",
       "      <td>26.44</td>\n",
       "      <td>13.23</td>\n",
       "      <td>5.58</td>\n",
       "      <td>2.23</td>\n",
       "      <td>60216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ctabgan</td>\n",
       "      <td>3.61</td>\n",
       "      <td>18.59</td>\n",
       "      <td>33.85</td>\n",
       "      <td>27.45</td>\n",
       "      <td>11.62</td>\n",
       "      <td>4.88</td>\n",
       "      <td>58141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>smotified-ctabgan</td>\n",
       "      <td>67.31</td>\n",
       "      <td>24.39</td>\n",
       "      <td>6.77</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>58172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vae-ctabgan</td>\n",
       "      <td>27.18</td>\n",
       "      <td>30.44</td>\n",
       "      <td>24.03</td>\n",
       "      <td>11.40</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.96</td>\n",
       "      <td>55492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>smotified-vae-ctabgan</td>\n",
       "      <td>30.36</td>\n",
       "      <td>29.92</td>\n",
       "      <td>22.19</td>\n",
       "      <td>10.95</td>\n",
       "      <td>4.73</td>\n",
       "      <td>1.85</td>\n",
       "      <td>55642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method      A      B      C      D      E   F+G  Total\n",
       "0                    Base  12.58  25.74  28.84  16.77  10.59  5.48  60224\n",
       "1           Undersampling  29.70  31.00  22.96   9.71   4.67  1.96  53896\n",
       "2                SMOTE-NC  31.63  31.29  22.17   9.67   3.79  1.44  57520\n",
       "3               table-gan  26.95  31.88  23.96  11.97   4.03  1.21  59543\n",
       "4      Smotified-tablegan  21.38  31.14  26.44  13.23   5.58  2.23  60215\n",
       "5            vae-tablegan  21.38  31.14  26.44  13.23   5.58  2.23  60217\n",
       "6                   ctgan  29.62  32.90  23.18   9.45   3.61  1.24  56004\n",
       "7         smotified-ctgan  31.01  32.88  22.29   9.33   3.37  1.12  58059\n",
       "8               vae-ctgan  21.38  31.14  26.44  13.23   5.58  2.23  60216\n",
       "9     smotified-vae-ctgan  21.38  31.14  26.44  13.23   5.58  2.23  60216\n",
       "10                ctabgan   3.61  18.59  33.85  27.45  11.62  4.88  58141\n",
       "11      smotified-ctabgan  67.31  24.39   6.77   1.32   0.19  0.02  58172\n",
       "12            vae-ctabgan  27.18  30.44  24.03  11.40   5.00  1.96  55492\n",
       "13  smotified-vae-ctabgan  30.36  29.92  22.19  10.95   4.73  1.85  55642"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_grade.head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CTGAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
