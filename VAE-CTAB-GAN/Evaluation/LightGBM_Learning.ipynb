{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d5d28ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler,OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, log_loss\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch \n",
    "import os\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c669424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b55fca72",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/base/train_category.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m test_data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/base/test_category.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m test_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(test_data_path)\n",
      "File \u001b[1;32mc:\\Users\\GCU\\anaconda3\\envs\\CTGAN\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\GCU\\anaconda3\\envs\\CTGAN\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\GCU\\anaconda3\\envs\\CTGAN\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1741\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m     (\n\u001b[0;32m   1745\u001b[0m         index,\n\u001b[0;32m   1746\u001b[0m         columns,\n\u001b[0;32m   1747\u001b[0m         col_dict,\n\u001b[1;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\GCU\\anaconda3\\envs\\CTGAN\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:239\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 239\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_chunk:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/base/train_category.csv\"\n",
    "data = pd.read_csv(data_path, low_memory=False)\n",
    "\n",
    "test_data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/base/test_category.csv\"\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed38855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep_features = ['grade', 'term_months', 'total_pymnt', 'total_pymnt_inv','total_il_high_credit_limit', 'loan_amnt']\n",
    "keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "\n",
    "data_classification = data.copy()\n",
    "test_classification = test_data.copy()\n",
    "\n",
    "data_classification = data_classification.drop(columns = keep_features)\n",
    "test_classification = test_classification.drop(columns = keep_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4173de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Encoding 완료! 결과 shape: (1116458, 35)\n"
     ]
    }
   ],
   "source": [
    "## data Encoding\n",
    "Labelencoding_features = ['term_months', 'sub_grade']\n",
    "onehot_features = ['debt_settlement_flag', 'home_ownership', 'purpose']\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "label_encoders = {}\n",
    "for col in Labelencoding_features:\n",
    "    le = LabelEncoder()\n",
    "    data_classification[col] = le.fit_transform(data_classification[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# One-Hot Encoding\n",
    "onehot_encoded = onehot_encoder.fit_transform(data_classification[onehot_features])\n",
    "onehot_encoded_df = pd.DataFrame(\n",
    "    onehot_encoded, \n",
    "    columns=onehot_encoder.get_feature_names_out(onehot_features),\n",
    "    index=data_classification.index\n",
    ")\n",
    "\n",
    "# Merge\n",
    "data_classification.drop(columns=onehot_features, inplace=True)\n",
    "data_classification = pd.concat([data_classification, onehot_encoded_df], axis=1)\n",
    "\n",
    "print(\"✅ Encoding 완료! 결과 shape:\", data_classification.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947c52a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 테스트 데이터 인코딩 완료! 결과 shape: (744306, 35)\n"
     ]
    }
   ],
   "source": [
    "##Test data encoding\n",
    "for col in Labelencoding_features:\n",
    "    le = label_encoders[col]\n",
    "    test_classification[col] = le.transform(test_classification[col])\n",
    "\n",
    "# One-Hot Encoding (train에서 fit된 onehot_encoder 재사용)\n",
    "onehot_encoded_test = onehot_encoder.transform(test_classification[onehot_features])\n",
    "onehot_encoded_test_df = pd.DataFrame(\n",
    "    onehot_encoded_test,\n",
    "    columns=onehot_encoder.get_feature_names_out(onehot_features),\n",
    "    index=test_classification.index\n",
    ")\n",
    "\n",
    "# Merge\n",
    "test_classification.drop(columns=onehot_features, inplace=True)\n",
    "test_classification = pd.concat([test_classification, onehot_encoded_test_df], axis=1)\n",
    "\n",
    "print(\"✅ 테스트 데이터 인코딩 완료! 결과 shape:\", test_classification.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8641974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features(df, label_encoders, onehot_encoder, label_cols, onehot_cols):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Label Encoding\n",
    "    for col in label_cols:\n",
    "        le = label_encoders[col]\n",
    "        df[col] = le.transform(df[col])\n",
    "\n",
    "    # One-Hot Encoding\n",
    "    onehot_encoded = onehot_encoder.transform(df[onehot_cols])\n",
    "    onehot_df = pd.DataFrame(\n",
    "        onehot_encoded, \n",
    "        columns=onehot_encoder.get_feature_names_out(onehot_cols),\n",
    "        index=df.index\n",
    "    )\n",
    "\n",
    "    df.drop(columns=onehot_cols, inplace=True)\n",
    "    df = pd.concat([df, onehot_df], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12424918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def load_data_by_method(method):\n",
    "    test_data = test_classification\n",
    "    X_test = test_data.drop(columns='loan_status')\n",
    "    y_test = test_data[['loan_status']]\n",
    "\n",
    "    base_data = data_classification\n",
    "\n",
    "    if method == 'Base':\n",
    "        X_train = base_data.drop(columns='loan_status')\n",
    "        y_train = base_data[['loan_status']]\n",
    "\n",
    "    elif method == 'Undersampling':\n",
    "        data_x = base_data.drop(columns='loan_status')\n",
    "        data_y = base_data[['loan_status']]\n",
    "        X_temp, _, y_temp, _ = train_test_split(data_x, data_y, test_size=0.13, random_state=42, stratify=data_y)\n",
    "        rus = RandomUnderSampler(random_state=42)\n",
    "        X_under, y_under = rus.fit_resample(X_temp, y_temp)\n",
    "        X_train, y_train = X_under, y_under\n",
    "\n",
    "    elif method == 'SMOTE-NC':\n",
    "        smote_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/smotenc/smotenc_data.csv\"\n",
    "        smote_data = pd.read_csv(smote_path)\n",
    "        drop_cols = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt', 'funded_amnt']\n",
    "        smote_data = smote_data.drop(columns=drop_cols)\n",
    "        smote_data = encode_features(smote_data, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        X_train = smote_data.drop(columns='loan_status')\n",
    "        y_train = smote_data[['loan_status']]\n",
    "\n",
    "    else:\n",
    "        fake_base = {\n",
    "            'table-gan': 'tablegan/tablegan.csv',\n",
    "            'Smotified-tablegan': 'tablegan/smotified-tablegan.csv',\n",
    "            'vae-tablegan': 'tablegan/vae-tablegan.csv',\n",
    "            'ctgan': 'ctgan/ctgan.csv',\n",
    "            'smotified-ctgan': 'ctgan/smotified-ctgan.csv',\n",
    "            'vae-ctgan': 'ctgan/vae-ctgan.csv',\n",
    "            'smotified-vae-ctgan': 'ctgan/smotified-vae-ctgan.csv',\n",
    "            'ctabgan': 'ctabgan/ctabgan.csv',\n",
    "            'smotified-ctabgan': 'ctabgan/smotified_ctabgan.csv',\n",
    "            'vae-ctabgan': 'ctabgan/vae-ctabgan.csv',\n",
    "            'smotified-vae-ctabgan': 'ctabgan/smotified-vae-ctabgan.csv'\n",
    "        }\n",
    "\n",
    "        if method not in fake_base:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "        fake_path = f\"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/{fake_base[method]}\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1  # 모든 fake는 default\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt', 'funded_amnt']\n",
    "        fake = fake.drop(columns=keep_features)\n",
    "        fake['term_months'] = fake['term_months'].apply(lambda x: 36 if abs(x - 36) < abs(x - 60) else 60)\n",
    "        fake = encode_features(fake, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        base_x = base_data.drop(columns='loan_status')\n",
    "        base_y = base_data[['loan_status']]\n",
    "        X_base, _, y_base, _ = train_test_split(base_x, base_y, test_size=0.2, stratify=base_y, random_state=42)\n",
    "        train_real = pd.concat([X_base, y_base], axis=1)\n",
    "        train_total = pd.concat([train_real, fake])\n",
    "        train_total = shuffle(train_total, random_state=42)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77285e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_with_sharpe_top = []\n",
    "\n",
    "summary_with_grade_top = []\n",
    "\n",
    "def linear_portfolio_top(Method, top_10_indices):\n",
    "    selected = test_data.loc[top_10_indices.index].copy()\n",
    "    returns = (selected['total_pymnt_inv'] - selected['funded_amnt']) / selected['funded_amnt']\n",
    "    \n",
    "    avg_return = returns.mean()\n",
    "    std_return = returns.std()\n",
    "    sharpe_ratio = avg_return / std_return if std_return != 0 else np.nan\n",
    "\n",
    "    summary_with_sharpe_top.append({\n",
    "        'Method': Method,\n",
    "        'Average Return': avg_return * 100,\n",
    "        'Std Dev': std_return,\n",
    "        'Sharpe Ratio': sharpe_ratio\n",
    "    }) \n",
    "\n",
    "    A_count = len(selected[selected['grade'] == 'A'])\n",
    "    B_count = len(selected[selected['grade'] == 'B'])\n",
    "    C_count = len(selected[selected['grade'] == 'C'])\n",
    "    D_count = len(selected[selected['grade'] == 'D'])\n",
    "    E_count = len(selected[selected['grade'] == 'E'])\n",
    "    F_G_count = len(selected[selected['grade'] == 'F']) + len(selected[selected['grade'] == 'G'])\n",
    "\n",
    "    summary_with_grade_top.append({\n",
    "        'Method': Method,\n",
    "        'A': A_count,\n",
    "        'B': B_count,\n",
    "        'C': C_count,\n",
    "        'D': D_count,\n",
    "        'E': E_count,\n",
    "        'F+G': F_G_count,\n",
    "        'Total': len(selected)\n",
    "    }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b609c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "##상위 10% 투자\n",
    "from imblearn.over_sampling import SMOTE\n",
    "drop2 = ['loan_status', 'return']\n",
    "\n",
    "def select_fully_paid(y_pred, method):\n",
    "    scaler = StandardScaler()\n",
    "    reg = LinearRegression()\n",
    "\n",
    "    fully_paid_indices = (y_pred == 0)\n",
    "    test_regression = test_data[fully_paid_indices]\n",
    "    test_regression['return'] = (test_regression['total_pymnt_inv'] - test_regression['funded_amnt'])/test_regression['funded_amnt']\n",
    "\n",
    "    train_regression = data.copy()\n",
    "\n",
    "    if method == 'Base':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        data_x = train_regression.drop(columns='return')\n",
    "        data_y = train_regression[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "        return method, top_10_percent\n",
    "    \n",
    "    elif method == 'Undersampling':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['loan_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        X_train = train_regression.drop(columns='loan_status')\n",
    "        y_train = train_regression[['loan_status']]\n",
    "\n",
    "        undersampler = RandomUnderSampler(random_state=42)\n",
    "        X_under, y_under = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        data_under = pd.concat([pd.DataFrame(X_under, columns=X_train.columns), pd.DataFrame(y_under, columns=['loan_status'])], axis=1)\n",
    "\n",
    "        data_x = data_under.drop(columns=drop2)  \n",
    "        data_y = data_under[['return']]  \n",
    "\n",
    "        test_x = test_regression.drop(columns = drop2)\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent\n",
    "    \n",
    "    elif method == 'SMOTE-NC':\n",
    "        smote_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/smotenc/smotenc_data.csv\"\n",
    "        data_smote = pd.read_csv(smote_path)\n",
    "        \n",
    "        data_smote['return'] = (data_smote['total_pymnt_inv'] - data_smote['funded_amnt'])/data_smote['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "\n",
    "        train_regression = data_smote.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        X_train = train_regression.drop(columns='return')\n",
    "        y_train = train_regression[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        #y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent\n",
    "    \n",
    "    elif method == 'table-gan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/tablegan/tablegan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent\n",
    "        \n",
    "    elif method == 'Smotified-tablegan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/tablegan/smotified-tablegan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    \n",
    "    elif method == 'vae-tablegan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/tablegan/vae-tablegan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    \n",
    "    elif method == 'ctgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    \n",
    "    elif method == 'smotified-ctgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/smotified-ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    \n",
    "    elif method == 'vae-ctgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/vae-ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    \n",
    "    elif method == 'smotified-vae-ctgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/smotified-vae-ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        \n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "\n",
    "    elif method == 'ctabgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        \n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    \n",
    "    elif method == 'smotified-ctabgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/smotified_ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        \n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "\n",
    "    elif method == 'vae-ctabgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/vae-ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        \n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    \n",
    "    elif method == 'smotified-vae-ctabgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/smotified-vae-ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        \n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad8ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "classification_metrics_summary = []\n",
    "\n",
    "def return_evaluation(model, data_x, data_y, X_test, y_test, method):\n",
    "    print(f\"Preprocessing method : {method}\")\n",
    "\n",
    "    if method == 'Base':\n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2,\n",
    "                                                           random_state=42, stratify=data_y)\n",
    "        model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "\n",
    "    elif method == 'Undersampling':\n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.13, random_state=42, stratify=data_y)\n",
    "        undersampler = RandomUnderSampler(random_state=42)\n",
    "        X_under, y_under = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        data_under = pd.concat([pd.DataFrame(X_under, columns=data_x.columns), pd.DataFrame(y_under, columns=['loan_status'])], axis=1)\n",
    "        X_train = data_under.drop(columns=['loan_status'])  # Feature (입력 데이터)\n",
    "        y_train = data_under[['loan_status']]  # Target (타겟 변수)\n",
    "\n",
    "        model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    elif method == 'SMOTE-NC':\n",
    "        smote_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/smotenc/smotenc_data.csv\"\n",
    "        data_smote = pd.read_csv(smote_path)\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        data_smote_classification = data_smote.copy()\n",
    "        data_smote_classification = data_smote_classification.drop(columns = keep_features)\n",
    "\n",
    "        data_smote_classification = encode_features(data_smote_classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        data_x = data_smote_classification.drop(columns='loan_status') \n",
    "        data_y = data_smote_classification[['loan_status']]\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, random_state=42, stratify=data_y)\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'table-gan':\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/tablegan/tablegan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "        \n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, random_state=42, stratify=data_y)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total, random_state=42)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        \n",
    "    elif method == 'Smotified-tablegan':\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/tablegan/smotified-tablegan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'vae-tablegan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/tablegan/vae-tablegan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'ctgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'smotified-ctgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/smotified-ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'vae-ctgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/vae-ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        \n",
    "    elif method == 'smotified-vae-ctgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/smotified-vae-ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'ctabgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'smotified-ctabgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/smotified_ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'vae-ctabgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/vae-ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'smotified-vae-ctabgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/smotified-vae-ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    report = classification_report(\n",
    "        y_test, y_pred,\n",
    "        target_names=[\"Fully Paid\", \"Default\"],\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "    classification_metrics_summary.append({\n",
    "        \"Method\": method,\n",
    "        \"Class 0 Precision\": report[\"Fully Paid\"][\"precision\"],\n",
    "        \"Class 0 Recall\": report[\"Fully Paid\"][\"recall\"],\n",
    "        \"Class 0 F1\": report[\"Fully Paid\"][\"f1-score\"],\n",
    "        \"Class 1 Precision\": report[\"Default\"][\"precision\"],\n",
    "        \"Class 1 Recall\": report[\"Default\"][\"recall\"],\n",
    "        \"Class 1 F1\": report[\"Default\"][\"f1-score\"],\n",
    "        \"Macro Avg F1\": report[\"macro avg\"][\"f1-score\"],\n",
    "        \"Weighted Avg F1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "    })\n",
    "\n",
    "    #10% index뽑기기\n",
    "    Method, top_10_indices = select_fully_paid(y_pred, method)\n",
    "\n",
    "    #portfolio 만들기들기\n",
    "    linear_portfolio_top(Method, top_10_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e721ce1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : Base\n",
      "RMSE: 0.19724239831874127\n",
      "R²: 0.016356161994040885\n",
      "Preprocessing method : Undersampling\n",
      "RMSE: 0.2007067594710921\n",
      "R²: -0.6261143279074499\n",
      "Preprocessing method : SMOTE-NC\n",
      "RMSE: 0.21738932909898348\n",
      "R²: -0.4388215339785775\n",
      "Preprocessing method : table-gan\n",
      "RMSE: 0.22283512191911087\n",
      "R²: -0.2932030258814302\n",
      "Preprocessing method : Smotified-tablegan\n",
      "RMSE: 0.1971861146028728\n",
      "R²: 0.017583017592604833\n",
      "Preprocessing method : vae-tablegan\n",
      "RMSE: 0.1971462665768218\n",
      "R²: 0.01738228600951275\n",
      "Preprocessing method : ctgan\n",
      "RMSE: 0.20415525644964622\n",
      "R²: -0.44007376324769765\n",
      "Preprocessing method : smotified-ctgan\n",
      "RMSE: 0.21385968419472373\n",
      "R²: -0.35103010611651353\n",
      "Preprocessing method : vae-ctgan\n",
      "RMSE: 0.19716343022106153\n",
      "R²: 0.017122464700463524\n",
      "Preprocessing method : smotified-vae-ctgan\n",
      "RMSE: 0.1971223544064629\n",
      "R²: 0.01723968711960333\n",
      "Preprocessing method : ctabgan\n",
      "RMSE: 0.3262947433219871\n",
      "R²: -2.107724009921067\n",
      "Preprocessing method : smotified-ctabgan\n",
      "RMSE: 0.34058759559462254\n",
      "R²: -2.3765921854528\n",
      "Preprocessing method : vae-ctabgan\n",
      "RMSE: 0.18764996280695193\n",
      "R²: -0.26223263487888837\n",
      "Preprocessing method : smotified-vae-ctabgan\n",
      "RMSE: 0.1932268510992866\n",
      "R²: -0.31075232732253744\n"
     ]
    }
   ],
   "source": [
    "methods = [\n",
    "    'Base', 'Undersampling', 'SMOTE-NC',\n",
    "    'table-gan', 'Smotified-tablegan', 'vae-tablegan',\n",
    "    'ctgan', 'smotified-ctgan', 'vae-ctgan',\n",
    "    'smotified-vae-ctgan', 'ctabgan', 'smotified-ctabgan', 'vae-ctabgan', 'smotified-vae-ctabgan'\n",
    "]\n",
    "\n",
    "X_test = test_classification.drop(columns='loan_status')\n",
    "y_test = test_classification['loan_status']\n",
    "\n",
    "returns_df = pd.DataFrame()\n",
    "\n",
    "for method in methods:\n",
    "    data_x = data_classification.drop(columns='loan_status')\n",
    "    data_y = data_classification['loan_status']\n",
    "\n",
    "    model = LGBMClassifier(\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=500,               \n",
    "        device='cpu',\n",
    "        verbosity=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    return_evaluation(model, data_x, data_y, X_test, y_test, method)\n",
    "\n",
    "#classification 결과\n",
    "classification_metrics_df = pd.DataFrame(classification_metrics_summary)\n",
    "\n",
    "#상위 10% 투자전략\n",
    "returns_with_sharpe_df_top = pd.DataFrame(summary_with_sharpe_top)\n",
    "portfolio_grade_distribution_df_top = pd.DataFrame(summary_with_grade_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f572ebfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Class 0 Precision</th>\n",
       "      <th>Class 0 Recall</th>\n",
       "      <th>Class 0 F1</th>\n",
       "      <th>Class 1 Precision</th>\n",
       "      <th>Class 1 Recall</th>\n",
       "      <th>Class 1 F1</th>\n",
       "      <th>Macro Avg F1</th>\n",
       "      <th>Weighted Avg F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.942686</td>\n",
       "      <td>0.947614</td>\n",
       "      <td>0.945144</td>\n",
       "      <td>0.779072</td>\n",
       "      <td>0.762267</td>\n",
       "      <td>0.770578</td>\n",
       "      <td>0.857861</td>\n",
       "      <td>0.911091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undersampling</td>\n",
       "      <td>0.975915</td>\n",
       "      <td>0.877935</td>\n",
       "      <td>0.924336</td>\n",
       "      <td>0.643858</td>\n",
       "      <td>0.910594</td>\n",
       "      <td>0.754341</td>\n",
       "      <td>0.839338</td>\n",
       "      <td>0.891175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE-NC</td>\n",
       "      <td>0.959110</td>\n",
       "      <td>0.920835</td>\n",
       "      <td>0.939583</td>\n",
       "      <td>0.719523</td>\n",
       "      <td>0.838008</td>\n",
       "      <td>0.774258</td>\n",
       "      <td>0.856921</td>\n",
       "      <td>0.907333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>table-gan</td>\n",
       "      <td>0.945213</td>\n",
       "      <td>0.939414</td>\n",
       "      <td>0.942305</td>\n",
       "      <td>0.756173</td>\n",
       "      <td>0.775318</td>\n",
       "      <td>0.765626</td>\n",
       "      <td>0.853965</td>\n",
       "      <td>0.907840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Smotified-tablegan</td>\n",
       "      <td>0.942669</td>\n",
       "      <td>0.947568</td>\n",
       "      <td>0.945112</td>\n",
       "      <td>0.778905</td>\n",
       "      <td>0.762205</td>\n",
       "      <td>0.770464</td>\n",
       "      <td>0.857788</td>\n",
       "      <td>0.911044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vae-tablegan</td>\n",
       "      <td>0.942751</td>\n",
       "      <td>0.947568</td>\n",
       "      <td>0.945153</td>\n",
       "      <td>0.778986</td>\n",
       "      <td>0.762563</td>\n",
       "      <td>0.770687</td>\n",
       "      <td>0.857920</td>\n",
       "      <td>0.911120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ctgan</td>\n",
       "      <td>0.966121</td>\n",
       "      <td>0.902751</td>\n",
       "      <td>0.933362</td>\n",
       "      <td>0.684193</td>\n",
       "      <td>0.869373</td>\n",
       "      <td>0.765746</td>\n",
       "      <td>0.849554</td>\n",
       "      <td>0.900665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>smotified-ctgan</td>\n",
       "      <td>0.956422</td>\n",
       "      <td>0.926410</td>\n",
       "      <td>0.941177</td>\n",
       "      <td>0.731152</td>\n",
       "      <td>0.825824</td>\n",
       "      <td>0.775609</td>\n",
       "      <td>0.858393</td>\n",
       "      <td>0.908879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vae-ctgan</td>\n",
       "      <td>0.942742</td>\n",
       "      <td>0.947636</td>\n",
       "      <td>0.945183</td>\n",
       "      <td>0.779198</td>\n",
       "      <td>0.762508</td>\n",
       "      <td>0.770762</td>\n",
       "      <td>0.857973</td>\n",
       "      <td>0.911159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>smotified-vae-ctgan</td>\n",
       "      <td>0.942743</td>\n",
       "      <td>0.947566</td>\n",
       "      <td>0.945148</td>\n",
       "      <td>0.778972</td>\n",
       "      <td>0.762528</td>\n",
       "      <td>0.770663</td>\n",
       "      <td>0.857905</td>\n",
       "      <td>0.911111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ctabgan</td>\n",
       "      <td>0.955420</td>\n",
       "      <td>0.927722</td>\n",
       "      <td>0.941367</td>\n",
       "      <td>0.733620</td>\n",
       "      <td>0.821381</td>\n",
       "      <td>0.775024</td>\n",
       "      <td>0.858196</td>\n",
       "      <td>0.908919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>smotified-ctabgan</td>\n",
       "      <td>0.955250</td>\n",
       "      <td>0.927343</td>\n",
       "      <td>0.941090</td>\n",
       "      <td>0.732444</td>\n",
       "      <td>0.820741</td>\n",
       "      <td>0.774083</td>\n",
       "      <td>0.857586</td>\n",
       "      <td>0.908512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vae-ctabgan</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.896260</td>\n",
       "      <td>0.931370</td>\n",
       "      <td>0.673506</td>\n",
       "      <td>0.883038</td>\n",
       "      <td>0.764169</td>\n",
       "      <td>0.847770</td>\n",
       "      <td>0.898754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>smotified-vae-ctabgan</td>\n",
       "      <td>0.967573</td>\n",
       "      <td>0.898584</td>\n",
       "      <td>0.931803</td>\n",
       "      <td>0.676654</td>\n",
       "      <td>0.875737</td>\n",
       "      <td>0.763430</td>\n",
       "      <td>0.847617</td>\n",
       "      <td>0.898959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method  Class 0 Precision  Class 0 Recall  Class 0 F1  \\\n",
       "0                    Base           0.942686        0.947614    0.945144   \n",
       "1           Undersampling           0.975915        0.877935    0.924336   \n",
       "2                SMOTE-NC           0.959110        0.920835    0.939583   \n",
       "3               table-gan           0.945213        0.939414    0.942305   \n",
       "4      Smotified-tablegan           0.942669        0.947568    0.945112   \n",
       "5            vae-tablegan           0.942751        0.947568    0.945153   \n",
       "6                   ctgan           0.966121        0.902751    0.933362   \n",
       "7         smotified-ctgan           0.956422        0.926410    0.941177   \n",
       "8               vae-ctgan           0.942742        0.947636    0.945183   \n",
       "9     smotified-vae-ctgan           0.942743        0.947566    0.945148   \n",
       "10                ctabgan           0.955420        0.927722    0.941367   \n",
       "11      smotified-ctabgan           0.955250        0.927343    0.941090   \n",
       "12            vae-ctabgan           0.969343        0.896260    0.931370   \n",
       "13  smotified-vae-ctabgan           0.967573        0.898584    0.931803   \n",
       "\n",
       "    Class 1 Precision  Class 1 Recall  Class 1 F1  Macro Avg F1  \\\n",
       "0            0.779072        0.762267    0.770578      0.857861   \n",
       "1            0.643858        0.910594    0.754341      0.839338   \n",
       "2            0.719523        0.838008    0.774258      0.856921   \n",
       "3            0.756173        0.775318    0.765626      0.853965   \n",
       "4            0.778905        0.762205    0.770464      0.857788   \n",
       "5            0.778986        0.762563    0.770687      0.857920   \n",
       "6            0.684193        0.869373    0.765746      0.849554   \n",
       "7            0.731152        0.825824    0.775609      0.858393   \n",
       "8            0.779198        0.762508    0.770762      0.857973   \n",
       "9            0.778972        0.762528    0.770663      0.857905   \n",
       "10           0.733620        0.821381    0.775024      0.858196   \n",
       "11           0.732444        0.820741    0.774083      0.857586   \n",
       "12           0.673506        0.883038    0.764169      0.847770   \n",
       "13           0.676654        0.875737    0.763430      0.847617   \n",
       "\n",
       "    Weighted Avg F1  \n",
       "0          0.911091  \n",
       "1          0.891175  \n",
       "2          0.907333  \n",
       "3          0.907840  \n",
       "4          0.911044  \n",
       "5          0.911120  \n",
       "6          0.900665  \n",
       "7          0.908879  \n",
       "8          0.911159  \n",
       "9          0.911111  \n",
       "10         0.908919  \n",
       "11         0.908512  \n",
       "12         0.898754  \n",
       "13         0.898959  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_metrics_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a732afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Average Return</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>19.575445</td>\n",
       "      <td>0.158344</td>\n",
       "      <td>1.236261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undersampling</td>\n",
       "      <td>15.333046</td>\n",
       "      <td>0.128179</td>\n",
       "      <td>1.196222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE-NC</td>\n",
       "      <td>15.023782</td>\n",
       "      <td>0.121883</td>\n",
       "      <td>1.232638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>table-gan</td>\n",
       "      <td>14.347957</td>\n",
       "      <td>0.111919</td>\n",
       "      <td>1.281999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Smotified-tablegan</td>\n",
       "      <td>17.022460</td>\n",
       "      <td>0.129226</td>\n",
       "      <td>1.317260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vae-tablegan</td>\n",
       "      <td>17.024474</td>\n",
       "      <td>0.129162</td>\n",
       "      <td>1.318075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ctgan</td>\n",
       "      <td>15.276597</td>\n",
       "      <td>0.117094</td>\n",
       "      <td>1.304639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>smotified-ctgan</td>\n",
       "      <td>15.070453</td>\n",
       "      <td>0.113854</td>\n",
       "      <td>1.323661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vae-ctgan</td>\n",
       "      <td>17.023758</td>\n",
       "      <td>0.129159</td>\n",
       "      <td>1.318049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>smotified-vae-ctgan</td>\n",
       "      <td>17.024534</td>\n",
       "      <td>0.129161</td>\n",
       "      <td>1.318084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ctabgan</td>\n",
       "      <td>16.237286</td>\n",
       "      <td>0.196037</td>\n",
       "      <td>0.828279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>smotified-ctabgan</td>\n",
       "      <td>8.539290</td>\n",
       "      <td>0.091172</td>\n",
       "      <td>0.936610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vae-ctabgan</td>\n",
       "      <td>16.174544</td>\n",
       "      <td>0.124686</td>\n",
       "      <td>1.297225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>smotified-vae-ctabgan</td>\n",
       "      <td>15.154452</td>\n",
       "      <td>0.120962</td>\n",
       "      <td>1.252826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method  Average Return   Std Dev  Sharpe Ratio\n",
       "0                    Base       19.575445  0.158344      1.236261\n",
       "1           Undersampling       15.333046  0.128179      1.196222\n",
       "2                SMOTE-NC       15.023782  0.121883      1.232638\n",
       "3               table-gan       14.347957  0.111919      1.281999\n",
       "4      Smotified-tablegan       17.022460  0.129226      1.317260\n",
       "5            vae-tablegan       17.024474  0.129162      1.318075\n",
       "6                   ctgan       15.276597  0.117094      1.304639\n",
       "7         smotified-ctgan       15.070453  0.113854      1.323661\n",
       "8               vae-ctgan       17.023758  0.129159      1.318049\n",
       "9     smotified-vae-ctgan       17.024534  0.129161      1.318084\n",
       "10                ctabgan       16.237286  0.196037      0.828279\n",
       "11      smotified-ctabgan        8.539290  0.091172      0.936610\n",
       "12            vae-ctabgan       16.174544  0.124686      1.297225\n",
       "13  smotified-vae-ctabgan       15.154452  0.120962      1.252826"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_with_sharpe_df_top.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc00db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F+G</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>7574</td>\n",
       "      <td>15503</td>\n",
       "      <td>17370</td>\n",
       "      <td>10098</td>\n",
       "      <td>6378</td>\n",
       "      <td>3301</td>\n",
       "      <td>60224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undersampling</td>\n",
       "      <td>16009</td>\n",
       "      <td>16708</td>\n",
       "      <td>12374</td>\n",
       "      <td>5232</td>\n",
       "      <td>2518</td>\n",
       "      <td>1055</td>\n",
       "      <td>53896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE-NC</td>\n",
       "      <td>18192</td>\n",
       "      <td>18000</td>\n",
       "      <td>12751</td>\n",
       "      <td>5565</td>\n",
       "      <td>2182</td>\n",
       "      <td>830</td>\n",
       "      <td>57520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>table-gan</td>\n",
       "      <td>16045</td>\n",
       "      <td>18981</td>\n",
       "      <td>14267</td>\n",
       "      <td>7125</td>\n",
       "      <td>2402</td>\n",
       "      <td>723</td>\n",
       "      <td>59543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Smotified-tablegan</td>\n",
       "      <td>12876</td>\n",
       "      <td>18751</td>\n",
       "      <td>15922</td>\n",
       "      <td>7968</td>\n",
       "      <td>3363</td>\n",
       "      <td>1342</td>\n",
       "      <td>60222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vae-tablegan</td>\n",
       "      <td>12876</td>\n",
       "      <td>18750</td>\n",
       "      <td>15920</td>\n",
       "      <td>7967</td>\n",
       "      <td>3363</td>\n",
       "      <td>1341</td>\n",
       "      <td>60217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ctgan</td>\n",
       "      <td>16583</td>\n",
       "      <td>18418</td>\n",
       "      <td>12973</td>\n",
       "      <td>5292</td>\n",
       "      <td>2018</td>\n",
       "      <td>697</td>\n",
       "      <td>55981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>smotified-ctgan</td>\n",
       "      <td>17992</td>\n",
       "      <td>19082</td>\n",
       "      <td>12935</td>\n",
       "      <td>5412</td>\n",
       "      <td>1958</td>\n",
       "      <td>652</td>\n",
       "      <td>58031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vae-ctgan</td>\n",
       "      <td>12878</td>\n",
       "      <td>18753</td>\n",
       "      <td>15920</td>\n",
       "      <td>7967</td>\n",
       "      <td>3363</td>\n",
       "      <td>1341</td>\n",
       "      <td>60222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>smotified-vae-ctgan</td>\n",
       "      <td>12876</td>\n",
       "      <td>18751</td>\n",
       "      <td>15919</td>\n",
       "      <td>7967</td>\n",
       "      <td>3363</td>\n",
       "      <td>1341</td>\n",
       "      <td>60217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ctabgan</td>\n",
       "      <td>2096</td>\n",
       "      <td>10812</td>\n",
       "      <td>19690</td>\n",
       "      <td>15971</td>\n",
       "      <td>6761</td>\n",
       "      <td>2844</td>\n",
       "      <td>58174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>smotified-ctabgan</td>\n",
       "      <td>39143</td>\n",
       "      <td>14188</td>\n",
       "      <td>3940</td>\n",
       "      <td>770</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>58161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vae-ctabgan</td>\n",
       "      <td>14849</td>\n",
       "      <td>16962</td>\n",
       "      <td>13389</td>\n",
       "      <td>6357</td>\n",
       "      <td>2764</td>\n",
       "      <td>1073</td>\n",
       "      <td>55394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>smotified-vae-ctabgan</td>\n",
       "      <td>16891</td>\n",
       "      <td>16645</td>\n",
       "      <td>12346</td>\n",
       "      <td>6096</td>\n",
       "      <td>2634</td>\n",
       "      <td>1027</td>\n",
       "      <td>55639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method      A      B      C      D     E   F+G  Total\n",
       "0                    Base   7574  15503  17370  10098  6378  3301  60224\n",
       "1           Undersampling  16009  16708  12374   5232  2518  1055  53896\n",
       "2                SMOTE-NC  18192  18000  12751   5565  2182   830  57520\n",
       "3               table-gan  16045  18981  14267   7125  2402   723  59543\n",
       "4      Smotified-tablegan  12876  18751  15922   7968  3363  1342  60222\n",
       "5            vae-tablegan  12876  18750  15920   7967  3363  1341  60217\n",
       "6                   ctgan  16583  18418  12973   5292  2018   697  55981\n",
       "7         smotified-ctgan  17992  19082  12935   5412  1958   652  58031\n",
       "8               vae-ctgan  12878  18753  15920   7967  3363  1341  60222\n",
       "9     smotified-vae-ctgan  12876  18751  15919   7967  3363  1341  60217\n",
       "10                ctabgan   2096  10812  19690  15971  6761  2844  58174\n",
       "11      smotified-ctabgan  39143  14188   3940    770   111     9  58161\n",
       "12            vae-ctabgan  14849  16962  13389   6357  2764  1073  55394\n",
       "13  smotified-vae-ctabgan  16891  16645  12346   6096  2634  1027  55639"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_grade_distribution_df_top.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bad410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        A      B      C      D      E   F+G\n",
      "0   12.58  25.74  28.84  16.77  10.59  5.48\n",
      "1   29.70  31.00  22.96   9.71   4.67  1.96\n",
      "2   31.63  31.29  22.17   9.67   3.79  1.44\n",
      "3   26.95  31.88  23.96  11.97   4.03  1.21\n",
      "4   21.38  31.14  26.44  13.23   5.58  2.23\n",
      "5   21.38  31.14  26.44  13.23   5.58  2.23\n",
      "6   29.62  32.90  23.17   9.45   3.60  1.25\n",
      "7   31.00  32.88  22.29   9.33   3.37  1.12\n",
      "8   21.38  31.14  26.44  13.23   5.58  2.23\n",
      "9   21.38  31.14  26.44  13.23   5.58  2.23\n",
      "10   3.60  18.59  33.85  27.45  11.62  4.89\n",
      "11  67.30  24.39   6.77   1.32   0.19  0.02\n",
      "12  26.81  30.62  24.17  11.48   4.99  1.94\n",
      "13  30.36  29.92  22.19  10.96   4.73  1.85\n"
     ]
    }
   ],
   "source": [
    "portfolio_grade = portfolio_grade_distribution_df_top.copy()\n",
    "\n",
    "grade_columns = ['A', 'B', 'C', 'D', 'E', 'F+G']\n",
    "\n",
    "for col in grade_columns:\n",
    "    portfolio_grade[col] = (portfolio_grade[col] / portfolio_grade['Total']) * 100\n",
    "    portfolio_grade[col] = round(portfolio_grade[col],2)\n",
    "\n",
    "# 결과 출력\n",
    "print(portfolio_grade[[col for col in grade_columns]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aafb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F+G</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>12.58</td>\n",
       "      <td>25.74</td>\n",
       "      <td>28.84</td>\n",
       "      <td>16.77</td>\n",
       "      <td>10.59</td>\n",
       "      <td>5.48</td>\n",
       "      <td>60224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undersampling</td>\n",
       "      <td>29.70</td>\n",
       "      <td>31.00</td>\n",
       "      <td>22.96</td>\n",
       "      <td>9.71</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1.96</td>\n",
       "      <td>53896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE-NC</td>\n",
       "      <td>31.63</td>\n",
       "      <td>31.29</td>\n",
       "      <td>22.17</td>\n",
       "      <td>9.67</td>\n",
       "      <td>3.79</td>\n",
       "      <td>1.44</td>\n",
       "      <td>57520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>table-gan</td>\n",
       "      <td>26.95</td>\n",
       "      <td>31.88</td>\n",
       "      <td>23.96</td>\n",
       "      <td>11.97</td>\n",
       "      <td>4.03</td>\n",
       "      <td>1.21</td>\n",
       "      <td>59543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Smotified-tablegan</td>\n",
       "      <td>21.38</td>\n",
       "      <td>31.14</td>\n",
       "      <td>26.44</td>\n",
       "      <td>13.23</td>\n",
       "      <td>5.58</td>\n",
       "      <td>2.23</td>\n",
       "      <td>60222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vae-tablegan</td>\n",
       "      <td>21.38</td>\n",
       "      <td>31.14</td>\n",
       "      <td>26.44</td>\n",
       "      <td>13.23</td>\n",
       "      <td>5.58</td>\n",
       "      <td>2.23</td>\n",
       "      <td>60217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ctgan</td>\n",
       "      <td>29.62</td>\n",
       "      <td>32.90</td>\n",
       "      <td>23.17</td>\n",
       "      <td>9.45</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.25</td>\n",
       "      <td>55981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>smotified-ctgan</td>\n",
       "      <td>31.00</td>\n",
       "      <td>32.88</td>\n",
       "      <td>22.29</td>\n",
       "      <td>9.33</td>\n",
       "      <td>3.37</td>\n",
       "      <td>1.12</td>\n",
       "      <td>58031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vae-ctgan</td>\n",
       "      <td>21.38</td>\n",
       "      <td>31.14</td>\n",
       "      <td>26.44</td>\n",
       "      <td>13.23</td>\n",
       "      <td>5.58</td>\n",
       "      <td>2.23</td>\n",
       "      <td>60222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>smotified-vae-ctgan</td>\n",
       "      <td>21.38</td>\n",
       "      <td>31.14</td>\n",
       "      <td>26.44</td>\n",
       "      <td>13.23</td>\n",
       "      <td>5.58</td>\n",
       "      <td>2.23</td>\n",
       "      <td>60217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ctabgan</td>\n",
       "      <td>3.60</td>\n",
       "      <td>18.59</td>\n",
       "      <td>33.85</td>\n",
       "      <td>27.45</td>\n",
       "      <td>11.62</td>\n",
       "      <td>4.89</td>\n",
       "      <td>58174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>smotified-ctabgan</td>\n",
       "      <td>67.30</td>\n",
       "      <td>24.39</td>\n",
       "      <td>6.77</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>58161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vae-ctabgan</td>\n",
       "      <td>26.81</td>\n",
       "      <td>30.62</td>\n",
       "      <td>24.17</td>\n",
       "      <td>11.48</td>\n",
       "      <td>4.99</td>\n",
       "      <td>1.94</td>\n",
       "      <td>55394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>smotified-vae-ctabgan</td>\n",
       "      <td>30.36</td>\n",
       "      <td>29.92</td>\n",
       "      <td>22.19</td>\n",
       "      <td>10.96</td>\n",
       "      <td>4.73</td>\n",
       "      <td>1.85</td>\n",
       "      <td>55639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method      A      B      C      D      E   F+G  Total\n",
       "0                    Base  12.58  25.74  28.84  16.77  10.59  5.48  60224\n",
       "1           Undersampling  29.70  31.00  22.96   9.71   4.67  1.96  53896\n",
       "2                SMOTE-NC  31.63  31.29  22.17   9.67   3.79  1.44  57520\n",
       "3               table-gan  26.95  31.88  23.96  11.97   4.03  1.21  59543\n",
       "4      Smotified-tablegan  21.38  31.14  26.44  13.23   5.58  2.23  60222\n",
       "5            vae-tablegan  21.38  31.14  26.44  13.23   5.58  2.23  60217\n",
       "6                   ctgan  29.62  32.90  23.17   9.45   3.60  1.25  55981\n",
       "7         smotified-ctgan  31.00  32.88  22.29   9.33   3.37  1.12  58031\n",
       "8               vae-ctgan  21.38  31.14  26.44  13.23   5.58  2.23  60222\n",
       "9     smotified-vae-ctgan  21.38  31.14  26.44  13.23   5.58  2.23  60217\n",
       "10                ctabgan   3.60  18.59  33.85  27.45  11.62  4.89  58174\n",
       "11      smotified-ctabgan  67.30  24.39   6.77   1.32   0.19  0.02  58161\n",
       "12            vae-ctabgan  26.81  30.62  24.17  11.48   4.99  1.94  55394\n",
       "13  smotified-vae-ctabgan  30.36  29.92  22.19  10.96   4.73  1.85  55639"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_grade.head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CTGAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
