{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d5d28ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler,OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, log_loss\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch \n",
    "import os\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c669424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55fca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/base/train_category.csv\"\n",
    "data = pd.read_csv(data_path, low_memory=False)\n",
    "\n",
    "test_data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/base/test_category.csv\"\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e61baede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_fico_range_high</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>mo_sin_old_rev_tl_op</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>avg_cur_bal</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>total_pymnt_inv</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>credit_history_years</th>\n",
       "      <th>term_months</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>744306.000000</td>\n",
       "      <td>7.443060e+05</td>\n",
       "      <td>744306.000000</td>\n",
       "      <td>744306.000000</td>\n",
       "      <td>744306.000000</td>\n",
       "      <td>744306.000000</td>\n",
       "      <td>744306.000000</td>\n",
       "      <td>744306.000000</td>\n",
       "      <td>7.443060e+05</td>\n",
       "      <td>744306.000000</td>\n",
       "      <td>744306.000000</td>\n",
       "      <td>744306.000000</td>\n",
       "      <td>744306.000000</td>\n",
       "      <td>744306.000000</td>\n",
       "      <td>744306.000000</td>\n",
       "      <td>744306.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>679.018287</td>\n",
       "      <td>7.731962e+04</td>\n",
       "      <td>18.572577</td>\n",
       "      <td>180.636256</td>\n",
       "      <td>0.504507</td>\n",
       "      <td>0.131775</td>\n",
       "      <td>440.370841</td>\n",
       "      <td>13629.729160</td>\n",
       "      <td>1.629202e+04</td>\n",
       "      <td>15171.417976</td>\n",
       "      <td>15152.635259</td>\n",
       "      <td>14583.501477</td>\n",
       "      <td>14589.791934</td>\n",
       "      <td>16.317230</td>\n",
       "      <td>42.023103</td>\n",
       "      <td>0.195070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>82.449535</td>\n",
       "      <td>7.524759e+04</td>\n",
       "      <td>13.076324</td>\n",
       "      <td>94.239203</td>\n",
       "      <td>0.247945</td>\n",
       "      <td>0.048311</td>\n",
       "      <td>267.094325</td>\n",
       "      <td>16289.110866</td>\n",
       "      <td>2.258693e+04</td>\n",
       "      <td>10685.589930</td>\n",
       "      <td>10684.376590</td>\n",
       "      <td>8971.692685</td>\n",
       "      <td>8974.558867</td>\n",
       "      <td>7.603429</td>\n",
       "      <td>10.405616</td>\n",
       "      <td>0.396255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>14.770000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>629.000000</td>\n",
       "      <td>4.600000e+04</td>\n",
       "      <td>11.830000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>246.990000</td>\n",
       "      <td>3193.000000</td>\n",
       "      <td>5.833000e+03</td>\n",
       "      <td>6901.486618</td>\n",
       "      <td>6883.957500</td>\n",
       "      <td>7925.000000</td>\n",
       "      <td>7925.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>694.000000</td>\n",
       "      <td>6.500000e+04</td>\n",
       "      <td>17.710000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>8048.000000</td>\n",
       "      <td>1.107400e+04</td>\n",
       "      <td>12304.238580</td>\n",
       "      <td>12289.525000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>739.000000</td>\n",
       "      <td>9.200000e+04</td>\n",
       "      <td>24.280000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.159900</td>\n",
       "      <td>584.960000</td>\n",
       "      <td>18311.750000</td>\n",
       "      <td>1.976400e+04</td>\n",
       "      <td>21114.071210</td>\n",
       "      <td>21093.845000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>850.000000</td>\n",
       "      <td>1.099920e+07</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>8.923000</td>\n",
       "      <td>0.309900</td>\n",
       "      <td>1719.830000</td>\n",
       "      <td>752994.000000</td>\n",
       "      <td>2.904836e+06</td>\n",
       "      <td>66714.370000</td>\n",
       "      <td>66714.370000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       last_fico_range_high    annual_inc            dti  \\\n",
       "count         744306.000000  7.443060e+05  744306.000000   \n",
       "mean             679.018287  7.731962e+04      18.572577   \n",
       "std               82.449535  7.524759e+04      13.076324   \n",
       "min                0.000000  0.000000e+00      -1.000000   \n",
       "25%              629.000000  4.600000e+04      11.830000   \n",
       "50%              694.000000  6.500000e+04      17.710000   \n",
       "75%              739.000000  9.200000e+04      24.280000   \n",
       "max              850.000000  1.099920e+07     999.000000   \n",
       "\n",
       "       mo_sin_old_rev_tl_op     revol_util       int_rate    installment  \\\n",
       "count         744306.000000  744306.000000  744306.000000  744306.000000   \n",
       "mean             180.636256       0.504507       0.131775     440.370841   \n",
       "std               94.239203       0.247945       0.048311     267.094325   \n",
       "min                2.000000       0.000000       0.053100      14.770000   \n",
       "25%              118.000000       0.316000       0.095800     246.990000   \n",
       "50%              167.000000       0.505000       0.126900     373.750000   \n",
       "75%              227.000000       0.695000       0.159900     584.960000   \n",
       "max              901.000000       8.923000       0.309900    1719.830000   \n",
       "\n",
       "         avg_cur_bal     revol_bal    total_pymnt  total_pymnt_inv  \\\n",
       "count  744306.000000  7.443060e+05  744306.000000    744306.000000   \n",
       "mean    13629.729160  1.629202e+04   15171.417976     15152.635259   \n",
       "std     16289.110866  2.258693e+04   10685.589930     10684.376590   \n",
       "min         0.000000  0.000000e+00       0.000000         0.000000   \n",
       "25%      3193.000000  5.833000e+03    6901.486618      6883.957500   \n",
       "50%      8048.000000  1.107400e+04   12304.238580     12289.525000   \n",
       "75%     18311.750000  1.976400e+04   21114.071210     21093.845000   \n",
       "max    752994.000000  2.904836e+06   66714.370000     66714.370000   \n",
       "\n",
       "         funded_amnt      loan_amnt  credit_history_years    term_months  \\\n",
       "count  744306.000000  744306.000000         744306.000000  744306.000000   \n",
       "mean    14583.501477   14589.791934             16.317230      42.023103   \n",
       "std      8971.692685    8974.558867              7.603429      10.405616   \n",
       "min       700.000000     700.000000              3.000000      36.000000   \n",
       "25%      7925.000000    7925.000000             11.000000      36.000000   \n",
       "50%     12000.000000   12000.000000             15.000000      36.000000   \n",
       "75%     20000.000000   20000.000000             20.000000      60.000000   \n",
       "max     40000.000000   40000.000000             75.000000      60.000000   \n",
       "\n",
       "         loan_status  \n",
       "count  744306.000000  \n",
       "mean        0.195070  \n",
       "std         0.396255  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ed38855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep_features = ['grade', 'term_months', 'total_pymnt', 'total_pymnt_inv','total_il_high_credit_limit', 'loan_amnt']\n",
    "keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "\n",
    "data_classification = data.copy()\n",
    "test_classification = test_data.copy()\n",
    "\n",
    "data_classification = data_classification.drop(columns = keep_features)\n",
    "test_classification = test_classification.drop(columns = keep_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31b60d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['last_fico_range_high', 'annual_inc', 'dti', 'mo_sin_old_rev_tl_op',\n",
       "       'revol_util', 'int_rate', 'installment', 'avg_cur_bal', 'revol_bal',\n",
       "       'debt_settlement_flag', 'sub_grade', 'home_ownership', 'purpose',\n",
       "       'credit_history_years', 'term_months', 'loan_status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classification.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d4173de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Encoding 완료! 결과 shape: (1116458, 35)\n"
     ]
    }
   ],
   "source": [
    "## data Encoding\n",
    "Labelencoding_features = ['term_months', 'sub_grade']\n",
    "onehot_features = ['debt_settlement_flag', 'home_ownership', 'purpose']\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "label_encoders = {}\n",
    "for col in Labelencoding_features:\n",
    "    le = LabelEncoder()\n",
    "    data_classification[col] = le.fit_transform(data_classification[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# One-Hot Encoding\n",
    "onehot_encoded = onehot_encoder.fit_transform(data_classification[onehot_features])\n",
    "onehot_encoded_df = pd.DataFrame(\n",
    "    onehot_encoded, \n",
    "    columns=onehot_encoder.get_feature_names_out(onehot_features),\n",
    "    index=data_classification.index\n",
    ")\n",
    "\n",
    "# Merge\n",
    "data_classification.drop(columns=onehot_features, inplace=True)\n",
    "data_classification = pd.concat([data_classification, onehot_encoded_df], axis=1)\n",
    "\n",
    "print(\"✅ Encoding 완료! 결과 shape:\", data_classification.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "947c52a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 테스트 데이터 인코딩 완료! 결과 shape: (744306, 35)\n"
     ]
    }
   ],
   "source": [
    "##Test data encoding\n",
    "for col in Labelencoding_features:\n",
    "    le = label_encoders[col]\n",
    "    test_classification[col] = le.transform(test_classification[col])\n",
    "\n",
    "# One-Hot Encoding (train에서 fit된 onehot_encoder 재사용)\n",
    "onehot_encoded_test = onehot_encoder.transform(test_classification[onehot_features])\n",
    "onehot_encoded_test_df = pd.DataFrame(\n",
    "    onehot_encoded_test,\n",
    "    columns=onehot_encoder.get_feature_names_out(onehot_features),\n",
    "    index=test_classification.index\n",
    ")\n",
    "\n",
    "# Merge\n",
    "test_classification.drop(columns=onehot_features, inplace=True)\n",
    "test_classification = pd.concat([test_classification, onehot_encoded_test_df], axis=1)\n",
    "\n",
    "print(\"✅ 테스트 데이터 인코딩 완료! 결과 shape:\", test_classification.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8641974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features(df, label_encoders, onehot_encoder, label_cols, onehot_cols):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Label Encoding\n",
    "    for col in label_cols:\n",
    "        le = label_encoders[col]\n",
    "        df[col] = le.transform(df[col])\n",
    "\n",
    "    # One-Hot Encoding\n",
    "    onehot_encoded = onehot_encoder.transform(df[onehot_cols])\n",
    "    onehot_df = pd.DataFrame(\n",
    "        onehot_encoded, \n",
    "        columns=onehot_encoder.get_feature_names_out(onehot_cols),\n",
    "        index=df.index\n",
    "    )\n",
    "\n",
    "    df.drop(columns=onehot_cols, inplace=True)\n",
    "    df = pd.concat([df, onehot_df], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12424918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def load_data_by_method(method):\n",
    "    test_data = test_classification\n",
    "    X_test = test_data.drop(columns='loan_status')\n",
    "    y_test = test_data[['loan_status']]\n",
    "\n",
    "    base_data = data_classification\n",
    "\n",
    "    if method == 'Base':\n",
    "        X_train = base_data.drop(columns='loan_status')\n",
    "        y_train = base_data[['loan_status']]\n",
    "\n",
    "    elif method == 'Undersampling':\n",
    "        data_x = base_data.drop(columns='loan_status')\n",
    "        data_y = base_data[['loan_status']]\n",
    "        X_temp, _, y_temp, _ = train_test_split(data_x, data_y, test_size=0.13, random_state=42, stratify=data_y)\n",
    "        rus = RandomUnderSampler(random_state=42)\n",
    "        X_under, y_under = rus.fit_resample(X_temp, y_temp)\n",
    "        X_train, y_train = X_under, y_under\n",
    "\n",
    "    elif method == 'SMOTE-NC':\n",
    "        smote_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/smotenc/smotenc_data.csv\"\n",
    "        smote_data = pd.read_csv(smote_path)\n",
    "        drop_cols = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt', 'funded_amnt']\n",
    "        smote_data = smote_data.drop(columns=drop_cols)\n",
    "        smote_data = encode_features(smote_data, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        X_train = smote_data.drop(columns='loan_status')\n",
    "        y_train = smote_data[['loan_status']]\n",
    "\n",
    "    else:\n",
    "        fake_base = {\n",
    "            'table-gan': 'tablegan/tablegan.csv',\n",
    "            'vae-tablegan': 'tablegan/vae-tablegan.csv',\n",
    "            'ctgan': 'ctgan/ctgan.csv',\n",
    "            'vae-ctgan': 'ctgan/vae-ctgan.csv',\n",
    "            'ctabgan': 'ctabgan/ctabgan.csv',\n",
    "            'vae-ctabgan': 'ctabgan/vae-ctabgan.csv'\n",
    "        }\n",
    "\n",
    "        if method not in fake_base:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "        fake_path = f\"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/{fake_base[method]}\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1  # 모든 fake는 default\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt', 'funded_amnt']\n",
    "        fake = fake.drop(columns=keep_features)\n",
    "        fake['term_months'] = fake['term_months'].apply(lambda x: 36 if abs(x - 36) < abs(x - 60) else 60)\n",
    "        fake = encode_features(fake, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        base_x = base_data.drop(columns='loan_status')\n",
    "        base_y = base_data[['loan_status']]\n",
    "        X_base, _, y_base, _ = train_test_split(base_x, base_y, test_size=0.2, stratify=base_y, random_state=42)\n",
    "        train_real = pd.concat([X_base, y_base], axis=1)\n",
    "        train_total = pd.concat([train_real, fake])\n",
    "        train_total = shuffle(train_total, random_state=42)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b77285e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_with_sharpe_top = []\n",
    "\n",
    "summary_with_grade_top = []\n",
    "\n",
    "def linear_portfolio_top(Method, top_10_indices):\n",
    "    selected = test_data.loc[top_10_indices.index].copy()\n",
    "    returns = (selected['total_pymnt_inv'] - selected['funded_amnt']) / selected['funded_amnt']\n",
    "    \n",
    "    avg_return = returns.mean()\n",
    "    std_return = returns.std()\n",
    "    sharpe_ratio = avg_return / std_return if std_return != 0 else np.nan\n",
    "\n",
    "    summary_with_sharpe_top.append({\n",
    "        'Method': Method,\n",
    "        'Average Return': avg_return * 100,\n",
    "        'Std Dev': std_return,\n",
    "        'Sharpe Ratio': sharpe_ratio\n",
    "    }) \n",
    "\n",
    "    A_count = len(selected[selected['grade'] == 'A'])\n",
    "    B_count = len(selected[selected['grade'] == 'B'])\n",
    "    C_count = len(selected[selected['grade'] == 'C'])\n",
    "    D_count = len(selected[selected['grade'] == 'D'])\n",
    "    E_count = len(selected[selected['grade'] == 'E'])\n",
    "    F_G_count = len(selected[selected['grade'] == 'F']) + len(selected[selected['grade'] == 'G'])\n",
    "\n",
    "    summary_with_grade_top.append({\n",
    "        'Method': Method,\n",
    "        'A': A_count,\n",
    "        'B': B_count,\n",
    "        'C': C_count,\n",
    "        'D': D_count,\n",
    "        'E': E_count,\n",
    "        'F+G': F_G_count,\n",
    "        'Total': len(selected)\n",
    "    }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b609c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "##상위 10% 투자\n",
    "from imblearn.over_sampling import SMOTE\n",
    "drop2 = ['loan_status', 'return']\n",
    "\n",
    "def select_fully_paid(y_pred, method):\n",
    "    scaler = StandardScaler()\n",
    "    reg = LinearRegression()\n",
    "\n",
    "    fully_paid_indices = (y_pred == 0)\n",
    "    test_regression = test_data[fully_paid_indices]\n",
    "    test_regression['return'] = (test_regression['total_pymnt_inv'] - test_regression['funded_amnt'])/test_regression['funded_amnt']\n",
    "\n",
    "    train_regression = data.copy()\n",
    "\n",
    "    if method == 'Base':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        data_x = train_regression.drop(columns='return')\n",
    "        data_y = train_regression[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.3))\n",
    "        return method, top_10_percent\n",
    "    \n",
    "    elif method == 'Undersampling':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['loan_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        X_train = train_regression.drop(columns='loan_status')\n",
    "        y_train = train_regression[['loan_status']]\n",
    "\n",
    "        undersampler = RandomUnderSampler(random_state=42)\n",
    "        X_under, y_under = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        data_under = pd.concat([pd.DataFrame(X_under, columns=X_train.columns), pd.DataFrame(y_under, columns=['loan_status'])], axis=1)\n",
    "\n",
    "        data_x = data_under.drop(columns=drop2)  \n",
    "        data_y = data_under[['return']]  \n",
    "\n",
    "        test_x = test_regression.drop(columns = drop2)\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.3))\n",
    "\n",
    "        return method, top_10_percent\n",
    "    \n",
    "    elif method == 'SMOTE-NC':\n",
    "        smote_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/smotenc/smotenc_data.csv\"\n",
    "        data_smote = pd.read_csv(smote_path)\n",
    "        \n",
    "        data_smote['return'] = (data_smote['total_pymnt_inv'] - data_smote['funded_amnt'])/data_smote['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "\n",
    "        train_regression = data_smote.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        X_train = train_regression.drop(columns='return')\n",
    "        y_train = train_regression[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        #y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.3))\n",
    "\n",
    "        return method, top_10_percent\n",
    "    \n",
    "    elif method == 'table-gan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/tablegan/tablegan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.3))\n",
    "\n",
    "        return method, top_10_percent\n",
    "        \n",
    "    \n",
    "    elif method == 'vae-tablegan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/tablegan/vae-tablegan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.3))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    \n",
    "    elif method == 'ctgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.3))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    \n",
    "    \n",
    "    elif method == 'vae-ctgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/vae-ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.3))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    \n",
    "\n",
    "    elif method == 'ctabgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        \n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.3))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    \n",
    "\n",
    "    elif method == 'vae-ctabgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/vae-ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        \n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.3))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ad8ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "classification_metrics_summary = []\n",
    "\n",
    "def return_evaluation(model, data_x, data_y, X_test, y_test, method):\n",
    "    print(f\"Preprocessing method : {method}\")\n",
    "\n",
    "    if method == 'Base':\n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2,\n",
    "                                                           random_state=42, stratify=data_y)\n",
    "        model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "\n",
    "    elif method == 'Undersampling':\n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.13, random_state=42, stratify=data_y)\n",
    "        undersampler = RandomUnderSampler(random_state=42)\n",
    "        X_under, y_under = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        data_under = pd.concat([pd.DataFrame(X_under, columns=data_x.columns), pd.DataFrame(y_under, columns=['loan_status'])], axis=1)\n",
    "        X_train = data_under.drop(columns=['loan_status'])  # Feature (입력 데이터)\n",
    "        y_train = data_under[['loan_status']]  # Target (타겟 변수)\n",
    "\n",
    "        model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    elif method == 'SMOTE-NC':\n",
    "        smote_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/smotenc/smotenc_data.csv\"\n",
    "        data_smote = pd.read_csv(smote_path)\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        data_smote_classification = data_smote.copy()\n",
    "        data_smote_classification = data_smote_classification.drop(columns = keep_features)\n",
    "\n",
    "        data_smote_classification = encode_features(data_smote_classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        data_x = data_smote_classification.drop(columns='loan_status') \n",
    "        data_y = data_smote_classification[['loan_status']]\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, random_state=42, stratify=data_y)\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'table-gan':\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/tablegan/tablegan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "        \n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, random_state=42, stratify=data_y)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total, random_state=42)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'vae-tablegan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/tablegan/vae-tablegan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'ctgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    \n",
    "    elif method == 'vae-ctgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/vae-ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        \n",
    "    \n",
    "    elif method == 'ctabgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    \n",
    "    elif method == 'vae-ctabgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/vae-ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    report = classification_report(\n",
    "        y_test, y_pred,\n",
    "        target_names=[\"Fully Paid\", \"Default\"],\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "    classification_metrics_summary.append({\n",
    "        \"Method\": method,\n",
    "        \"Class 0 Precision\": report[\"Fully Paid\"][\"precision\"],\n",
    "        \"Class 0 Recall\": report[\"Fully Paid\"][\"recall\"],\n",
    "        \"Class 0 F1\": report[\"Fully Paid\"][\"f1-score\"],\n",
    "        \"Class 1 Precision\": report[\"Default\"][\"precision\"],\n",
    "        \"Class 1 Recall\": report[\"Default\"][\"recall\"],\n",
    "        \"Class 1 F1\": report[\"Default\"][\"f1-score\"],\n",
    "        \"Macro Avg F1\": report[\"macro avg\"][\"f1-score\"],\n",
    "        \"Weighted Avg F1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "    })\n",
    "\n",
    "    #10% index뽑기기\n",
    "    Method, top_10_indices = select_fully_paid(y_pred, method)\n",
    "\n",
    "    #portfolio 만들기들기\n",
    "    linear_portfolio_top(Method, top_10_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e721ce1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : Base\n",
      "RMSE: 0.19724239831874127\n",
      "R²: 0.016356161994040885\n",
      "Preprocessing method : Undersampling\n",
      "RMSE: 0.2007067594710921\n",
      "R²: -0.6261143279074499\n",
      "Preprocessing method : SMOTE-NC\n",
      "RMSE: 0.21738932909898348\n",
      "R²: -0.4388215339785775\n",
      "Preprocessing method : table-gan\n",
      "RMSE: 0.22283512191911087\n",
      "R²: -0.2932030258814302\n",
      "Preprocessing method : vae-tablegan\n",
      "RMSE: 0.19711916977635202\n",
      "R²: 0.01713664028480333\n",
      "Preprocessing method : ctgan\n",
      "RMSE: 0.20417476204372026\n",
      "R²: -0.4387418751424177\n",
      "Preprocessing method : vae-ctgan\n",
      "RMSE: 0.19714586790744248\n",
      "R²: 0.01727389074379415\n",
      "Preprocessing method : ctabgan\n",
      "RMSE: 0.32584135834426026\n",
      "R²: -2.1225462244435604\n",
      "Preprocessing method : vae-ctabgan\n",
      "RMSE: 0.18743344332452533\n",
      "R²: -0.2581912507621018\n"
     ]
    }
   ],
   "source": [
    "methods = [\n",
    "    'Base', 'Undersampling', 'SMOTE-NC',\n",
    "    'table-gan',  'vae-tablegan',\n",
    "    'ctgan',  'vae-ctgan',\n",
    "    'ctabgan', 'vae-ctabgan'\n",
    "]\n",
    "\n",
    "X_test = test_classification.drop(columns='loan_status')\n",
    "y_test = test_classification['loan_status']\n",
    "\n",
    "returns_df = pd.DataFrame()\n",
    "\n",
    "for method in methods:\n",
    "    data_x = data_classification.drop(columns='loan_status')\n",
    "    data_y = data_classification['loan_status']\n",
    "\n",
    "    model = LGBMClassifier(\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=500,               \n",
    "        device='cpu',\n",
    "        verbosity=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    return_evaluation(model, data_x, data_y, X_test, y_test, method)\n",
    "\n",
    "#classification 결과\n",
    "classification_metrics_df = pd.DataFrame(classification_metrics_summary)\n",
    "\n",
    "#상위 10% 투자전략\n",
    "returns_with_sharpe_df_top = pd.DataFrame(summary_with_sharpe_top)\n",
    "portfolio_grade_distribution_df_top = pd.DataFrame(summary_with_grade_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f572ebfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Class 0 Precision</th>\n",
       "      <th>Class 0 Recall</th>\n",
       "      <th>Class 0 F1</th>\n",
       "      <th>Class 1 Precision</th>\n",
       "      <th>Class 1 Recall</th>\n",
       "      <th>Class 1 F1</th>\n",
       "      <th>Macro Avg F1</th>\n",
       "      <th>Weighted Avg F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.942686</td>\n",
       "      <td>0.947614</td>\n",
       "      <td>0.945144</td>\n",
       "      <td>0.779072</td>\n",
       "      <td>0.762267</td>\n",
       "      <td>0.770578</td>\n",
       "      <td>0.857861</td>\n",
       "      <td>0.911091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undersampling</td>\n",
       "      <td>0.975915</td>\n",
       "      <td>0.877935</td>\n",
       "      <td>0.924336</td>\n",
       "      <td>0.643858</td>\n",
       "      <td>0.910594</td>\n",
       "      <td>0.754341</td>\n",
       "      <td>0.839338</td>\n",
       "      <td>0.891175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE-NC</td>\n",
       "      <td>0.959110</td>\n",
       "      <td>0.920835</td>\n",
       "      <td>0.939583</td>\n",
       "      <td>0.719523</td>\n",
       "      <td>0.838008</td>\n",
       "      <td>0.774258</td>\n",
       "      <td>0.856921</td>\n",
       "      <td>0.907333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>table-gan</td>\n",
       "      <td>0.945213</td>\n",
       "      <td>0.939414</td>\n",
       "      <td>0.942305</td>\n",
       "      <td>0.756173</td>\n",
       "      <td>0.775318</td>\n",
       "      <td>0.765626</td>\n",
       "      <td>0.853965</td>\n",
       "      <td>0.907840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vae-tablegan</td>\n",
       "      <td>0.942778</td>\n",
       "      <td>0.947541</td>\n",
       "      <td>0.945153</td>\n",
       "      <td>0.778926</td>\n",
       "      <td>0.762687</td>\n",
       "      <td>0.770721</td>\n",
       "      <td>0.857937</td>\n",
       "      <td>0.911127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ctgan</td>\n",
       "      <td>0.965947</td>\n",
       "      <td>0.903003</td>\n",
       "      <td>0.933415</td>\n",
       "      <td>0.684572</td>\n",
       "      <td>0.868643</td>\n",
       "      <td>0.765700</td>\n",
       "      <td>0.849558</td>\n",
       "      <td>0.900699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vae-ctgan</td>\n",
       "      <td>0.942752</td>\n",
       "      <td>0.947583</td>\n",
       "      <td>0.945161</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.762563</td>\n",
       "      <td>0.770711</td>\n",
       "      <td>0.857936</td>\n",
       "      <td>0.911131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ctabgan</td>\n",
       "      <td>0.956067</td>\n",
       "      <td>0.926652</td>\n",
       "      <td>0.941130</td>\n",
       "      <td>0.731435</td>\n",
       "      <td>0.824295</td>\n",
       "      <td>0.775093</td>\n",
       "      <td>0.858111</td>\n",
       "      <td>0.908741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vae-ctabgan</td>\n",
       "      <td>0.969249</td>\n",
       "      <td>0.896581</td>\n",
       "      <td>0.931500</td>\n",
       "      <td>0.674083</td>\n",
       "      <td>0.882624</td>\n",
       "      <td>0.764386</td>\n",
       "      <td>0.847943</td>\n",
       "      <td>0.898901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Method  Class 0 Precision  Class 0 Recall  Class 0 F1  \\\n",
       "0           Base           0.942686        0.947614    0.945144   \n",
       "1  Undersampling           0.975915        0.877935    0.924336   \n",
       "2       SMOTE-NC           0.959110        0.920835    0.939583   \n",
       "3      table-gan           0.945213        0.939414    0.942305   \n",
       "4   vae-tablegan           0.942778        0.947541    0.945153   \n",
       "5          ctgan           0.965947        0.903003    0.933415   \n",
       "6      vae-ctgan           0.942752        0.947583    0.945161   \n",
       "7        ctabgan           0.956067        0.926652    0.941130   \n",
       "8    vae-ctabgan           0.969249        0.896581    0.931500   \n",
       "\n",
       "   Class 1 Precision  Class 1 Recall  Class 1 F1  Macro Avg F1  \\\n",
       "0           0.779072        0.762267    0.770578      0.857861   \n",
       "1           0.643858        0.910594    0.754341      0.839338   \n",
       "2           0.719523        0.838008    0.774258      0.856921   \n",
       "3           0.756173        0.775318    0.765626      0.853965   \n",
       "4           0.778926        0.762687    0.770721      0.857937   \n",
       "5           0.684572        0.868643    0.765700      0.849558   \n",
       "6           0.779035        0.762563    0.770711      0.857936   \n",
       "7           0.731435        0.824295    0.775093      0.858111   \n",
       "8           0.674083        0.882624    0.764386      0.847943   \n",
       "\n",
       "   Weighted Avg F1  \n",
       "0         0.911091  \n",
       "1         0.891175  \n",
       "2         0.907333  \n",
       "3         0.907840  \n",
       "4         0.911127  \n",
       "5         0.900699  \n",
       "6         0.911131  \n",
       "7         0.908741  \n",
       "8         0.898901  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_metrics_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a732afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Average Return</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>17.202054</td>\n",
       "      <td>0.147956</td>\n",
       "      <td>1.162645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undersampling</td>\n",
       "      <td>14.814365</td>\n",
       "      <td>0.125718</td>\n",
       "      <td>1.178380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE-NC</td>\n",
       "      <td>14.571902</td>\n",
       "      <td>0.124408</td>\n",
       "      <td>1.171299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>table-gan</td>\n",
       "      <td>14.009027</td>\n",
       "      <td>0.118714</td>\n",
       "      <td>1.180069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vae-tablegan</td>\n",
       "      <td>15.836188</td>\n",
       "      <td>0.132309</td>\n",
       "      <td>1.196909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ctgan</td>\n",
       "      <td>14.791409</td>\n",
       "      <td>0.121213</td>\n",
       "      <td>1.220286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vae-ctgan</td>\n",
       "      <td>15.836051</td>\n",
       "      <td>0.132305</td>\n",
       "      <td>1.196931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ctabgan</td>\n",
       "      <td>15.116245</td>\n",
       "      <td>0.190455</td>\n",
       "      <td>0.793690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vae-ctabgan</td>\n",
       "      <td>15.373828</td>\n",
       "      <td>0.129282</td>\n",
       "      <td>1.189172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Method  Average Return   Std Dev  Sharpe Ratio\n",
       "0           Base       17.202054  0.147956      1.162645\n",
       "1  Undersampling       14.814365  0.125718      1.178380\n",
       "2       SMOTE-NC       14.571902  0.124408      1.171299\n",
       "3      table-gan       14.009027  0.118714      1.180069\n",
       "4   vae-tablegan       15.836188  0.132309      1.196909\n",
       "5          ctgan       14.791409  0.121213      1.220286\n",
       "6      vae-ctgan       15.836051  0.132305      1.196931\n",
       "7        ctabgan       15.116245  0.190455      0.793690\n",
       "8    vae-ctabgan       15.373828  0.129282      1.189172"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_with_sharpe_df_top.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cc00db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F+G</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>35359</td>\n",
       "      <td>49894</td>\n",
       "      <td>49811</td>\n",
       "      <td>26252</td>\n",
       "      <td>13443</td>\n",
       "      <td>5914</td>\n",
       "      <td>180673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undersampling</td>\n",
       "      <td>48518</td>\n",
       "      <td>50673</td>\n",
       "      <td>37532</td>\n",
       "      <td>15521</td>\n",
       "      <td>6831</td>\n",
       "      <td>2614</td>\n",
       "      <td>161689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE-NC</td>\n",
       "      <td>52201</td>\n",
       "      <td>54241</td>\n",
       "      <td>39630</td>\n",
       "      <td>17423</td>\n",
       "      <td>6621</td>\n",
       "      <td>2445</td>\n",
       "      <td>172561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>table-gan</td>\n",
       "      <td>48556</td>\n",
       "      <td>56500</td>\n",
       "      <td>43489</td>\n",
       "      <td>21019</td>\n",
       "      <td>6932</td>\n",
       "      <td>2135</td>\n",
       "      <td>178631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vae-tablegan</td>\n",
       "      <td>43903</td>\n",
       "      <td>55385</td>\n",
       "      <td>46053</td>\n",
       "      <td>22614</td>\n",
       "      <td>9181</td>\n",
       "      <td>3506</td>\n",
       "      <td>180642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ctgan</td>\n",
       "      <td>49168</td>\n",
       "      <td>54384</td>\n",
       "      <td>39610</td>\n",
       "      <td>16615</td>\n",
       "      <td>6168</td>\n",
       "      <td>2077</td>\n",
       "      <td>168022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vae-ctgan</td>\n",
       "      <td>43908</td>\n",
       "      <td>55388</td>\n",
       "      <td>46057</td>\n",
       "      <td>22615</td>\n",
       "      <td>9181</td>\n",
       "      <td>3506</td>\n",
       "      <td>180655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ctabgan</td>\n",
       "      <td>13012</td>\n",
       "      <td>46789</td>\n",
       "      <td>58407</td>\n",
       "      <td>36047</td>\n",
       "      <td>14319</td>\n",
       "      <td>5630</td>\n",
       "      <td>174204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vae-ctabgan</td>\n",
       "      <td>46338</td>\n",
       "      <td>50249</td>\n",
       "      <td>39541</td>\n",
       "      <td>19075</td>\n",
       "      <td>7955</td>\n",
       "      <td>3100</td>\n",
       "      <td>166258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Method      A      B      C      D      E   F+G   Total\n",
       "0           Base  35359  49894  49811  26252  13443  5914  180673\n",
       "1  Undersampling  48518  50673  37532  15521   6831  2614  161689\n",
       "2       SMOTE-NC  52201  54241  39630  17423   6621  2445  172561\n",
       "3      table-gan  48556  56500  43489  21019   6932  2135  178631\n",
       "4   vae-tablegan  43903  55385  46053  22614   9181  3506  180642\n",
       "5          ctgan  49168  54384  39610  16615   6168  2077  168022\n",
       "6      vae-ctgan  43908  55388  46057  22615   9181  3506  180655\n",
       "7        ctabgan  13012  46789  58407  36047  14319  5630  174204\n",
       "8    vae-ctabgan  46338  50249  39541  19075   7955  3100  166258"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_grade_distribution_df_top.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91bad410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       A      B      C      D     E   F+G\n",
      "0  19.57  27.62  27.57  14.53  7.44  3.27\n",
      "1  30.01  31.34  23.21   9.60  4.22  1.62\n",
      "2  30.25  31.43  22.97  10.10  3.84  1.42\n",
      "3  27.18  31.63  24.35  11.77  3.88  1.20\n",
      "4  24.30  30.66  25.49  12.52  5.08  1.94\n",
      "5  29.26  32.37  23.57   9.89  3.67  1.24\n",
      "6  24.30  30.66  25.49  12.52  5.08  1.94\n",
      "7   7.47  26.86  33.53  20.69  8.22  3.23\n",
      "8  27.87  30.22  23.78  11.47  4.78  1.86\n"
     ]
    }
   ],
   "source": [
    "portfolio_grade = portfolio_grade_distribution_df_top.copy()\n",
    "\n",
    "grade_columns = ['A', 'B', 'C', 'D', 'E', 'F+G']\n",
    "\n",
    "for col in grade_columns:\n",
    "    portfolio_grade[col] = (portfolio_grade[col] / portfolio_grade['Total']) * 100\n",
    "    portfolio_grade[col] = round(portfolio_grade[col],2)\n",
    "\n",
    "# 결과 출력\n",
    "print(portfolio_grade[[col for col in grade_columns]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5aafb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F+G</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>19.57</td>\n",
       "      <td>27.62</td>\n",
       "      <td>27.57</td>\n",
       "      <td>14.53</td>\n",
       "      <td>7.44</td>\n",
       "      <td>3.27</td>\n",
       "      <td>180673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undersampling</td>\n",
       "      <td>30.01</td>\n",
       "      <td>31.34</td>\n",
       "      <td>23.21</td>\n",
       "      <td>9.60</td>\n",
       "      <td>4.22</td>\n",
       "      <td>1.62</td>\n",
       "      <td>161689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE-NC</td>\n",
       "      <td>30.25</td>\n",
       "      <td>31.43</td>\n",
       "      <td>22.97</td>\n",
       "      <td>10.10</td>\n",
       "      <td>3.84</td>\n",
       "      <td>1.42</td>\n",
       "      <td>172561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>table-gan</td>\n",
       "      <td>27.18</td>\n",
       "      <td>31.63</td>\n",
       "      <td>24.35</td>\n",
       "      <td>11.77</td>\n",
       "      <td>3.88</td>\n",
       "      <td>1.20</td>\n",
       "      <td>178631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vae-tablegan</td>\n",
       "      <td>24.30</td>\n",
       "      <td>30.66</td>\n",
       "      <td>25.49</td>\n",
       "      <td>12.52</td>\n",
       "      <td>5.08</td>\n",
       "      <td>1.94</td>\n",
       "      <td>180642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ctgan</td>\n",
       "      <td>29.26</td>\n",
       "      <td>32.37</td>\n",
       "      <td>23.57</td>\n",
       "      <td>9.89</td>\n",
       "      <td>3.67</td>\n",
       "      <td>1.24</td>\n",
       "      <td>168022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vae-ctgan</td>\n",
       "      <td>24.30</td>\n",
       "      <td>30.66</td>\n",
       "      <td>25.49</td>\n",
       "      <td>12.52</td>\n",
       "      <td>5.08</td>\n",
       "      <td>1.94</td>\n",
       "      <td>180655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ctabgan</td>\n",
       "      <td>7.47</td>\n",
       "      <td>26.86</td>\n",
       "      <td>33.53</td>\n",
       "      <td>20.69</td>\n",
       "      <td>8.22</td>\n",
       "      <td>3.23</td>\n",
       "      <td>174204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vae-ctabgan</td>\n",
       "      <td>27.87</td>\n",
       "      <td>30.22</td>\n",
       "      <td>23.78</td>\n",
       "      <td>11.47</td>\n",
       "      <td>4.78</td>\n",
       "      <td>1.86</td>\n",
       "      <td>166258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Method      A      B      C      D     E   F+G   Total\n",
       "0           Base  19.57  27.62  27.57  14.53  7.44  3.27  180673\n",
       "1  Undersampling  30.01  31.34  23.21   9.60  4.22  1.62  161689\n",
       "2       SMOTE-NC  30.25  31.43  22.97  10.10  3.84  1.42  172561\n",
       "3      table-gan  27.18  31.63  24.35  11.77  3.88  1.20  178631\n",
       "4   vae-tablegan  24.30  30.66  25.49  12.52  5.08  1.94  180642\n",
       "5          ctgan  29.26  32.37  23.57   9.89  3.67  1.24  168022\n",
       "6      vae-ctgan  24.30  30.66  25.49  12.52  5.08  1.94  180655\n",
       "7        ctabgan   7.47  26.86  33.53  20.69  8.22  3.23  174204\n",
       "8    vae-ctabgan  27.87  30.22  23.78  11.47  4.78  1.86  166258"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_grade.head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CTGAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
