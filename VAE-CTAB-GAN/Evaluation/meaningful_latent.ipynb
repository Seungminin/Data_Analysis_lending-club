{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2ecf976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler,OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, log_loss\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24e4743b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1726298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, json, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score, f1_score, silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# 0) 재현성 & Device\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) 경로/설정\n",
    "# -----------------------------\n",
    "DATA_CSV = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/VAE-CTAB-GAN/Real_Datasets/train_category_1.csv\"        \n",
    "PROCESSED_CSV = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/VAE-CTAB-GAN/preprocess/processed.csv\"\n",
    "CKPT = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/VAE-CTAB-GAN/checkepoint_box/checkpoints_best/vae_ctabgan_epoch150.pth\"\n",
    "TARGET_COL = \"grade\"                                      # 또는 \"purpose\", \"home_ownership\" 등\n",
    "LATENT_DIM = 64                                           # 학습 당시 설정과 동일하게!\n",
    "\n",
    "# -----------------------------\n",
    "# 2) VAE Encoder 정의(당신 코드와 동일 인터페이스)\n",
    "#    - mu, logvar 반환하도록.\n",
    "# -----------------------------\n",
    "class VAEEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim = 64):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        conv_out_dim = 64 * input_dim  # 입력을 (B, 1, input_dim)으로 받는다고 가정\n",
    "\n",
    "        self.fc_mu = nn.Sequential(\n",
    "            nn.Linear(conv_out_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, latent_dim)\n",
    "        )\n",
    "        self.fc_logvar = nn.Sequential(\n",
    "            nn.Linear(conv_out_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, latent_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # (B, 1, input_dim)\n",
    "        h = self.conv(x)\n",
    "        h = self.flatten(h)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9a6915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, json, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score, f1_score, silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/VAE-CTAB-GAN\")\n",
    "\n",
    "# 1) 학습 당시와 동일한 transformer 로드\n",
    "with open(r\"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/VAE-CTAB-GAN/preprocess/transformer/transformer.pkl\", \"rb\") as f:\n",
    "    transformer = pickle.load(f)\n",
    "\n",
    "\n",
    "with open(r\"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/VAE-CTAB-GAN/preprocess/dataprep/dataprep.pkl\", \"rb\") as f:\n",
    "    prep = pickle.load(f)\n",
    "\n",
    "y = prep.df[TARGET_COL].to_numpy()  # processed와 같은 행 집합/순서\n",
    "\n",
    "# 2) 연속 성분(tanh) 인덱스 추출\n",
    "cont_idx = []\n",
    "offset = 0\n",
    "for dim, act in transformer.output_info:  # 예: [(1,'tanh'), (7,'softmax'), (1,'tanh'), ...]\n",
    "    if act == 'tanh':\n",
    "        cont_idx.extend(range(offset, offset + dim))\n",
    "    offset += dim\n",
    "\n",
    "# 3) 전체 입력에서 연속 성분만 선택\n",
    "X_full = pd.read_csv(PROCESSED_CSV).values.astype(np.float32)   # 210차원 등\n",
    "X_cont = X_full[:, cont_idx].astype(np.float32)                 # => 14차원이어야 함\n",
    "\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Encoder 로드\n",
    "# -----------------------------\n",
    "input_dim = X_cont.shape[1]\n",
    "encoder = VAEEncoder(input_dim=input_dim, latent_dim=LATENT_DIM).to(device)\n",
    "ckpt = torch.load(CKPT, map_location=device)\n",
    "\n",
    "# 키가 다를 수 있어서 방어적으로 처리\n",
    "key_candidates = [\"encoder_state_dict\", \"vae_encoder\", \"encoder\", \"state_dict\", \"model_state_dict\"]\n",
    "state = None\n",
    "for k in key_candidates:\n",
    "    if k in ckpt:\n",
    "        state = ckpt[k]\n",
    "        break\n",
    "if state is None:\n",
    "    # 전체 모델이 저장된 경우에서 encoder.*만 추출\n",
    "    maybe = {k.replace(\"encoder.\", \"\"): v for k, v in ckpt.items() if k.startswith(\"encoder.\")}\n",
    "    state = maybe if len(maybe) > 0 else ckpt\n",
    "\n",
    "encoder.load_state_dict(state, strict=False)\n",
    "encoder.eval()\n",
    "for p in encoder.parameters(): p.requires_grad = False\n",
    "\n",
    "# -----------------------------\n",
    "# 5) z 추출 (mu 사용 권장: 안정적, 재현성 높음)\n",
    "# -----------------------------\n",
    "def get_mu_z(batch_np, batch_size=4096):\n",
    "    zs = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(batch_np), batch_size):\n",
    "            xb = torch.from_numpy(batch_np[i:i+batch_size]).to(device)\n",
    "            z, mu, logvar = encoder(xb)\n",
    "            zs.append(mu.detach().cpu().numpy())\n",
    "    return np.concatenate(zs, axis=0)\n",
    "\n",
    "Z = get_mu_z(X_cont)\n",
    "\n",
    "# 베이스라인 1: 랜덤 노이즈 (동일 분산/차원)\n",
    "Z_rand = np.random.randn(*Z.shape).astype(np.float32)\n",
    "\n",
    "# (선택) 베이스라인 2: 원 입력(변환공간) 자체\n",
    "X_base = X_cont  # 동일 파이프라인으로 비교\n",
    "\n",
    "# -----------------------------\n",
    "# 6) k-NN probe (z만으로 속성 예측)\n",
    "# -----------------------------\n",
    "def knn_probe(feat, y, k=5, test_size=0.3):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(feat, y, test_size=test_size, random_state=SEED, stratify=y)\n",
    "    clf = KNeighborsClassifier(n_neighbors=k, weights=\"distance\")\n",
    "    clf.fit(Xtr, ytr)\n",
    "    pred = clf.predict(Xte)\n",
    "    acc = accuracy_score(yte, pred)\n",
    "    f1 = f1_score(yte, pred, average=\"weighted\")  # binary면 \"binary\"로 바꿔도 됨\n",
    "    return acc, f1\n",
    "\n",
    "acc_z, f1_z = knn_probe(Z, y, k=7)\n",
    "acc_r, f1_r = knn_probe(Z_rand, y, k=7)\n",
    "acc_x, f1_x = knn_probe(X_base, y, k=7)\n",
    "\n",
    "print(f\"[kNN] z     -> acc={acc_z:.3f}, f1={f1_z:.3f}\")\n",
    "print(f\"[kNN] rand  -> acc={acc_r:.3f}, f1={f1_r:.3f}\")\n",
    "print(f\"[kNN] xbase -> acc={acc_x:.3f}, f1={f1_x:.3f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Silhouette (라벨 없이 구조성 평가; 라벨 있을 경우 ARI도 가능)\n",
    "#    - k는 도메인에 맞게: 예) loan_status=2 클래스면 2, grade면 7 등\n",
    "# -----------------------------\n",
    "from sklearn.cluster import KMeans\n",
    "def silhouette_on(feat, n_clusters=2):\n",
    "    km = KMeans(n_clusters=n_clusters, n_init=10, random_state=SEED)\n",
    "    lab = km.fit_predict(feat)\n",
    "    return silhouette_score(feat, lab)\n",
    "\n",
    "sil_z = silhouette_on(Z, n_clusters=len(np.unique(y)))\n",
    "sil_r = silhouette_on(Z_rand, n_clusters=len(np.unique(y)))\n",
    "sil_x = silhouette_on(X_base, n_clusters=len(np.unique(y)))\n",
    "print(f\"[Silhouette] z={sil_z:.3f} | rand={sil_r:.3f} | xbase={sil_x:.3f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 8) 시각화: PCA / t-SNE\n",
    "# -----------------------------\n",
    "def plot_2d(feat, y, title):\n",
    "    pca2 = PCA(n_components=2, random_state=SEED).fit_transform(feat)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sc = plt.scatter(pca2[:,0], pca2[:,1], c=y, s=6, alpha=0.7)\n",
    "    plt.title(f\"{title} | PCA-2D\")\n",
    "    plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\"); plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    tsne2 = TSNE(n_components=2, init=\"pca\", perplexity=30, random_state=SEED).fit_transform(feat)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sc = plt.scatter(tsne2[:,0], tsne2[:,1], c=y, s=6, alpha=0.7)\n",
    "    plt.title(f\"{title} | t-SNE-2D\")\n",
    "    plt.xlabel(\"tSNE-1\"); plt.ylabel(\"tSNE-2\"); plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "idx = np.random.RandomState(42).choice(len(Z), size=min(20000, len(Z)), replace=False)\n",
    "plot_2d(Z[idx], y[idx], \"Latent z (subsample)\")\n",
    "plot_2d(Z_rand[idx], y[idx], \"Random Noise (subsample)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ad1daab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_in: 896 => expected input_dim: 14\n",
      "current X.shape[1]: 222\n"
     ]
    }
   ],
   "source": [
    "# expected in_features from ckpt\n",
    "def expected_in_from_ckpt(state):\n",
    "    w = state.get('fc_mu.0.weight', None)\n",
    "    if w is None:\n",
    "        # state가 중첩이면 꺼내세요 (예: encoder_state_dict)\n",
    "        for k in ('encoder_state_dict','vae_encoder','state_dict','encoder'):\n",
    "            if k in ckpt:\n",
    "                w = ckpt[k]['fc_mu.0.weight']\n",
    "                break\n",
    "    return w.shape[1]\n",
    "\n",
    "exp_in = expected_in_from_ckpt(state)\n",
    "print(\"expected_in:\", exp_in, \"=> expected input_dim:\", exp_in//64)\n",
    "print(\"current X.shape[1]:\", X.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ddb7ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] fc_mu.0.weight in_features = 896\n",
      "[Checkpoint] => expected input_dim = 14\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "ckpt_path = CKPT  # 네 checkpoint 경로\n",
    "ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "\n",
    "# 1) encoder state_dict 찾기\n",
    "state = None\n",
    "for k in [\"encoder_state_dict\", \"vae_encoder\", \"encoder\", \"state_dict\", \"model_state_dict\"]:\n",
    "    if k in ckpt:\n",
    "        state = ckpt[k]\n",
    "        break\n",
    "if state is None:\n",
    "    # encoder.* prefix 제거\n",
    "    maybe = {k.replace(\"encoder.\", \"\"): v for k, v in ckpt.items() if k.startswith(\"encoder.\")}\n",
    "    state = maybe if len(maybe) > 0 else ckpt\n",
    "\n",
    "# 2) fc_mu 첫 레이어의 weight shape 확인\n",
    "if \"fc_mu.0.weight\" in state:\n",
    "    in_features = state[\"fc_mu.0.weight\"].shape[1]\n",
    "    print(f\"[Checkpoint] fc_mu.0.weight in_features = {in_features}\")\n",
    "    print(f\"[Checkpoint] => expected input_dim = {in_features // 64}\")\n",
    "else:\n",
    "    print(\"fc_mu.0.weight not found, keys:\", list(state.keys())[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23c0cbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_cont shape: (174231, 14)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/VAE-CTAB-GAN\")\n",
    "\n",
    "# 1) 학습 당시와 동일한 transformer 로드\n",
    "with open(r\"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/VAE-CTAB-GAN/preprocess/transformer/transformer.pkl\", \"rb\") as f:\n",
    "    transformer = pickle.load(f)\n",
    "\n",
    "# 2) 연속 성분(tanh) 인덱스 추출\n",
    "cont_idx = []\n",
    "offset = 0\n",
    "for dim, act in transformer.output_info:  # 예: [(1,'tanh'), (7,'softmax'), (1,'tanh'), ...]\n",
    "    if act == 'tanh':\n",
    "        cont_idx.extend(range(offset, offset + dim))\n",
    "    offset += dim\n",
    "\n",
    "# 3) 전체 입력에서 연속 성분만 선택\n",
    "X_full = pd.read_csv(PROCESSED_CSV).values.astype(np.float32)   # 210차원 등\n",
    "X_cont = X_full[:, cont_idx].astype(np.float32)                 # => 14차원이어야 함\n",
    "print(\"X_cont shape:\", X_cont.shape)     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CTGAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
