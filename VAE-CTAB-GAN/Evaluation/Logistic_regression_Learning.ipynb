{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d5d28ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler,OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, log_loss\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch \n",
    "import os\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c669424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55fca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/base/train_category.csv\"\n",
    "data = pd.read_csv(data_path, low_memory=False)\n",
    "\n",
    "test_data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/base/test_category.csv\"\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ed38855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep_features = ['grade', 'term_months', 'total_pymnt', 'total_pymnt_inv','total_il_high_credit_limit', 'loan_amnt']\n",
    "keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "\n",
    "data_classification = data.copy()\n",
    "test_classification = test_data.copy()\n",
    "\n",
    "data_classification = data_classification.drop(columns = keep_features)\n",
    "test_classification = test_classification.drop(columns = keep_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d4173de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Encoding 완료! 결과 shape: (1116458, 35)\n"
     ]
    }
   ],
   "source": [
    "## data Encoding\n",
    "Labelencoding_features = ['term_months', 'sub_grade']\n",
    "onehot_features = ['debt_settlement_flag', 'home_ownership', 'purpose']\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "label_encoders = {}\n",
    "for col in Labelencoding_features:\n",
    "    le = LabelEncoder()\n",
    "    data_classification[col] = le.fit_transform(data_classification[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# One-Hot Encoding\n",
    "onehot_encoded = onehot_encoder.fit_transform(data_classification[onehot_features])\n",
    "onehot_encoded_df = pd.DataFrame(\n",
    "    onehot_encoded, \n",
    "    columns=onehot_encoder.get_feature_names_out(onehot_features),\n",
    "    index=data_classification.index\n",
    ")\n",
    "\n",
    "# Merge\n",
    "data_classification.drop(columns=onehot_features, inplace=True)\n",
    "data_classification = pd.concat([data_classification, onehot_encoded_df], axis=1)\n",
    "\n",
    "print(\"✅ Encoding 완료! 결과 shape:\", data_classification.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "947c52a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 테스트 데이터 인코딩 완료! 결과 shape: (744306, 35)\n"
     ]
    }
   ],
   "source": [
    "##Test data encoding\n",
    "for col in Labelencoding_features:\n",
    "    le = label_encoders[col]\n",
    "    test_classification[col] = le.transform(test_classification[col])\n",
    "\n",
    "# One-Hot Encoding (train에서 fit된 onehot_encoder 재사용)\n",
    "onehot_encoded_test = onehot_encoder.transform(test_classification[onehot_features])\n",
    "onehot_encoded_test_df = pd.DataFrame(\n",
    "    onehot_encoded_test,\n",
    "    columns=onehot_encoder.get_feature_names_out(onehot_features),\n",
    "    index=test_classification.index\n",
    ")\n",
    "\n",
    "# Merge\n",
    "test_classification.drop(columns=onehot_features, inplace=True)\n",
    "test_classification = pd.concat([test_classification, onehot_encoded_test_df], axis=1)\n",
    "\n",
    "print(\"✅ 테스트 데이터 인코딩 완료! 결과 shape:\", test_classification.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8641974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features(df, label_encoders, onehot_encoder, label_cols, onehot_cols):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Label Encoding\n",
    "    for col in label_cols:\n",
    "        le = label_encoders[col]\n",
    "        df[col] = le.transform(df[col])\n",
    "\n",
    "    # One-Hot Encoding\n",
    "    onehot_encoded = onehot_encoder.transform(df[onehot_cols])\n",
    "    onehot_df = pd.DataFrame(\n",
    "        onehot_encoded, \n",
    "        columns=onehot_encoder.get_feature_names_out(onehot_cols),\n",
    "        index=df.index\n",
    "    )\n",
    "\n",
    "    df.drop(columns=onehot_cols, inplace=True)\n",
    "    df = pd.concat([df, onehot_df], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12424918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def load_data_by_method(method):\n",
    "    test_data = test_classification\n",
    "    X_test = test_data.drop(columns='loan_status')\n",
    "    y_test = test_data[['loan_status']]\n",
    "\n",
    "    base_data = data_classification\n",
    "\n",
    "    if method == 'Base':\n",
    "        X_train = base_data.drop(columns='loan_status')\n",
    "        y_train = base_data[['loan_status']]\n",
    "\n",
    "    elif method == 'Undersampling':\n",
    "        data_x = base_data.drop(columns='loan_status')\n",
    "        data_y = base_data[['loan_status']]\n",
    "        X_temp, _, y_temp, _ = train_test_split(data_x, data_y, test_size=0.13, random_state=42, stratify=data_y)\n",
    "        rus = RandomUnderSampler(random_state=42)\n",
    "        X_under, y_under = rus.fit_resample(X_temp, y_temp)\n",
    "        X_train, y_train = X_under, y_under\n",
    "\n",
    "    elif method == 'SMOTE-NC':\n",
    "        smote_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/smotenc/smotenc_data.csv\"\n",
    "        smote_data = pd.read_csv(smote_path)\n",
    "        drop_cols = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt', 'funded_amnt']\n",
    "        smote_data = smote_data.drop(columns=drop_cols)\n",
    "        smote_data = encode_features(smote_data, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        X_train = smote_data.drop(columns='loan_status')\n",
    "        y_train = smote_data[['loan_status']]\n",
    "\n",
    "    else:\n",
    "        fake_base = {\n",
    "            'table-gan': 'tablegan/tablegan.csv',\n",
    "            'vae-tablegan': 'tablegan/vae-tablegan.csv',\n",
    "            'ctgan': 'ctgan/ctgan.csv',\n",
    "            'vae-ctgan': 'ctgan/vae-ctgan.csv',\n",
    "            'ctabgan': 'ctabgan/ctabgan.csv',\n",
    "            'vae-ctabgan': 'ctabgan/vae-ctabgan.csv',\n",
    "        }\n",
    "\n",
    "        if method not in fake_base:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "        fake_path = f\"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/{fake_base[method]}\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1  # 모든 fake는 default\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt', 'funded_amnt']\n",
    "        fake = fake.drop(columns=keep_features)\n",
    "        fake['term_months'] = fake['term_months'].apply(lambda x: 36 if abs(x - 36) < abs(x - 60) else 60)\n",
    "        fake = encode_features(fake, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        base_x = base_data.drop(columns='loan_status')\n",
    "        base_y = base_data[['loan_status']]\n",
    "        X_base, _, y_base, _ = train_test_split(base_x, base_y, test_size=0.2, stratify=base_y, random_state=42)\n",
    "        train_real = pd.concat([X_base, y_base], axis=1)\n",
    "        train_total = pd.concat([train_real, fake])\n",
    "        train_total = shuffle(train_total, random_state=42)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b77285e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_with_sharpe_top = []\n",
    "\n",
    "summary_with_grade_top = []\n",
    "\n",
    "def linear_portfolio_top(Method, top_10_indices):\n",
    "    selected = test_data.loc[top_10_indices.index].copy()\n",
    "    returns = (selected['total_pymnt_inv'] - selected['funded_amnt']) / selected['funded_amnt']\n",
    "    \n",
    "    avg_return = returns.mean()\n",
    "    std_return = returns.std()\n",
    "    sharpe_ratio = avg_return / std_return if std_return != 0 else np.nan\n",
    "\n",
    "    summary_with_sharpe_top.append({\n",
    "        'Method': Method,\n",
    "        'Average Return': avg_return * 100,\n",
    "        'Std Dev': std_return,\n",
    "        'Sharpe Ratio': sharpe_ratio\n",
    "    }) \n",
    "\n",
    "    A_count = len(selected[selected['grade'] == 'A'])\n",
    "    B_count = len(selected[selected['grade'] == 'B'])\n",
    "    C_count = len(selected[selected['grade'] == 'C'])\n",
    "    D_count = len(selected[selected['grade'] == 'D'])\n",
    "    E_count = len(selected[selected['grade'] == 'E'])\n",
    "    F_G_count = len(selected[selected['grade'] == 'F']) + len(selected[selected['grade'] == 'G'])\n",
    "\n",
    "    summary_with_grade_top.append({\n",
    "        'Method': Method,\n",
    "        'A': A_count,\n",
    "        'B': B_count,\n",
    "        'C': C_count,\n",
    "        'D': D_count,\n",
    "        'E': E_count,\n",
    "        'F+G': F_G_count,\n",
    "        'Total': len(selected)\n",
    "    }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b609c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "##상위 10% 투자\n",
    "from imblearn.over_sampling import SMOTE\n",
    "drop2 = ['loan_status', 'return']\n",
    "\n",
    "def select_fully_paid(y_pred, method):\n",
    "    scaler = StandardScaler()\n",
    "    reg = LinearRegression()\n",
    "\n",
    "    fully_paid_indices = (y_pred == 0)\n",
    "    test_regression = test_data[fully_paid_indices]\n",
    "    test_regression['return'] = (test_regression['total_pymnt_inv'] - test_regression['funded_amnt'])/test_regression['funded_amnt']\n",
    "\n",
    "    train_regression = data.copy()\n",
    "\n",
    "    if method == 'Base':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        data_x = train_regression.drop(columns='return')\n",
    "        data_y = train_regression[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "        return method, top_10_percent\n",
    "    \n",
    "    elif method == 'Undersampling':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['loan_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        X_train = train_regression.drop(columns='loan_status')\n",
    "        y_train = train_regression[['loan_status']]\n",
    "\n",
    "        undersampler = RandomUnderSampler(random_state=42)\n",
    "        X_under, y_under = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        data_under = pd.concat([pd.DataFrame(X_under, columns=X_train.columns), pd.DataFrame(y_under, columns=['loan_status'])], axis=1)\n",
    "\n",
    "        data_x = data_under.drop(columns=drop2)  \n",
    "        data_y = data_under[['return']]  \n",
    "\n",
    "        test_x = test_regression.drop(columns = drop2)\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent\n",
    "    \n",
    "    elif method == 'SMOTE-NC':\n",
    "        smote_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/smotenc/smotenc_data.csv\"\n",
    "        data_smote = pd.read_csv(smote_path)\n",
    "        \n",
    "        data_smote['return'] = (data_smote['total_pymnt_inv'] - data_smote['funded_amnt'])/data_smote['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "\n",
    "        train_regression = data_smote.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        X_train = train_regression.drop(columns='return')\n",
    "        y_train = train_regression[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        #y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent\n",
    "    \n",
    "    elif method == 'table-gan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/tablegan/tablegan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent\n",
    "        \n",
    "    \n",
    "    elif method == 'vae-tablegan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/tablegan/vae-tablegan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    \n",
    "    elif method == 'ctgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    \n",
    "    elif method == 'vae-ctgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/vae-ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "\n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "    \n",
    "    elif method == 'ctabgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        \n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent \n",
    "\n",
    "    elif method == 'vae-ctabgan':\n",
    "        train_regression['return'] = (train_regression['total_pymnt_inv'] - train_regression['funded_amnt'])/train_regression['funded_amnt']\n",
    "        drop_features = ['loan_status','grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        train_regression = train_regression.drop(columns=drop_features)\n",
    "        test_regression = test_regression.drop(columns=drop_features)\n",
    "        \n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/vae-ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        fake_regression = fake.copy()\n",
    "\n",
    "        fake_regression['return'] = (fake_regression['total_pymnt_inv'] - fake_regression['funded_amnt'])/fake_regression['funded_amnt']\n",
    "        fake_regression = fake_regression.drop(columns=drop_features)\n",
    "        fake_regression['term_months'] = fake_regression['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        \n",
    "        train_regression = encode_features(train_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        test_regression = encode_features(test_regression, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        fake_regression = encode_features(fake_regression,label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        train_total = pd.concat([train_regression, fake_regression])\n",
    "\n",
    "        data_x = train_total.drop(columns='return')\n",
    "        data_y = train_total[['return']]\n",
    "\n",
    "        test_x = test_regression.drop(columns = 'return')\n",
    "        test_y = test_regression[['return']]\n",
    "\n",
    "        data_x_scaled = scaler.fit_transform(data_x)\n",
    "\n",
    "        X_train = data_x_scaled\n",
    "        y_train = data_y\n",
    "\n",
    "        test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        #print(reg.coef_)\n",
    "        y_pred = reg.predict(test_x_scaled)\n",
    "\n",
    "        print(\"RMSE:\", mean_squared_error(test_y, y_pred, squared=False))\n",
    "        print(\"R²:\", r2_score(test_y, y_pred))\n",
    "\n",
    "        test_regression['predicted_return'] = reg.predict(test_x_scaled)\n",
    "        top_10_percent = test_regression.sort_values(by='predicted_return', ascending=False).head(int(len(test_regression)*0.1))\n",
    "\n",
    "        return method, top_10_percent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ad8ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "classification_metrics_summary = []\n",
    "\n",
    "def return_evaluation(model, data_x, data_y, X_test, y_test, method):\n",
    "    print(f\"Preprocessing method : {method}\")\n",
    "\n",
    "    if method == 'Base':\n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2,\n",
    "                                                           random_state=42, stratify=data_y)\n",
    "        model.fit(\n",
    "        X_train, y_train\n",
    "        )\n",
    "\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "\n",
    "    elif method == 'Undersampling':\n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.13, random_state=42, stratify=data_y)\n",
    "        undersampler = RandomUnderSampler(random_state=42)\n",
    "        X_under, y_under = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        data_under = pd.concat([pd.DataFrame(X_under, columns=data_x.columns), pd.DataFrame(y_under, columns=['loan_status'])], axis=1)\n",
    "        X_train = data_under.drop(columns=['loan_status'])  # Feature (입력 데이터)\n",
    "        y_train = data_under[['loan_status']]  # Target (타겟 변수)\n",
    "\n",
    "        model.fit(\n",
    "        X_train, y_train\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    elif method == 'SMOTE-NC':\n",
    "        smote_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/smotenc/smotenc_data.csv\"\n",
    "        data_smote = pd.read_csv(smote_path)\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        data_smote_classification = data_smote.copy()\n",
    "        data_smote_classification = data_smote_classification.drop(columns = keep_features)\n",
    "\n",
    "        data_smote_classification = encode_features(data_smote_classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        data_x = data_smote_classification.drop(columns='loan_status') \n",
    "        data_y = data_smote_classification[['loan_status']]\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, random_state=42, stratify=data_y)\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'table-gan':\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/tablegan/tablegan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "        \n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, random_state=42, stratify=data_y)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total, random_state=42)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'vae-tablegan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/tablegan/vae-tablegan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'ctgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'vae-ctgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctgan/vae-ctgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'ctabgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'vae-ctabgan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/portfolios/ctabgan/vae-ctabgan.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'total_pymnt', 'total_pymnt_inv', 'loan_amnt','funded_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        fake_Classification['term_months'] = fake_Classification['term_months'].apply(lambda x:36 if abs(x-36)<abs(x-60) else 60)\n",
    "        fake_Classification = encode_features(fake_Classification, label_encoders, onehot_encoder, Labelencoding_features, onehot_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state=42)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    report = classification_report(\n",
    "        y_test, y_pred,\n",
    "        target_names=[\"Fully Paid\", \"Default\"],\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "    classification_metrics_summary.append({\n",
    "        \"Method\": method,\n",
    "        \"Class 0 Precision\": report[\"Fully Paid\"][\"precision\"],\n",
    "        \"Class 0 Recall\": report[\"Fully Paid\"][\"recall\"],\n",
    "        \"Class 0 F1\": report[\"Fully Paid\"][\"f1-score\"],\n",
    "        \"Class 1 Precision\": report[\"Default\"][\"precision\"],\n",
    "        \"Class 1 Recall\": report[\"Default\"][\"recall\"],\n",
    "        \"Class 1 F1\": report[\"Default\"][\"f1-score\"],\n",
    "        \"Macro Avg F1\": report[\"macro avg\"][\"f1-score\"],\n",
    "        \"Weighted Avg F1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "    })\n",
    "\n",
    "    #10% index뽑기기\n",
    "    Method, top_10_indices = select_fully_paid(y_pred, method)\n",
    "\n",
    "    #portfolio 만들기들기\n",
    "    linear_portfolio_top(Method, top_10_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e721ce1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : Base\n",
      "RMSE: 0.2255712121825778\n",
      "R²: 0.28348672641562445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  11%|█         | 1/9 [00:36<04:54, 36.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : Undersampling\n",
      "RMSE: 0.21079269931409053\n",
      "R²: -0.04847987488476457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  22%|██▏       | 2/9 [00:53<02:53, 24.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : SMOTE-NC\n",
      "RMSE: 0.21524131555684947\n",
      "R²: -0.06276604139076869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  33%|███▎      | 3/9 [01:53<04:05, 40.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : table-gan\n",
      "RMSE: 0.2106338311480332\n",
      "R²: -0.017375804058554545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  44%|████▍     | 4/9 [02:44<03:45, 45.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : vae-tablegan\n",
      "RMSE: 0.21332693278329593\n",
      "R²: 0.22529644061940746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  56%|█████▌    | 5/9 [03:40<03:15, 48.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : ctgan\n",
      "RMSE: 0.2063422317456705\n",
      "R²: 0.006387770952888228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  67%|██████▋   | 6/9 [04:35<02:33, 51.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : vae-ctgan\n",
      "RMSE: 0.2134991821459753\n",
      "R²: 0.22509816265809945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  78%|███████▊  | 7/9 [05:34<01:46, 53.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : ctabgan\n",
      "RMSE: 0.3149860736413162\n",
      "R²: -1.3487488809416863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  89%|████████▉ | 8/9 [06:27<00:53, 53.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : vae-ctabgan\n",
      "RMSE: 0.19611490220231476\n",
      "R²: 0.11334605906564399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods: 100%|██████████| 9/9 [07:18<00:00, 48.69s/it]\n"
     ]
    }
   ],
   "source": [
    "methods = [\n",
    "    'Base', 'Undersampling', 'SMOTE-NC',\n",
    "    'table-gan', 'vae-tablegan',\n",
    "    'ctgan', 'vae-ctgan',\n",
    "    'ctabgan', 'vae-ctabgan'\n",
    "]\n",
    "\n",
    "X_test = test_classification.drop(columns='loan_status')\n",
    "y_test = test_classification['loan_status']\n",
    "\n",
    "returns_df = pd.DataFrame()\n",
    "\n",
    "for method in tqdm(methods, desc=\"Methods\"):\n",
    "    data_x = data_classification.drop(columns='loan_status')\n",
    "    data_y = data_classification['loan_status']\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        penalty='l2',                  \n",
    "        C=1.0,                         \n",
    "        max_iter=500,                \n",
    "        n_jobs=-1,                    \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    return_evaluation(model, data_x, data_y, X_test, y_test, method)\n",
    "\n",
    "#classification 결과\n",
    "classification_metrics_df = pd.DataFrame(classification_metrics_summary)\n",
    "\n",
    "#상위 10% 투자전략\n",
    "returns_with_sharpe_df_top = pd.DataFrame(summary_with_sharpe_top)\n",
    "portfolio_grade_distribution_df_top = pd.DataFrame(summary_with_grade_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f572ebfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Class 0 Precision</th>\n",
       "      <th>Class 0 Recall</th>\n",
       "      <th>Class 0 F1</th>\n",
       "      <th>Class 1 Precision</th>\n",
       "      <th>Class 1 Recall</th>\n",
       "      <th>Class 1 F1</th>\n",
       "      <th>Macro Avg F1</th>\n",
       "      <th>Weighted Avg F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.839542</td>\n",
       "      <td>0.971838</td>\n",
       "      <td>0.900859</td>\n",
       "      <td>0.667763</td>\n",
       "      <td>0.233560</td>\n",
       "      <td>0.346075</td>\n",
       "      <td>0.623467</td>\n",
       "      <td>0.792637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undersampling</td>\n",
       "      <td>0.909530</td>\n",
       "      <td>0.777164</td>\n",
       "      <td>0.838153</td>\n",
       "      <td>0.425498</td>\n",
       "      <td>0.681015</td>\n",
       "      <td>0.523754</td>\n",
       "      <td>0.680954</td>\n",
       "      <td>0.776823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE-NC</td>\n",
       "      <td>0.906636</td>\n",
       "      <td>0.783277</td>\n",
       "      <td>0.840454</td>\n",
       "      <td>0.427275</td>\n",
       "      <td>0.667165</td>\n",
       "      <td>0.520929</td>\n",
       "      <td>0.680691</td>\n",
       "      <td>0.778124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>table-gan</td>\n",
       "      <td>0.905963</td>\n",
       "      <td>0.779301</td>\n",
       "      <td>0.837872</td>\n",
       "      <td>0.422487</td>\n",
       "      <td>0.666221</td>\n",
       "      <td>0.517071</td>\n",
       "      <td>0.677472</td>\n",
       "      <td>0.775293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vae-tablegan</td>\n",
       "      <td>0.874832</td>\n",
       "      <td>0.876085</td>\n",
       "      <td>0.875458</td>\n",
       "      <td>0.485644</td>\n",
       "      <td>0.482775</td>\n",
       "      <td>0.484205</td>\n",
       "      <td>0.679832</td>\n",
       "      <td>0.799137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ctgan</td>\n",
       "      <td>0.908726</td>\n",
       "      <td>0.780860</td>\n",
       "      <td>0.839955</td>\n",
       "      <td>0.427913</td>\n",
       "      <td>0.676366</td>\n",
       "      <td>0.524190</td>\n",
       "      <td>0.682072</td>\n",
       "      <td>0.778358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vae-ctgan</td>\n",
       "      <td>0.874665</td>\n",
       "      <td>0.876738</td>\n",
       "      <td>0.875700</td>\n",
       "      <td>0.486353</td>\n",
       "      <td>0.481597</td>\n",
       "      <td>0.483963</td>\n",
       "      <td>0.679832</td>\n",
       "      <td>0.799284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ctabgan</td>\n",
       "      <td>0.910042</td>\n",
       "      <td>0.785767</td>\n",
       "      <td>0.843351</td>\n",
       "      <td>0.434599</td>\n",
       "      <td>0.679493</td>\n",
       "      <td>0.530130</td>\n",
       "      <td>0.686741</td>\n",
       "      <td>0.782251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vae-ctabgan</td>\n",
       "      <td>0.906163</td>\n",
       "      <td>0.782828</td>\n",
       "      <td>0.839992</td>\n",
       "      <td>0.426156</td>\n",
       "      <td>0.665498</td>\n",
       "      <td>0.519590</td>\n",
       "      <td>0.679791</td>\n",
       "      <td>0.777491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Method  Class 0 Precision  Class 0 Recall  Class 0 F1  \\\n",
       "0           Base           0.839542        0.971838    0.900859   \n",
       "1  Undersampling           0.909530        0.777164    0.838153   \n",
       "2       SMOTE-NC           0.906636        0.783277    0.840454   \n",
       "3      table-gan           0.905963        0.779301    0.837872   \n",
       "4   vae-tablegan           0.874832        0.876085    0.875458   \n",
       "5          ctgan           0.908726        0.780860    0.839955   \n",
       "6      vae-ctgan           0.874665        0.876738    0.875700   \n",
       "7        ctabgan           0.910042        0.785767    0.843351   \n",
       "8    vae-ctabgan           0.906163        0.782828    0.839992   \n",
       "\n",
       "   Class 1 Precision  Class 1 Recall  Class 1 F1  Macro Avg F1  \\\n",
       "0           0.667763        0.233560    0.346075      0.623467   \n",
       "1           0.425498        0.681015    0.523754      0.680954   \n",
       "2           0.427275        0.667165    0.520929      0.680691   \n",
       "3           0.422487        0.666221    0.517071      0.677472   \n",
       "4           0.485644        0.482775    0.484205      0.679832   \n",
       "5           0.427913        0.676366    0.524190      0.682072   \n",
       "6           0.486353        0.481597    0.483963      0.679832   \n",
       "7           0.434599        0.679493    0.530130      0.686741   \n",
       "8           0.426156        0.665498    0.519590      0.679791   \n",
       "\n",
       "   Weighted Avg F1  \n",
       "0         0.792637  \n",
       "1         0.776823  \n",
       "2         0.778124  \n",
       "3         0.775293  \n",
       "4         0.799137  \n",
       "5         0.778358  \n",
       "6         0.799284  \n",
       "7         0.782251  \n",
       "8         0.777491  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_metrics_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a732afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Average Return</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>18.759043</td>\n",
       "      <td>0.147587</td>\n",
       "      <td>1.271047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undersampling</td>\n",
       "      <td>14.080652</td>\n",
       "      <td>0.108609</td>\n",
       "      <td>1.296458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE-NC</td>\n",
       "      <td>14.063036</td>\n",
       "      <td>0.109973</td>\n",
       "      <td>1.278770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>table-gan</td>\n",
       "      <td>13.368777</td>\n",
       "      <td>0.102612</td>\n",
       "      <td>1.302851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vae-tablegan</td>\n",
       "      <td>16.659611</td>\n",
       "      <td>0.125442</td>\n",
       "      <td>1.328071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ctgan</td>\n",
       "      <td>14.454617</td>\n",
       "      <td>0.104446</td>\n",
       "      <td>1.383930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vae-ctgan</td>\n",
       "      <td>16.663924</td>\n",
       "      <td>0.125483</td>\n",
       "      <td>1.327986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ctabgan</td>\n",
       "      <td>13.828176</td>\n",
       "      <td>0.162899</td>\n",
       "      <td>0.848882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vae-ctabgan</td>\n",
       "      <td>14.740086</td>\n",
       "      <td>0.106924</td>\n",
       "      <td>1.378553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Method  Average Return   Std Dev  Sharpe Ratio\n",
       "0           Base       18.759043  0.147587      1.271047\n",
       "1  Undersampling       14.080652  0.108609      1.296458\n",
       "2       SMOTE-NC       14.063036  0.109973      1.278770\n",
       "3      table-gan       13.368777  0.102612      1.302851\n",
       "4   vae-tablegan       16.659611  0.125442      1.328071\n",
       "5          ctgan       14.454617  0.104446      1.383930\n",
       "6      vae-ctgan       16.663924  0.125483      1.327986\n",
       "7        ctabgan       13.828176  0.162899      0.848882\n",
       "8    vae-ctabgan       14.740086  0.106924      1.378553"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_with_sharpe_df_top.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cc00db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F+G</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>9883</td>\n",
       "      <td>18525</td>\n",
       "      <td>20245</td>\n",
       "      <td>11582</td>\n",
       "      <td>6955</td>\n",
       "      <td>2162</td>\n",
       "      <td>69352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undersampling</td>\n",
       "      <td>16611</td>\n",
       "      <td>17229</td>\n",
       "      <td>12256</td>\n",
       "      <td>4156</td>\n",
       "      <td>875</td>\n",
       "      <td>65</td>\n",
       "      <td>51192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE-NC</td>\n",
       "      <td>17438</td>\n",
       "      <td>17315</td>\n",
       "      <td>11782</td>\n",
       "      <td>4258</td>\n",
       "      <td>893</td>\n",
       "      <td>73</td>\n",
       "      <td>51759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>table-gan</td>\n",
       "      <td>15292</td>\n",
       "      <td>18042</td>\n",
       "      <td>12646</td>\n",
       "      <td>4681</td>\n",
       "      <td>799</td>\n",
       "      <td>75</td>\n",
       "      <td>51535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vae-tablegan</td>\n",
       "      <td>13265</td>\n",
       "      <td>19121</td>\n",
       "      <td>15949</td>\n",
       "      <td>7744</td>\n",
       "      <td>2983</td>\n",
       "      <td>935</td>\n",
       "      <td>59997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ctgan</td>\n",
       "      <td>16159</td>\n",
       "      <td>17976</td>\n",
       "      <td>12320</td>\n",
       "      <td>4155</td>\n",
       "      <td>815</td>\n",
       "      <td>56</td>\n",
       "      <td>51481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vae-ctgan</td>\n",
       "      <td>13270</td>\n",
       "      <td>19131</td>\n",
       "      <td>15966</td>\n",
       "      <td>7756</td>\n",
       "      <td>2989</td>\n",
       "      <td>941</td>\n",
       "      <td>60053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ctabgan</td>\n",
       "      <td>2989</td>\n",
       "      <td>15363</td>\n",
       "      <td>22896</td>\n",
       "      <td>9582</td>\n",
       "      <td>876</td>\n",
       "      <td>23</td>\n",
       "      <td>51729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vae-ctabgan</td>\n",
       "      <td>15544</td>\n",
       "      <td>17545</td>\n",
       "      <td>13178</td>\n",
       "      <td>4657</td>\n",
       "      <td>791</td>\n",
       "      <td>42</td>\n",
       "      <td>51757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Method      A      B      C      D     E   F+G  Total\n",
       "0           Base   9883  18525  20245  11582  6955  2162  69352\n",
       "1  Undersampling  16611  17229  12256   4156   875    65  51192\n",
       "2       SMOTE-NC  17438  17315  11782   4258   893    73  51759\n",
       "3      table-gan  15292  18042  12646   4681   799    75  51535\n",
       "4   vae-tablegan  13265  19121  15949   7744  2983   935  59997\n",
       "5          ctgan  16159  17976  12320   4155   815    56  51481\n",
       "6      vae-ctgan  13270  19131  15966   7756  2989   941  60053\n",
       "7        ctabgan   2989  15363  22896   9582   876    23  51729\n",
       "8    vae-ctabgan  15544  17545  13178   4657   791    42  51757"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_grade_distribution_df_top.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91bad410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       A      B      C      D      E   F+G\n",
      "0  14.25  26.71  29.19  16.70  10.03  3.12\n",
      "1  32.45  33.66  23.94   8.12   1.71  0.13\n",
      "2  33.69  33.45  22.76   8.23   1.73  0.14\n",
      "3  29.67  35.01  24.54   9.08   1.55  0.15\n",
      "4  22.11  31.87  26.58  12.91   4.97  1.56\n",
      "5  31.39  34.92  23.93   8.07   1.58  0.11\n",
      "6  22.10  31.86  26.59  12.92   4.98  1.57\n",
      "7   5.78  29.70  44.26  18.52   1.69  0.04\n",
      "8  30.03  33.90  25.46   9.00   1.53  0.08\n"
     ]
    }
   ],
   "source": [
    "portfolio_grade = portfolio_grade_distribution_df_top.copy()\n",
    "\n",
    "grade_columns = ['A', 'B', 'C', 'D', 'E', 'F+G']\n",
    "\n",
    "for col in grade_columns:\n",
    "    portfolio_grade[col] = (portfolio_grade[col] / portfolio_grade['Total']) * 100\n",
    "    portfolio_grade[col] = round(portfolio_grade[col],2)\n",
    "\n",
    "# 결과 출력\n",
    "print(portfolio_grade[[col for col in grade_columns]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5aafb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F+G</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>14.25</td>\n",
       "      <td>26.71</td>\n",
       "      <td>29.19</td>\n",
       "      <td>16.70</td>\n",
       "      <td>10.03</td>\n",
       "      <td>3.12</td>\n",
       "      <td>69352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undersampling</td>\n",
       "      <td>32.45</td>\n",
       "      <td>33.66</td>\n",
       "      <td>23.94</td>\n",
       "      <td>8.12</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.13</td>\n",
       "      <td>51192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE-NC</td>\n",
       "      <td>33.69</td>\n",
       "      <td>33.45</td>\n",
       "      <td>22.76</td>\n",
       "      <td>8.23</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.14</td>\n",
       "      <td>51759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>table-gan</td>\n",
       "      <td>29.67</td>\n",
       "      <td>35.01</td>\n",
       "      <td>24.54</td>\n",
       "      <td>9.08</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.15</td>\n",
       "      <td>51535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vae-tablegan</td>\n",
       "      <td>22.11</td>\n",
       "      <td>31.87</td>\n",
       "      <td>26.58</td>\n",
       "      <td>12.91</td>\n",
       "      <td>4.97</td>\n",
       "      <td>1.56</td>\n",
       "      <td>59997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ctgan</td>\n",
       "      <td>31.39</td>\n",
       "      <td>34.92</td>\n",
       "      <td>23.93</td>\n",
       "      <td>8.07</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.11</td>\n",
       "      <td>51481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vae-ctgan</td>\n",
       "      <td>22.10</td>\n",
       "      <td>31.86</td>\n",
       "      <td>26.59</td>\n",
       "      <td>12.92</td>\n",
       "      <td>4.98</td>\n",
       "      <td>1.57</td>\n",
       "      <td>60053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ctabgan</td>\n",
       "      <td>5.78</td>\n",
       "      <td>29.70</td>\n",
       "      <td>44.26</td>\n",
       "      <td>18.52</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.04</td>\n",
       "      <td>51729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vae-ctabgan</td>\n",
       "      <td>30.03</td>\n",
       "      <td>33.90</td>\n",
       "      <td>25.46</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.08</td>\n",
       "      <td>51757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Method      A      B      C      D      E   F+G  Total\n",
       "0           Base  14.25  26.71  29.19  16.70  10.03  3.12  69352\n",
       "1  Undersampling  32.45  33.66  23.94   8.12   1.71  0.13  51192\n",
       "2       SMOTE-NC  33.69  33.45  22.76   8.23   1.73  0.14  51759\n",
       "3      table-gan  29.67  35.01  24.54   9.08   1.55  0.15  51535\n",
       "4   vae-tablegan  22.11  31.87  26.58  12.91   4.97  1.56  59997\n",
       "5          ctgan  31.39  34.92  23.93   8.07   1.58  0.11  51481\n",
       "6      vae-ctgan  22.10  31.86  26.59  12.92   4.98  1.57  60053\n",
       "7        ctabgan   5.78  29.70  44.26  18.52   1.69  0.04  51729\n",
       "8    vae-ctabgan  30.03  33.90  25.46   9.00   1.53  0.08  51757"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_grade.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CTGAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
