{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4426647e",
   "metadata": {},
   "source": [
    "## 생성형 데이터와 original 데이터 간에 각 분포 차이. \n",
    "- Wasserstein_distance\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8aebfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, log_loss\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch \n",
    "import os\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fafb9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load original data\n",
    "data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/Dataset/return_feature_train.csv\"\n",
    "data = pd.read_csv(data_path, low_memory=False)\n",
    "\n",
    "##load test data\n",
    "test_data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/Dataset/return_feature_test.csv\"\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "#Fake dataset\n",
    "fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/tablegan/samples/return_feature/return_feature_OI_11_00_fake.csv\"\n",
    "fake = pd.read_csv(fake_path)\n",
    "fake['loan_status'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "327f85a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['loan_status'].value_counts()\n",
    "\n",
    "X_train, X_val = train_test_split(data, test_size = 0.2, stratify = data['loan_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51903224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_status\n",
       "0    718935\n",
       "1    174231\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed237e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_features = ['grade', 'term_months', 'total_pymnt', 'total_pymnt_inv']\n",
    "\n",
    "data_classification = data.copy()\n",
    "test_classification = test_data.copy()\n",
    "fake_Classification = fake.copy()\n",
    "\n",
    "data_classification = data_classification.drop(columns = keep_features)\n",
    "test_classification = test_classification.drop(columns = keep_features)\n",
    "fake_Classification = fake_Classification.drop(columns = keep_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553c465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "import pandas as pd\n",
    "\n",
    "def compute_wasserstein_topk(real_df: pd.DataFrame, fake_df: pd.DataFrame, top_k: int = 5, visualize: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    각 feature별 Wasserstein Distance를 계산하고, 차이가 큰 top-k feature를 반환합니다.\n",
    "\n",
    "    Parameters:\n",
    "    - real_df (pd.DataFrame): 원본 데이터\n",
    "    - fake_df (pd.DataFrame): 생성된 데이터\n",
    "    - top_k (int): 차이가 큰 상위 K개의 feature 추출\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: feature 이름과 Wasserstein Distance 포함된 top-k 데이터프레임\n",
    "    \"\"\"\n",
    "    assert list(data_classification.columns) == list(fake_Classification.columns), \"컬럼 이름이 일치해야 합니다.\"\n",
    "\n",
    "    distances = {}\n",
    "    for col in real_df.columns:\n",
    "        real_col = data_classification[col].dropna()\n",
    "        fake_col = fake_Classification[col].dropna()\n",
    "        distances[col] = wasserstein_distance(real_col, fake_col)\n",
    "\n",
    "    dist_series = pd.Series(distances, name=\"Wasserstein Distance\")\n",
    "    mean_distance = dist_series.mean()\n",
    "    print(f\"📏 평균 Wasserstein Distance: {mean_distance:.4f}\")\n",
    "    \n",
    "    topk_df = dist_series.sort_values(ascending=False).head(top_k).reset_index()\n",
    "    topk_df.columns = [\"Feature\", \"Wasserstein Distance\"]\n",
    "\n",
    "    # 📊 시각화\n",
    "    if visualize:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(data=topk_df, x=\"Wasserstein Distance\", y=\"Feature\", palette=\"viridis\")\n",
    "        plt.title(f\"Top {top_k} Features with Highest Wasserstein Distance\")\n",
    "        plt.xlabel(\"Wasserstein Distance\")\n",
    "        plt.ylabel(\"Feature\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return topk_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e78281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_result = compute_wasserstein_topk(real, fake, top_k=3, visualize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a1fd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# ✅ 1. MMD 시각화 함수\n",
    "def visualize_mmd_matrix(real_df, fake_df, gamma=1.0):\n",
    "    real_k = rbf_kernel(real_df, real_df, gamma=gamma)\n",
    "    fake_k = rbf_kernel(fake_df, fake_df, gamma=gamma)\n",
    "    cross_k = rbf_kernel(real_df, fake_df, gamma=gamma)\n",
    "\n",
    "    # 전체 커널 평균 계산\n",
    "    mmd_value = real_k.mean() + fake_k.mean() - 2 * cross_k.mean()\n",
    "    print(f\"📏 MMD (RBF, γ={gamma}): {mmd_value:.4f}\")\n",
    "\n",
    "    # 시각화 (real vs fake kernel matrix)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    sns.heatmap(real_k[:100, :100], ax=axes[0], cmap='Blues')\n",
    "    axes[0].set_title(\"Real Kernel Matrix\")\n",
    "    sns.heatmap(fake_k[:100, :100], ax=axes[1], cmap='Oranges')\n",
    "    axes[1].set_title(\"Fake Kernel Matrix\")\n",
    "    plt.suptitle(\"MMD - RBF Kernel Matrix Visualization (Top 100 samples)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ✅ 2. Correlation Matrix Distance 시각화 함수\n",
    "def visualize_correlation_difference(real_df, fake_df):\n",
    "    real_corr = real_df.corr()\n",
    "    fake_corr = fake_df.corr()\n",
    "    diff_corr = np.abs(real_corr - fake_corr)\n",
    "\n",
    "    distance = np.linalg.norm(real_corr - fake_corr, ord='fro')\n",
    "    print(f\"📏 Correlation Matrix Distance (Frobenius Norm): {distance:.4f}\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    sns.heatmap(real_corr, ax=axes[0], cmap='coolwarm', center=0, annot=False)\n",
    "    axes[0].set_title(\"Real Correlation\")\n",
    "    sns.heatmap(fake_corr, ax=axes[1], cmap='coolwarm', center=0, annot=False)\n",
    "    axes[1].set_title(\"Fake Correlation\")\n",
    "    sns.heatmap(diff_corr, ax=axes[2], cmap='YlOrRd')\n",
    "    axes[2].set_title(\"Difference (|Real - Fake|)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ✅ 3. PCA 시각화 함수\n",
    "def visualize_pca_projection(real_df, fake_df):\n",
    "    combined = pd.concat([real_df, fake_df])\n",
    "    labels = [0] * len(real_df) + [1] * len(fake_df)\n",
    "    pca = PCA(n_components=2)\n",
    "    components = pca.fit_transform(combined)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.scatterplot(x=components[:, 0], y=components[:, 1], hue=labels,\n",
    "                    palette=['blue', 'orange'], alpha=0.6)\n",
    "    plt.title(\"PCA Projection (Blue: Real, Orange: Fake)\")\n",
    "    plt.xlabel(\"Principal Component 1\")\n",
    "    plt.ylabel(\"Principal Component 2\")\n",
    "    plt.legend(title=\"Data\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca77e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = data_classification\n",
    "fake_df = fake_classification\n",
    "\n",
    "visualize_mmd_matrix(real_df, fake_df, gamma=1.0)\n",
    "visualize_correlation_difference(real_df, fake_df)\n",
    "visualize_pca_projection(real_df, fake_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CTGAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
