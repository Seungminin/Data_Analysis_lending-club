{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, log_loss\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch \n",
    "import os\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load original data\n",
    "data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/Dataset/train_dataset.csv\"\n",
    "data = pd.read_csv(data_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load test data\n",
    "test_data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/Dataset/test_dataset.csv\"\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data.drop(columns='loan_status')\n",
    "data_y = data[['loan_status']]\n",
    "\n",
    "X_test = test_data.drop(columns='loan_status')\n",
    "y_test = test_data[['loan_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.25, random_state=42, stratify=data_y)\n",
    "\n",
    "print(f\"Train size: {X_train.shape[0]} samples ({X_train.shape[0]/len(data):.1%})\")\n",
    "print(f\"Validation size: {X_val.shape[0]} samples ({X_val.shape[0]/len(data):.1%})\")\n",
    "print(f\"Test size: {X_test.shape[0]} samples ({X_test.shape[0]/len(data):.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##GridSearch hyperparameter tuning.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 1ï¸âƒ£ XGBoost ëª¨ë¸ ì •ì˜\n",
    "model = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.01,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2ï¸âƒ£ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300],\n",
    "    'learning_rate': [0.1, 0.01, 0.05, 0.001],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# 3ï¸âƒ£ GridSearchCV ì •ì˜\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1-weighted',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4ï¸âƒ£ í•™ìŠµ ìˆ˜í–‰\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 5ï¸âƒ£ ìµœì  ëª¨ë¸ë¡œ í•™ìŠµ ë° eval ë¡œê·¸ í™•ì¸\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "best_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# 6ï¸âƒ£ Loss ê·¸ë˜í”„ ì‹œê°í™”\n",
    "evals_result = best_model.evals_result()\n",
    "train_loss = evals_result['validation_0']['logloss']\n",
    "val_loss = evals_result['validation_1']['logloss']\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_loss, label='Train Loss (Log Loss)', color='blue')\n",
    "plt.plot(val_loss, label='Validation Loss (Log Loss)', color='red')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.title('XGBoost Training & Validation Loss Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 7ï¸âƒ£ ì˜ˆì¸¡ ë° í‰ê°€\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"ğŸ”¹ Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 8ï¸âƒ£ ROC Curve & PRC ì‹œê°í™”\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "auc_roc = auc(fpr, tpr)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "auc_prc = auc(recall, precision)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, label=f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, label=f\"AU-PRC: {auc_prc:.4f}\", color=\"green\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9ï¸âƒ£ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶œë ¥\n",
    "print(\"âœ… Best Hyperparameters:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8ï¸âƒ£ ROC & Precision-Recall Curve ì‹œê°í™” í•¨ìˆ˜\n",
    "def plot_evaluation_curves(fpr, tpr, auc_roc, recall, precision, auc_prc):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # ğŸ”¹ ROC Curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(fpr, tpr, marker='.', label=f\"AUC-ROC = {auc_roc:.4f}\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # ëœë¤ ëª¨ë¸ ê¸°ì¤€ì„ \n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title('ROC Curve_undersampling')\n",
    "    plt.legend()\n",
    "\n",
    "    # ğŸ”¹ Precision-Recall Curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(recall, precision, marker='.', label=f\"AU-PRC = {auc_prc:.4f}\")\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve_undersampling')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 9ï¸âƒ£ ê²°ê³¼ ì‹œê°í™” ì‹¤í–‰\n",
    "plot_evaluation_curves(fpr, tpr, auc_roc, recall, precision, auc_prc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load original data\n",
    "data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/Dataset/train_dataset.csv\"\n",
    "data = pd.read_csv(data_path, low_memory=False)\n",
    "\n",
    "##load test data\n",
    "test_data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/Dataset/test_dataset.csv\"\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data.drop(columns='loan_status')\n",
    "data_y = data[['loan_status']]\n",
    "\n",
    "X_test = test_data.drop(columns = \"loan_status\")\n",
    "y_test = test_data[['loan_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ê°œìˆ˜ í™•ì¸\n",
    "print(\"Original class distribution:\\n\", data_y.value_counts())\n",
    "\n",
    "# ì–¸ë”ìƒ˜í”Œë§ ì ìš© (Random Undersampling)\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_under, y_under = undersampler.fit_resample(data_x, data_y)\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸ (ê° ë°ì´í„°ì…‹ í¬ê¸°)\n",
    "print(f\"Original data size: {data_x.shape[0]} samples\")\n",
    "print(f\"Undersampled data size: {X_under.shape[0]} samples\")\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ ë³€í™˜ (í•„ìš”í•˜ë©´)\n",
    "data_under = pd.concat([pd.DataFrame(X_under, columns=data_x.columns), pd.DataFrame(y_under, columns=['loan_status'])], axis=1)\n",
    "\n",
    "# ì–¸ë”ìƒ˜í”Œë§ ë° ì˜¤ë²„ìƒ˜í”Œë§ ê²°ê³¼ í™•ì¸\n",
    "print(f\"\\nUndersampling imbalance check\\n{data_under['loan_status'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data_under.drop(columns=['loan_status'])  # Feature (ì…ë ¥ ë°ì´í„°)\n",
    "data_y = data_under[['loan_status']]  # Target (íƒ€ê²Ÿ ë³€ìˆ˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data under 6:2:2 train,val,test set\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.20, random_state=42, stratify=data_y)\n",
    "\n",
    "print(f\"Train size: {X_train.shape[0]} samples ({X_train.shape[0]/len(data_under):.1%})\")\n",
    "print(f\"Validation size: {X_val.shape[0]} samples ({X_val.shape[0]/len(data_under):.1%})\")\n",
    "print(f\"Test size: {X_test.shape[0]} samples ({X_test.shape[0]/len(data_under):.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##GridSearch hyperparameter tuning.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 1ï¸âƒ£ XGBoost ëª¨ë¸ ì •ì˜\n",
    "model = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.01,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2ï¸âƒ£ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300],\n",
    "    'learning_rate': [0.1, 0.01, 0.05, 0.001],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# 3ï¸âƒ£ GridSearchCV ì •ì˜\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1-weighted',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4ï¸âƒ£ í•™ìŠµ ìˆ˜í–‰\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 5ï¸âƒ£ ìµœì  ëª¨ë¸ë¡œ í•™ìŠµ ë° eval ë¡œê·¸ í™•ì¸\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "best_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# 6ï¸âƒ£ Loss ê·¸ë˜í”„ ì‹œê°í™”\n",
    "evals_result = best_model.evals_result()\n",
    "train_loss = evals_result['validation_0']['logloss']\n",
    "val_loss = evals_result['validation_1']['logloss']\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_loss, label='Train Loss (Log Loss)', color='blue')\n",
    "plt.plot(val_loss, label='Validation Loss (Log Loss)', color='red')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.title('XGBoost Training & Validation Loss Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 7ï¸âƒ£ ì˜ˆì¸¡ ë° í‰ê°€\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"ğŸ”¹ Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 8ï¸âƒ£ ROC Curve & PRC ì‹œê°í™”\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "auc_roc = auc(fpr, tpr)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "auc_prc = auc(recall, precision)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, label=f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, label=f\"AU-PRC: {auc_prc:.4f}\", color=\"green\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9ï¸âƒ£ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶œë ¥\n",
    "print(\"âœ… Best Hyperparameters:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8ï¸âƒ£ ROC & Precision-Recall Curve ì‹œê°í™” í•¨ìˆ˜\n",
    "def plot_evaluation_curves(fpr, tpr, auc_roc, recall, precision, auc_prc):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # ğŸ”¹ ROC Curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(fpr, tpr, marker='.', label=f\"AUC-ROC = {auc_roc:.4f}\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # ëœë¤ ëª¨ë¸ ê¸°ì¤€ì„ \n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title('ROC Curve_undersampling')\n",
    "    plt.legend()\n",
    "\n",
    "    # ğŸ”¹ Precision-Recall Curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(recall, precision, marker='.', label=f\"AU-PRC = {auc_prc:.4f}\")\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve_undersampling')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 9ï¸âƒ£ ê²°ê³¼ ì‹œê°í™” ì‹¤í–‰\n",
    "plot_evaluation_curves(fpr, tpr, auc_roc, recall, precision, auc_prc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load test data\n",
    "test_data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/Dataset/test_dataset.csv\"\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/Dataset/smote_data.csv\"\n",
    "augmentation_data = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Augmentation_data the number of columns : {len(augmentation_data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smotenc = augmentation_data.drop(columns='loan_status')\n",
    "y_train_smotenc = augmentation_data[['loan_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data under 6:2:2 train,val,test set\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_smotenc, y_train_smotenc, test_size=0.2, random_state=42, stratify=y_train_smotenc)\n",
    "\n",
    "print(f\"Train size: {X_train.shape[0]} samples ({X_train.shape[0]/len(augmentation_data):.1%})\")\n",
    "print(f\"Validation size: {X_val.shape[0]} samples ({X_val.shape[0]/len(augmentation_data):.1%})\")\n",
    "print(f\"Test size: {X_test.shape[0]} samples ({X_test.shape[0]/len(augmentation_data):.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##GridSearch hyperparameter tuning.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 1ï¸âƒ£ XGBoost ëª¨ë¸ ì •ì˜\n",
    "model = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.01,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2ï¸âƒ£ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300],\n",
    "    'learning_rate': [0.1, 0.01, 0.05, 0.001],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# 3ï¸âƒ£ GridSearchCV ì •ì˜\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1-weighted',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4ï¸âƒ£ í•™ìŠµ ìˆ˜í–‰\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 5ï¸âƒ£ ìµœì  ëª¨ë¸ë¡œ í•™ìŠµ ë° eval ë¡œê·¸ í™•ì¸\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "best_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# 6ï¸âƒ£ Loss ê·¸ë˜í”„ ì‹œê°í™”\n",
    "evals_result = best_model.evals_result()\n",
    "train_loss = evals_result['validation_0']['logloss']\n",
    "val_loss = evals_result['validation_1']['logloss']\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_loss, label='Train Loss (Log Loss)', color='blue')\n",
    "plt.plot(val_loss, label='Validation Loss (Log Loss)', color='red')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.title('XGBoost Training & Validation Loss Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 7ï¸âƒ£ ì˜ˆì¸¡ ë° í‰ê°€\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"ğŸ”¹ Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 8ï¸âƒ£ ROC Curve & PRC ì‹œê°í™”\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "auc_roc = auc(fpr, tpr)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "auc_prc = auc(recall, precision)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, label=f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, label=f\"AU-PRC: {auc_prc:.4f}\", color=\"green\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9ï¸âƒ£ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶œë ¥\n",
    "print(\"âœ… Best Hyperparameters:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8ï¸âƒ£ ROC & Precision-Recall Curve ì‹œê°í™” í•¨ìˆ˜\n",
    "def plot_evaluation_curves(fpr, tpr, auc_roc, recall, precision, auc_prc):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # ğŸ”¹ ROC Curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(fpr, tpr, marker='.', label=f\"AUC-ROC = {auc_roc:.4f}\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # ëœë¤ ëª¨ë¸ ê¸°ì¤€ì„ \n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title('ROC Curve_undersampling')\n",
    "    plt.legend()\n",
    "\n",
    "    # ğŸ”¹ Precision-Recall Curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(recall, precision, marker='.', label=f\"AU-PRC = {auc_prc:.4f}\")\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve_undersampling')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 9ï¸âƒ£ ê²°ê³¼ ì‹œê°í™” ì‹¤í–‰\n",
    "plot_evaluation_curves(fpr, tpr, auc_roc, recall, precision, auc_prc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
