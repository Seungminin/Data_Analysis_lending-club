{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63a68d4b",
   "metadata": {},
   "source": [
    "## 여러 machine Learning model 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e244d88",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b29ca564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, log_loss\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch \n",
    "import os\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9cda38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load original data\n",
    "data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/Dataset/return_feature_train.csv\"\n",
    "data = pd.read_csv(data_path, low_memory=False)\n",
    "\n",
    "##load test data\n",
    "test_data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/Dataset/return_feature_test.csv\"\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12925537",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_features = ['grade', 'term_months', 'total_pymnt', 'total_pymnt_inv','total_il_high_credit_limit', 'loan_amnt']\n",
    "\n",
    "data_classification = data.copy()\n",
    "test_classification = test_data.copy()\n",
    "\n",
    "data_classification = data_classification.drop(columns = keep_features)\n",
    "test_classification = test_classification.drop(columns = keep_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdd4e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data_classification.drop(columns='loan_status')\n",
    "data_y = data_classification[['loan_status']]\n",
    "\n",
    "X_test = test_classification.drop(columns='loan_status')\n",
    "y_test = test_classification[['loan_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93922314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "def method_evaluation(model, data_x, data_y, X_test, y_test, method):\n",
    "    print(f\"Preprocessing method : {method}\")\n",
    "\n",
    "    if method == 'Base':\n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y)\n",
    "\n",
    "        model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    elif method == 'Undersampling':\n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.13, stratify=data_y)\n",
    "        undersampler = RandomUnderSampler()\n",
    "        X_under, y_under = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        data_under = pd.concat([pd.DataFrame(X_under, columns=data_x.columns), pd.DataFrame(y_under, columns=['loan_status'])], axis=1)\n",
    "        X_train = data_under.drop(columns=['loan_status'])  # Feature (입력 데이터)\n",
    "        y_train = data_under[['loan_status']]  # Target (타겟 변수)\n",
    "\n",
    "        model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    elif method == 'SMOTE':\n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.33, stratify=data_y)\n",
    "\n",
    "        smote = SMOTE()\n",
    "\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        augmentation_data = pd.concat([X_train_smote, y_train_smote], axis = 1)\n",
    "        X_train = augmentation_data.drop(columns='loan_status')\n",
    "        y_train = augmentation_data[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    elif method == 'table-gan':\n",
    "        #Fake dataset\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/tablegan/samples/return_feature/return_feature_OI_11_00_fake.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "        \n",
    "        keep_features = ['grade', 'term_months', 'total_pymnt', 'total_pymnt_inv','total_il_high_credit_limit', 'loan_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.33, stratify=data_y)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total, random_state=42)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    elif method == 'Smotified-gan':\n",
    "        fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/tablegan/samples/oversampled/oversampled_OI_11_00_fake.csv\"\n",
    "        fake = pd.read_csv(fake_path)\n",
    "        fake['loan_status'] = 1\n",
    "\n",
    "        keep_features = ['grade', 'term_months', 'total_pymnt', 'total_pymnt_inv','total_il_high_credit_limit', 'loan_amnt']\n",
    "        fake_Classification = fake.copy()\n",
    "        fake_Classification = fake_Classification.drop(columns = keep_features)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y)\n",
    "        train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "        \n",
    "        train_total = pd.concat([train_dataset,fake_Classification])\n",
    "        train_total = shuffle(train_total)\n",
    "\n",
    "        X_train = train_total.drop(columns='loan_status')\n",
    "        y_train = train_total[['loan_status']]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],  # Train & Validation Loss 저장\n",
    "        )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # ROC Curve & PRC에 필요\n",
    "\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "\n",
    "    precision_0 = precision_score(y_test, y_pred, pos_label=0)\n",
    "    recall_0 = recall_score(y_test, y_pred, pos_label=0)\n",
    "    f1_0 = f1_score(y_test, y_pred, pos_label=0)\n",
    "\n",
    "    precision_1 = precision_score(y_test, y_pred, pos_label=1)\n",
    "    recall_1 = recall_score(y_test, y_pred, pos_label=1)\n",
    "    f1_1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "    au_prc = auc(recall, precision)\n",
    "\n",
    "    results_summary.append({\n",
    "    'Method': method,\n",
    "    'Recall_0': recall_0,\n",
    "    'Precision_0': precision_0,\n",
    "    'F1_0': f1_0,\n",
    "    'Recall_1': recall_1,\n",
    "    'Precision_1': precision_1,\n",
    "    'F1_1': f1_1,\n",
    "    'AU_PRC': au_prc,\n",
    "    'y_prob': y_prob,\n",
    "    'y_test': y_test.squeeze()  \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99954d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Base 시작 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Base Repeats:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : Base\n",
      "[LightGBM] [Info] Number of positive: 174231, number of negative: 718935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2974\n",
      "[LightGBM] [Info] Number of data points in the train set: 893166, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.195071 -> initscore=-1.417389\n",
      "[LightGBM] [Info] Start training from score -1.417389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Base Repeats:   1%|          | 1/100 [00:01<02:40,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : Base\n",
      "[LightGBM] [Info] Number of positive: 174231, number of negative: 718935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012987 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2976\n",
      "[LightGBM] [Info] Number of data points in the train set: 893166, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.195071 -> initscore=-1.417389\n",
      "[LightGBM] [Info] Start training from score -1.417389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Base Repeats:   2%|▏         | 2/100 [00:03<02:34,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : Base\n",
      "[LightGBM] [Info] Number of positive: 174231, number of negative: 718935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2974\n",
      "[LightGBM] [Info] Number of data points in the train set: 893166, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.195071 -> initscore=-1.417389\n",
      "[LightGBM] [Info] Start training from score -1.417389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Base Repeats:   3%|▎         | 3/100 [00:04<02:32,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : Base\n",
      "[LightGBM] [Info] Number of positive: 174231, number of negative: 718935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2976\n",
      "[LightGBM] [Info] Number of data points in the train set: 893166, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.195071 -> initscore=-1.417389\n",
      "[LightGBM] [Info] Start training from score -1.417389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Base Repeats:   4%|▍         | 4/100 [00:06<02:31,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : Base\n",
      "[LightGBM] [Info] Number of positive: 174231, number of negative: 718935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012996 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2975\n",
      "[LightGBM] [Info] Number of data points in the train set: 893166, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.195071 -> initscore=-1.417389\n",
      "[LightGBM] [Info] Start training from score -1.417389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Base Repeats:   5%|▌         | 5/100 [00:07<02:28,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : Base\n",
      "[LightGBM] [Info] Number of positive: 174231, number of negative: 718935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2972\n",
      "[LightGBM] [Info] Number of data points in the train set: 893166, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.195071 -> initscore=-1.417389\n",
      "[LightGBM] [Info] Start training from score -1.417389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Base Repeats:   6%|▌         | 6/100 [00:09<02:26,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : Base\n",
      "[LightGBM] [Info] Number of positive: 174231, number of negative: 718935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2975\n",
      "[LightGBM] [Info] Number of data points in the train set: 893166, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.195071 -> initscore=-1.417389\n",
      "[LightGBM] [Info] Start training from score -1.417389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Base Repeats:   7%|▋         | 7/100 [00:10<02:24,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : Base\n",
      "[LightGBM] [Info] Number of positive: 174231, number of negative: 718935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2974\n",
      "[LightGBM] [Info] Number of data points in the train set: 893166, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.195071 -> initscore=-1.417389\n",
      "[LightGBM] [Info] Start training from score -1.417389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Base Repeats:   8%|▊         | 8/100 [00:12<02:24,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : Base\n",
      "[LightGBM] [Info] Number of positive: 174231, number of negative: 718935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2974\n",
      "[LightGBM] [Info] Number of data points in the train set: 893166, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.195071 -> initscore=-1.417389\n",
      "[LightGBM] [Info] Start training from score -1.417389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Base Repeats:   9%|▉         | 9/100 [00:14<02:22,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : Base\n",
      "[LightGBM] [Info] Number of positive: 174231, number of negative: 718935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2972\n",
      "[LightGBM] [Info] Number of data points in the train set: 893166, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.195071 -> initscore=-1.417389\n",
      "[LightGBM] [Info] Start training from score -1.417389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Base Repeats:  10%|█         | 10/100 [00:15<02:19,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : Base\n",
      "[LightGBM] [Info] Number of positive: 174231, number of negative: 718935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2974\n",
      "[LightGBM] [Info] Number of data points in the train set: 893166, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.195071 -> initscore=-1.417389\n",
      "[LightGBM] [Info] Start training from score -1.417389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Base Repeats:  11%|█         | 11/100 [00:17<02:19,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : Base\n",
      "[LightGBM] [Info] Number of positive: 174231, number of negative: 718935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2974\n",
      "[LightGBM] [Info] Number of data points in the train set: 893166, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.195071 -> initscore=-1.417389\n",
      "[LightGBM] [Info] Start training from score -1.417389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Base Repeats:  12%|█▏        | 12/100 [00:18<02:17,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : Base\n",
      "[LightGBM] [Info] Number of positive: 174231, number of negative: 718935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2974\n",
      "[LightGBM] [Info] Number of data points in the train set: 893166, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.195071 -> initscore=-1.417389\n",
      "[LightGBM] [Info] Start training from score -1.417389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Base Repeats:  13%|█▎        | 13/100 [00:20<02:14,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing method : Base\n",
      "[LightGBM] [Info] Number of positive: 174231, number of negative: 718935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2974\n",
      "[LightGBM] [Info] Number of data points in the train set: 893166, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.195071 -> initscore=-1.417389\n",
      "[LightGBM] [Info] Start training from score -1.417389\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "Methods = ['Base', 'Undersampling', 'SMOTE', 'table-gan','Smotified-gan']\n",
    "n_runs = 100\n",
    "\n",
    "all_results = []\n",
    "\n",
    "X_test = test_classification.drop(columns='loan_status')\n",
    "y_test = test_classification['loan_status']\n",
    "\n",
    "for method in Methods:\n",
    "    print(f\"\\n===== {method} 시작 =====\")\n",
    "    \n",
    "    method_results = []\n",
    "\n",
    "    for run in tqdm(range(n_runs), desc=f'{method} Repeats'):\n",
    "        data_x = data_classification.drop(columns='loan_status')\n",
    "        data_y = data_classification['loan_status']\n",
    "\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'num_leaves': 31,\n",
    "            'n_estimators': 500,\n",
    "            'class_weight': None,\n",
    "            'random_state': 42,\n",
    "        }\n",
    "\n",
    "        lgbm_model = LGBMClassifier(**params)\n",
    "\n",
    "        method_evaluation(model, data_x, data_y, X_test, y_test, method)\n",
    "\n",
    "        last_result = results_summary[-1]  # 방금 추가된 결과만 가져옴\n",
    "        method_results.append(last_result)\n",
    "\n",
    "    all_results.append((method, method_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952f37da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Method  Recall_1_Mean  Recall_1_Std  F1_1_Mean  F1_1_Std  \\\n",
      "0           Base       0.000000           NaN   0.000000       NaN   \n",
      "1  Undersampling       0.909644           NaN   0.717852       NaN   \n",
      "2          SMOTE       0.819811           NaN   0.738830       NaN   \n",
      "3      table-gan       1.000000           NaN   0.326458       NaN   \n",
      "4  Smotified-gan       1.000000           NaN   0.326458       NaN   \n",
      "\n",
      "   AU_PRC_Mean  AU_PRC_Std  \n",
      "0     0.765373         NaN  \n",
      "1     0.766754         NaN  \n",
      "2     0.763563         NaN  \n",
      "3     0.671002         NaN  \n",
      "4     0.703048         NaN  \n"
     ]
    }
   ],
   "source": [
    "summary_stats = []\n",
    "\n",
    "for method, results in all_results:\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    summary_stats.append({\n",
    "        'Method': method,\n",
    "        'Recall_1_Mean': df['Recall_1'].mean(),\n",
    "        'Recall_1_Std': df['Recall_1'].std(),\n",
    "        'F1_1_Mean': df['F1_1'].mean(),\n",
    "        'F1_1_Std': df['F1_1'].std(),\n",
    "        'AU_PRC_Mean': df['AU_PRC'].mean(),\n",
    "        'AU_PRC_Std': df['AU_PRC'].std(),\n",
    "    })\n",
    "\n",
    "stats_df = pd.DataFrame(summary_stats)\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52188529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Recall_1_Mean</th>\n",
       "      <th>Recall_1_Std</th>\n",
       "      <th>F1_1_Mean</th>\n",
       "      <th>F1_1_Std</th>\n",
       "      <th>AU_PRC_Mean</th>\n",
       "      <th>AU_PRC_Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.765373</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undersampling</td>\n",
       "      <td>0.909644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.717852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.766754</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.819811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.738830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.763563</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>table-gan</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.326458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671002</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Smotified-gan</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.326458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.703048</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Method  Recall_1_Mean  Recall_1_Std  F1_1_Mean  F1_1_Std  \\\n",
       "0           Base       0.000000           NaN   0.000000       NaN   \n",
       "1  Undersampling       0.909644           NaN   0.717852       NaN   \n",
       "2          SMOTE       0.819811           NaN   0.738830       NaN   \n",
       "3      table-gan       1.000000           NaN   0.326458       NaN   \n",
       "4  Smotified-gan       1.000000           NaN   0.326458       NaN   \n",
       "\n",
       "   AU_PRC_Mean  AU_PRC_Std  \n",
       "0     0.765373         NaN  \n",
       "1     0.766754         NaN  \n",
       "2     0.763563         NaN  \n",
       "3     0.671002         NaN  \n",
       "4     0.703048         NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea071639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "all_f1_df = pd.concat([\n",
    "    pd.DataFrame({'Method': method, 'F1_1': [r['F1_1'] for r in results]})\n",
    "    for method, results in all_results\n",
    "])\n",
    "\n",
    "sns.boxplot(data=all_f1_df, x='Method', y='F1_1')\n",
    "plt.title('F1-Score (Class 1) Distribution by Method')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3c0796",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "x = stats_df['Method']\n",
    "y = stats_df['AU_PRC_Mean']\n",
    "err = stats_df['AU_PRC_Std']\n",
    "\n",
    "plt.bar(x, y, yerr=err, capsize=5)\n",
    "plt.ylabel('AU-PRC (Mean ± Std)')\n",
    "plt.title('AU-PRC by Sampling Method')\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CTGAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
