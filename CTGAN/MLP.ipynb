{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "677670a2",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5048adcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, log_loss\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e679960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dab4f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load original data\n",
    "data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/Dataset/return_feature_train.csv\"\n",
    "data = pd.read_csv(data_path, low_memory=False)\n",
    "\n",
    "##load test data\n",
    "test_data_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/Dataset/return_feature_test.csv\"\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "## Load original data\n",
    "fake_path = \"C:/Users/GCU/Lending_club/Data_Analysis_lending-club/CTGAN/ctgan_output/synthetic_ctgan_data_class1.csv\"\n",
    "fake = pd.read_csv(fake_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f5e61c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_features = ['grade', 'term_months', 'total_pymnt', 'total_pymnt_inv','total_il_high_credit_limit', 'loan_amnt']\n",
    "\n",
    "data_classification = data.copy()\n",
    "test_classification = test_data.copy()\n",
    "fake_classification = fake.copy()\n",
    "\n",
    "data_classification = data_classification.drop(columns = keep_features)\n",
    "test_classification = test_classification.drop(columns = keep_features)\n",
    "fake_classification = fake_classification.drop(columns = keep_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15dbf81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data_classification.drop(columns='loan_status')\n",
    "data_y = data_classification[['loan_status']]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(data_x, data_y, train_size=0.8, test_size=0.2, random_state=42, stratify=data_y)\n",
    "\n",
    "train_classification = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16a4f83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "train_data = pd.concat([train_classification, fake_classification])\n",
    "train_data['loan_status'].value_counts()\n",
    "train_data = shuffle(train_data, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf19f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns='loan_status')\n",
    "y_train = train_data[['loan_status']]\n",
    "\n",
    "X_test = test_classification.drop(columns='loan_status')\n",
    "y_test = test_classification[['loan_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc5797de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2506f713",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = ClassificationDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = ClassificationDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = ClassificationDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=500, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=500)\n",
    "test_loader = DataLoader(test_dataset, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "090da18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = MLPClassifier(input_dim=X_train_tensor.shape[1]).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56030a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  20%|██        | 1/5 [00:18<01:13, 18.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 0.3753 | Val Loss: 0.2965 | Val Acc: 0.8806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  40%|████      | 2/5 [00:36<00:54, 18.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 0.3145 | Val Loss: 0.3470 | Val Acc: 0.8616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  60%|██████    | 3/5 [00:53<00:35, 17.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 0.3062 | Val Loss: 0.3160 | Val Acc: 0.8703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  80%|████████  | 4/5 [01:10<00:17, 17.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 0.3005 | Val Loss: 0.3116 | Val Acc: 0.8725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 5/5 [01:27<00:00, 17.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 0.2978 | Val Loss: 0.3123 | Val Acc: 0.8689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "patience = 7\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in tqdm(range(100), desc=\"Training Epochs\"):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            output = model(X_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "            preds = (output >= 0.5).float()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = sum(val_losses) / len(val_losses)\n",
    "    val_acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # --- Early Stopping Check ---\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        best_model_state = copy.deepcopy(model.state_dict())  # 모델 저장\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"⏹ Early stopping triggered at epoch {epoch+1}.\")\n",
    "            break\n",
    "\n",
    "# --- 최적 모델 로드 (선택) ---\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"✅ Best model restored (based on lowest validation loss).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "234ba74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Evaluation Metrics:\n",
      " - Accuracy:  0.8691\n",
      " - Precision: 0.6146\n",
      " - Recall:    0.8823\n",
      " - F1-Score:  0.7245\n",
      " - AU-PRC:    0.7430\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, average_precision_score\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        y_prob = model(X_batch)  \n",
    "        y_pred = (y_prob >= 0.5).float() \n",
    "\n",
    "        all_probs.extend(y_prob.cpu().numpy())\n",
    "        all_preds.extend(y_pred.cpu().numpy())\n",
    "        all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "y_true = np.array(all_labels).flatten()\n",
    "y_pred_cls = np.array(all_preds).flatten()\n",
    "y_prob_cls = np.array(all_probs).flatten()\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred_cls)\n",
    "precision = precision_score(y_true, y_pred_cls)\n",
    "recall = recall_score(y_true, y_pred_cls)\n",
    "f1 = f1_score(y_true, y_pred_cls)\n",
    "au_prc = average_precision_score(y_true, y_prob_cls)  \n",
    "\n",
    "print(f\"🔍 Evaluation Metrics:\")\n",
    "print(f\" - Accuracy:  {acc:.4f}\")\n",
    "print(f\" - Precision: {precision:.4f}\")\n",
    "print(f\" - Recall:    {recall:.4f}\")\n",
    "print(f\" - F1-Score:  {f1:.4f}\")\n",
    "print(f\" - AU-PRC:    {au_prc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91ad0e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9681    0.8659    0.9142    599114\n",
      "         1.0     0.6146    0.8823    0.7245    145192\n",
      "\n",
      "    accuracy                         0.8691    744306\n",
      "   macro avg     0.7913    0.8741    0.8193    744306\n",
      "weighted avg     0.8991    0.8691    0.8772    744306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true, y_pred_cls, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CTGAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
